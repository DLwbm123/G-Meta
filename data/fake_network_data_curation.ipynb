{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/kexinhuang/.dgl/sst.zip from https://data.dgl.ai/dataset/sst.zip...\n",
      "Extracting file to /Users/kexinhuang/.dgl/sst\n",
      "Preprocessing...\n",
      "Dataset creation finished. #Trees: 5\n",
      "the rock is destined to be the 21st century 's new `` conan '' and that he 's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . "
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data.tree import SST\n",
    "from dgl.data import SSTBatch\n",
    "\n",
    "# Each sample in the dataset is a constituency tree. The leaf nodes\n",
    "# represent words. The word is an int value stored in the \"x\" field.\n",
    "# The non-leaf nodes have a special word PAD_WORD. The sentiment\n",
    "# label is stored in the \"y\" feature field.\n",
    "trainset = SST(mode='tiny')  # the \"tiny\" set has only five trees\n",
    "tiny_sst = trainset.trees\n",
    "num_vocabs = trainset.num_vocabs\n",
    "num_classes = trainset.num_classes\n",
    "\n",
    "vocab = trainset.vocab # vocabulary dict: key -> id\n",
    "inv_vocab = {v: k for k, v in vocab.items()} # inverted vocabulary dict: id -> word\n",
    "\n",
    "a_tree = tiny_sst[0]\n",
    "for token in a_tree.ndata['x'].tolist():\n",
    "    if token != trainset.PAD_WORD:\n",
    "        print(inv_vocab[token], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.batch(tiny_sst)\n",
    "x = graph.to_networkx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DGLGraph(num_nodes=71, num_edges=70,\n",
       "         ndata_schemes={'x': Scheme(shape=(), dtype=torch.int64), 'y': Scheme(shape=(), dtype=torch.int64), 'mask': Scheme(shape=(), dtype=torch.int64)}\n",
       "         edata_schemes={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_sst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.barabasi_albert_graph(100, 5, seed = 1)\n",
    "C = nx.clustering(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(G, 'fakegraph.adjlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BINs = plt.hist(list(C.values()), bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29., 39., 21.,  7.,  4.]),\n",
       " array([0.        , 0.10666667, 0.21333333, 0.32      , 0.42666667,\n",
       "        0.53333333]),\n",
       " <a list of 5 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_normalized_adjacency(adj):\n",
    "    adj = adj + sp.eye(adj.shape[0])\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    row_sum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(row_sum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def row_normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.adjacency_matrix(G)\n",
    "A = aug_normalized_adjacency(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.eye(A.shape[0])\n",
    "features = row_normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, isspmatrix\n",
    "isspmatrix(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(A.shape[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(list(C.values()))\n",
    "label_count = 5\n",
    "for i in range(label_count):\n",
    "    thr_down = np.percentile(tmp, i*(100/label_count))\n",
    "    thr_up = np.percentile(tmp,(i+1)*(100/label_count))\n",
    "    labels[np.where((tmp <= thr_up) & (tmp > thr_down))] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = [A, features, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('fake_graph.npz', A, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isspmatrix(np.load('fake_graph.npz', allow_pickle = True)['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "#from normalization import fetch_normalization, row_normalize\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_citation(dataset_str=\"cora\", normalization=\"AugNormAdj\", cuda=True):\n",
    "    names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
    "            if sys.version_info > (3, 0):\n",
    "                objects.append(pkl.load(f, encoding='latin1'))\n",
    "            else:\n",
    "                objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\"data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "    if dataset_str == 'citeseer':\n",
    "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
    "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
    "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
    "        tx = tx_extended\n",
    "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
    "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
    "        ty = ty_extended\n",
    "\n",
    "    features = sp.vstack((allx, tx)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    labels = np.vstack((ally, ty))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "\n",
    "    adj, features = preprocess_citation(adj, features, normalization)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense())).float()\n",
    "    labels = torch.LongTensor(labels)\n",
    "    labels = torch.max(labels, dim=1)[1]\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj).float()\n",
    "\n",
    "    if cuda:\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    return adj, features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "dataset_str=\"cora\"\n",
    "objects = []\n",
    "for i in range(len(names)):\n",
    "    with open(\"../meta_gnn/data/ind.{}.{}\".format(dataset_str.lower(), names[i]), 'rb') as f:\n",
    "        if sys.version_info > (3, 0):\n",
    "            objects.append(pkl.load(f, encoding='latin1'))\n",
    "        else:\n",
    "            objects.append(pkl.load(f))\n",
    "\n",
    "x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "test_idx_reorder = parse_index_file(\"../meta_gnn/data/ind.{}.test.index\".format(dataset_str))\n",
    "test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "features = sp.vstack((allx, tx)).tolil()\n",
    "features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10556 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def generate_graph(n):\n",
    "    '''\n",
    "    input: \n",
    "        - n: number of graphs\n",
    "    output:\n",
    "        - G_set: a list of nx graphs [G_1, G_2, ..., G_n]\n",
    "        - F_set: features associated with each node in the graph [F_1, ..., F_n] where L_i is a dictionary {node_1: features_1, ....}\n",
    "        - L_set: labels associated with each node in the graph [L_1, ..., L_n] where L_i is a dictionary {node_1: label_1, ....}\n",
    "    '''    \n",
    "    G_set = []\n",
    "    F_set = []\n",
    "    L_set = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        G = nx.barabasi_albert_graph(100, 5)\n",
    "        labels = np.zeros(A.shape[0], )\n",
    "        tmp = np.array(list(C.values()))\n",
    "        label_count = 5\n",
    "        for i in range(label_count):\n",
    "            thr_down = np.percentile(tmp, i*(100/label_count))\n",
    "            thr_up = np.percentile(tmp,(i+1)*(100/label_count))\n",
    "            labels[np.where((tmp <= thr_up) & (tmp > thr_down))] = i\n",
    "            \n",
    "        features = np.eye(A.shape[0])\n",
    "        features = row_normalize(features)\n",
    "        G_set.append(G)\n",
    "        F_set.append(features)\n",
    "        L_set.append(labels)\n",
    "    return G_set, F_set, L_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_subgraphs(G, features, labels, h, idx):\n",
    "    '''\n",
    "    input:\n",
    "        - G: a graph\n",
    "        - features: node features\n",
    "        - labels: node labels\n",
    "        - h: h hops\n",
    "        - idx: graph index\n",
    "    output:\n",
    "        - S_list: a list of DGL subgraphs where each subgraph is centered on a node i. {node i: adj_i, ....}\n",
    "    '''\n",
    "    S_list = {}\n",
    "    \n",
    "    for i in list(G.nodes):\n",
    "        h_hops_neighbor = list(nx.single_source_shortest_path_length(G, i, cutoff=h).keys())\n",
    "        features = features[h_hops_neighbor]\n",
    "        labels = labels[h_hops_neighbor]\n",
    "        S = dgl.DGLGraph()\n",
    "        S.from_networkx(G.subgraph(h_hops_neighbor))\n",
    "        S.ndata['x'] = features\n",
    "        S.ndata['y'] = labels\n",
    "        S.ndata['center_node'] = i\n",
    "        S.ndata['graph_idx'] = idx\n",
    "        S_list.append(S)        \n",
    "    return S_list    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n, h):\n",
    "    '''\n",
    "    generate h hops subgraphs for n \n",
    "    \n",
    "    input:\n",
    "        - n: use in total n graphs\n",
    "        - h: h hops subgraph\n",
    "    '''\n",
    "    \n",
    "    total_subgraph_list = []\n",
    "    G_set, F_set, L_set = generate_graph(n)\n",
    "    for i in range(len(G_set)):\n",
    "        G = G_set[i]\n",
    "        F = F_set[i]\n",
    "        L = L_set[i]\n",
    "        \n",
    "        S_list = graph_to_subgraphs(G, F, L, h, i)\n",
    "        total_subgraph_list = total_subgraph_list + S_list\n",
    "        \n",
    "    return total_subgraph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
