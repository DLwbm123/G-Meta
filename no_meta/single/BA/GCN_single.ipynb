{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "adj = np.load('../../../data/single_graph/BA/graph_adj.npy')\n",
    "rows, cols = np.where(adj == 1)\n",
    "edges = zip(rows.tolist(), cols.tolist())\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "labels = pd.read_csv('../../../data/single_graph/BA/data.csv').label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')\n",
    "\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "    \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_feat, hidden_dim, out_cls):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(in_feat, hidden_dim, F.relu)\n",
    "        self.gcn2 = GCN(hidden_dim, out_cls, None)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        features = g.in_degrees().view(-1, 1).float()\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "labels = torch.tensor(labels)\n",
    "inputs = torch.eye(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dgl.DGLGraph()\n",
    "S.from_networkx(G)\n",
    "S.ndata['h'] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "labeled_nodes = np.random.choice(list(range(G.number_of_nodes())), int(G.number_of_nodes() * 0.15), replace = False)\n",
    "labels_train = labels[labeled_nodes]\n",
    "\n",
    "unlabelled_nodes = [i for i in list(range(G.number_of_nodes())) if i not in labeled_nodes]\n",
    "val_nodes = np.random.choice(unlabelled_nodes, int(len(unlabelled_nodes)*0.2), replace = False)\n",
    "test_nodes = [i for i in unlabelled_nodes if i not in val_nodes]\n",
    "\n",
    "val_label = labels[val_nodes]\n",
    "test_label = labels[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 316.9016\n",
      "Epoch 100 | Loss: 2.0407\n",
      "Epoch 200 | Loss: 1.9164\n",
      "Epoch 300 | Loss: 1.7446\n",
      "Epoch 400 | Loss: 1.5990\n",
      "Epoch 500 | Loss: 1.4944\n",
      "Epoch 600 | Loss: 1.4168\n",
      "Epoch 700 | Loss: 1.3567\n",
      "Epoch 800 | Loss: 1.3086\n",
      "Epoch 900 | Loss: 1.2687\n",
      "Epoch 1000 | Loss: 1.2350\n",
      "Epoch 1100 | Loss: 1.2058\n",
      "Epoch 1200 | Loss: 1.1803\n",
      "Epoch 1300 | Loss: 1.1577\n",
      "Epoch 1400 | Loss: 1.1373\n",
      "Epoch 1500 | Loss: 1.1190\n",
      "Epoch 1600 | Loss: 1.1022\n",
      "Epoch 1700 | Loss: 1.0868\n",
      "Epoch 1800 | Loss: 1.0727\n",
      "Epoch 1900 | Loss: 1.0595\n"
     ]
    }
   ],
   "source": [
    "net = Net(1, 64, 10)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.03)\n",
    "all_logits = []\n",
    "for epoch in range(2000):\n",
    "    logits = net(S, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "logits = net(S, inputs)\n",
    "# we save the logits for visualization later\n",
    "logp = F.log_softmax(logits, 1)\n",
    "# we only compute loss for labeled nodes\n",
    "#loss = F.nll_loss(logp[labeled_nodes], labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_Y = torch.max(logp[test_nodes], 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of argmax predictions on the test set: 56.617647%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "    (test_label == argmax_Y.float()).sum().item() / len(test_label) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
