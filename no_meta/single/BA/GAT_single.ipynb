{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "adj = np.load('../../../data/single_graph/BA/graph_adj.npy')\n",
    "rows, cols = np.where(adj == 1)\n",
    "edges = zip(rows.tolist(), cols.tolist())\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "labels = pd.read_csv('../../../data/single_graph/BA/data.csv').label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import edge_softmax, GATConv\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 num_classes,\n",
    "                 heads,\n",
    "                 activation,\n",
    "                 feat_drop,\n",
    "                 attn_drop,\n",
    "                 negative_slope,\n",
    "                 residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        # input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads[0],\n",
    "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
    "        # hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads[l],\n",
    "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
    "        # output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads[-1],\n",
    "            feat_drop, attn_drop, negative_slope, residual, None))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.g.in_degrees().view(-1, 1).float()\n",
    "        #h = inputs\n",
    "        for l in range(self.num_layers):\n",
    "            h = self.gat_layers[l](self.g, h).flatten(1)\n",
    "        # output projection\n",
    "        logits = self.gat_layers[-1](self.g, h).mean(1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "labels = torch.tensor(labels)\n",
    "inputs = torch.eye(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dgl.DGLGraph()\n",
    "S.from_networkx(G)\n",
    "S.ndata['h'] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 200])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "labeled_nodes = np.random.choice(list(range(G.number_of_nodes())), int(G.number_of_nodes() * 0.15), replace = False)\n",
    "labels_train = labels[labeled_nodes]\n",
    "\n",
    "unlabelled_nodes = [i for i in list(range(G.number_of_nodes())) if i not in labeled_nodes]\n",
    "val_nodes = np.random.choice(unlabelled_nodes, int(len(unlabelled_nodes)*0.2), replace = False)\n",
    "test_nodes = [i for i in unlabelled_nodes if i not in val_nodes]\n",
    "\n",
    "val_label = labels[val_nodes]\n",
    "test_label = labels[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 58,  40,  34, 102, 184, 198,  95,   4,  29, 168, 171,  18,  11,\n",
       "        89, 110, 118, 159,  35, 136,  59,  51,  16,  44,  94,  31, 162,\n",
       "        38,  28, 193,  27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 154.8825\n",
      "Epoch 100 | Loss: 7.1227\n",
      "Epoch 200 | Loss: 5.2233\n",
      "Epoch 300 | Loss: 5.9650\n",
      "Epoch 400 | Loss: 2.6290\n",
      "Epoch 500 | Loss: 3.4418\n",
      "Epoch 600 | Loss: 2.6763\n",
      "Epoch 700 | Loss: 2.4389\n",
      "Epoch 800 | Loss: 2.2699\n",
      "Epoch 900 | Loss: 3.0237\n",
      "Epoch 1000 | Loss: 2.6132\n",
      "Epoch 1100 | Loss: 2.4184\n",
      "Epoch 1200 | Loss: 2.1928\n",
      "Epoch 1300 | Loss: 2.3225\n",
      "Epoch 1400 | Loss: 2.1570\n",
      "Epoch 1500 | Loss: 2.2151\n",
      "Epoch 1600 | Loss: 2.1654\n",
      "Epoch 1700 | Loss: 2.1993\n",
      "Epoch 1800 | Loss: 2.1972\n",
      "Epoch 1900 | Loss: 2.3749\n"
     ]
    }
   ],
   "source": [
    "heads = ([2] * 3) + [1]\n",
    "net = GAT(S, 3, 1, 32, 10, heads, F.elu, .3, .3, .2, False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n",
    "all_logits = []\n",
    "for epoch in range(2000):\n",
    "    logits = net(inputs)\n",
    "    # we save the logits for visualization later\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "logits = net(inputs)\n",
    "# we save the logits for visualization later\n",
    "logp = F.log_softmax(logits, 1)\n",
    "# we only compute loss for labeled nodes\n",
    "#loss = F.nll_loss(logp[labeled_nodes], labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.9580,  -7.7852, -26.6310,  ...,  -1.4376, -10.3898,  -0.9722],\n",
       "        [ -0.2970, -14.7138, -40.7679,  ...,  -2.4015, -16.4597,  -1.7937],\n",
       "        [ -0.1986, -17.4598, -46.8344,  ...,  -2.9251, -18.6655,  -2.0679],\n",
       "        ...,\n",
       "        [ -0.0675, -22.3445, -55.7989,  ...,  -3.6947, -23.2302,  -3.2094],\n",
       "        [ -0.9972,  -7.5244, -26.0619,  ...,  -1.4109, -10.1616,  -0.9509],\n",
       "        [ -0.8538,  -8.1289, -28.0184,  ...,  -1.5704, -10.7501,  -1.0056]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_Y = torch.max(logp[test_nodes], 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of argmax predictions on the test set: 5.147059%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "    (test_label == argmax_Y.float()).sum().item() / len(test_label) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
