{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "os.chdir('../../../graphwave/')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphwave\n",
    "from graphwave.shapes import build_graph\n",
    "\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "width_basis = 50\n",
    "\n",
    "### 1. Choose the basis (cycle, torus or chain)\n",
    "basis_type = \"cycle\" \n",
    "\n",
    "### 2. Add the shapes \n",
    "n_shapes = 10  \n",
    "list_shapes = [[\"house\"]] * n_shapes + [[\"diamond\"]] * n_shapes + [[\"star\", 6]] * n_shapes + [[\"fan\", 6]] * n_shapes\n",
    "\n",
    "### 3. Pass all these parameters to the Graph Structure\n",
    "add_edges = 100 # random edges to add\n",
    "G, communities, _ , role_id = build_graph.build_structure(width_basis, basis_type, list_shapes, start=0,\n",
    "                                       add_random_edges=add_edges, plot=False,\n",
    "                                       savefig=False)\n",
    "d = dict(zip(np.unique(role_id), range(len(np.unique(role_id)))))\n",
    "labels = np.array([d[i] for i in role_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import edge_softmax, GATConv\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 num_classes,\n",
    "                 heads,\n",
    "                 activation,\n",
    "                 feat_drop,\n",
    "                 attn_drop,\n",
    "                 negative_slope,\n",
    "                 residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        # input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads[0],\n",
    "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
    "        # hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads[l],\n",
    "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
    "        # output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads[-1],\n",
    "            feat_drop, attn_drop, negative_slope, residual, None))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.g.in_degrees().view(-1, 1).float()\n",
    "        #h = inputs\n",
    "        for l in range(self.num_layers):\n",
    "            h = self.gat_layers[l](self.g, h).flatten(1)\n",
    "        # output projection\n",
    "        logits = self.gat_layers[-1](self.g, h).mean(1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "labels = torch.tensor(labels)\n",
    "inputs = torch.eye(G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = dgl.DGLGraph()\n",
    "S.from_networkx(G)\n",
    "S.ndata['h'] = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "labeled_nodes = np.random.choice(list(range(G.number_of_nodes())), int(G.number_of_nodes() * 0.15), replace = False)\n",
    "labels_train = labels[labeled_nodes]\n",
    "\n",
    "unlabelled_nodes = [i for i in list(range(G.number_of_nodes())) if i not in labeled_nodes]\n",
    "val_nodes = np.random.choice(unlabelled_nodes, int(len(unlabelled_nodes)*0.2), replace = False)\n",
    "test_nodes = [i for i in unlabelled_nodes if i not in val_nodes]\n",
    "\n",
    "val_label = labels[val_nodes]\n",
    "test_label = labels[test_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([189, 123, 185, 213, 106, 127, 176,  73, 275, 242, 266, 147, 299,\n",
       "        58, 122,  78,  11, 167, 220,  29,  27, 110, 251,  12, 105,  18,\n",
       "       297,  90, 293, 184, 139, 248, 229,  59,  51,  88,  95, 164,  80,\n",
       "       217, 221, 228, 191,   4,  70])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 5.3663\n",
      "Epoch 100 | Loss: 2.6359\n",
      "Epoch 200 | Loss: 2.5178\n",
      "Epoch 300 | Loss: 2.2414\n",
      "Epoch 400 | Loss: 2.1468\n",
      "Epoch 500 | Loss: 2.4150\n",
      "Epoch 600 | Loss: 2.0852\n",
      "Epoch 700 | Loss: 2.1001\n",
      "Epoch 800 | Loss: 2.0909\n",
      "Epoch 900 | Loss: 2.0447\n",
      "Epoch 1000 | Loss: 2.2949\n",
      "Epoch 1100 | Loss: 2.0190\n",
      "Epoch 1200 | Loss: 1.8654\n",
      "Epoch 1300 | Loss: 1.9245\n",
      "Epoch 1400 | Loss: 2.2727\n",
      "Epoch 1500 | Loss: 2.0938\n",
      "Epoch 1600 | Loss: 1.9930\n",
      "Epoch 1700 | Loss: 2.0411\n",
      "Epoch 1800 | Loss: 2.0852\n",
      "Epoch 1900 | Loss: 1.8101\n"
     ]
    }
   ],
   "source": [
    "heads = ([2] * 3) + [1]\n",
    "net = GAT(S, 3, 1, 32, 17, heads, F.elu, .3, .3, .2, False)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n",
    "all_logits = []\n",
    "for epoch in range(2000):\n",
    "    logits = net(inputs)\n",
    "    # we save the logits for visualization later\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "logits = net(inputs)\n",
    "# we save the logits for visualization later\n",
    "logp = F.log_softmax(logits, 1)\n",
    "# we only compute loss for labeled nodes\n",
    "#loss = F.nll_loss(logp[labeled_nodes], labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-14.9496,  -4.3516,  -5.7407,  ...,  -4.2716,  -3.1702,  -5.5340],\n",
       "        [-14.8440,  -4.2218,  -5.3892,  ...,  -4.2352,  -3.2041,  -5.4097],\n",
       "        [-14.7956,  -4.2231,  -5.2378,  ...,  -4.3001,  -3.2845,  -5.3591],\n",
       "        ...,\n",
       "        [-15.4750,  -3.7269,  -5.0493,  ...,  -4.0530,  -2.7159,  -4.9317],\n",
       "        [-14.8445,  -4.6181,  -6.4436,  ...,  -4.2698,  -3.2026,  -5.8785],\n",
       "        [-14.7487,  -4.8938,  -7.4249,  ...,  -4.4523,  -3.3096,  -6.3532]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_Y = torch.max(logp[test_nodes], 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of argmax predictions on the test set: 19.117647%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "    (test_label == argmax_Y.float()).sum().item() / len(test_label) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
