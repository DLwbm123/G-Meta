{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 954.12it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1636.80it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 515.25it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.32it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 Val acc: [0.     0.5    0.5    0.5    0.4978 0.4895 0.4822 0.473  0.4595 0.4524\n",
      " 0.    ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.         0.53125    0.47916667 0.40625    0.40625    0.        ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.         0.58333333 0.63541667 0.73958333 0.72916667 0.        ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.         0.5        0.54166667 0.57291667 0.60416667 0.        ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.         0.4375     0.47916667 0.48958333 0.5        0.        ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.         0.41666667 0.32291667 0.28125    0.25       0.        ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.    0.625 0.5   0.5   0.5   0.   ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.         0.48958333 0.47916667 0.53125    0.58333333 0.        ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.         0.51041667 0.48958333 0.48958333 0.44791667 0.        ]\n",
      "epoch: 1 Val acc: [0.     0.488  0.5225 0.53   0.5327 0.5366 0.5464 0.555  0.563  0.567\n",
      " 0.    ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.         0.5625     0.59375    0.65625    0.61458333 0.        ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.         0.58333333 0.58333333 0.58333333 0.51041667 0.        ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.         0.61458333 0.66666667 0.65625    0.71875    0.        ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.         0.48958333 0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.         0.39583333 0.41666667 0.44791667 0.5        0.        ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.         0.59375    0.625      0.61458333 0.5625     0.        ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.         0.60416667 0.625      0.625      0.65625    0.        ]\n",
      "epoch: 2 Val acc: [0.     0.5073 0.515  0.5303 0.5444 0.558  0.567  0.5757 0.58   0.584\n",
      " 0.    ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.         0.38541667 0.34375    0.33333333 0.4375     0.        ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.         0.53125    0.45833333 0.41666667 0.38541667 0.        ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.         0.63541667 0.60416667 0.58333333 0.60416667 0.        ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.         0.5        0.5        0.5        0.47916667 0.        ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.         0.5        0.5        0.54166667 0.61458333 0.        ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.         0.48958333 0.5        0.5        0.5625     0.        ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 Val acc: [0.     0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.4963\n",
      " 0.    ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.         0.5        0.5        0.51041667 0.5625     0.        ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.         0.63541667 0.5625     0.5625     0.6875     0.        ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.         0.48958333 0.51041667 0.52083333 0.51041667 0.        ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.         0.36458333 0.36458333 0.35416667 0.35416667 0.        ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.         0.30208333 0.28125    0.27083333 0.28125    0.        ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.      0.65625 0.65625 0.65625 0.65625 0.     ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.         0.5        0.51041667 0.52083333 0.60416667 0.        ]\n",
      "epoch: 4 Val acc: [0.     0.5    0.5    0.503  0.5073 0.5103 0.5176 0.525  0.529  0.5337\n",
      " 0.    ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.         0.66666667 0.63541667 0.63541667 0.63541667 0.        ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.         0.67708333 0.67708333 0.65625    0.57291667 0.        ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.         0.33333333 0.41666667 0.48958333 0.47916667 0.        ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.         0.54166667 0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.         0.38541667 0.39583333 0.38541667 0.38541667 0.        ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.         0.53125    0.51041667 0.51041667 0.5        0.        ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.         0.39583333 0.39583333 0.39583333 0.38541667 0.        ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.         0.53125    0.51041667 0.5625     0.64583333 0.        ]\n",
      "epoch: 5 Val acc: [0.     0.5005 0.511  0.53   0.5483 0.575  0.5825 0.593  0.6064 0.6094\n",
      " 0.    ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.         0.61458333 0.625      0.625      0.64583333 0.        ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.         0.40625    0.40625    0.38541667 0.38541667 0.        ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.         0.54166667 0.54166667 0.54166667 0.53125    0.        ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.         0.27083333 0.27083333 0.27083333 0.27083333 0.        ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.         0.44791667 0.55208333 0.58333333 0.59375    0.        ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.         0.52083333 0.55208333 0.5        0.5        0.        ]\n",
      "epoch: 6 Val acc: [0.     0.4963 0.4924 0.5264 0.5273 0.528  0.5317 0.539  0.5396 0.538\n",
      " 0.    ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.         0.48958333 0.48958333 0.48958333 0.48958333 0.        ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.         0.40625    0.39583333 0.47916667 0.5        0.        ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.         0.16666667 0.21875    0.26041667 0.34375    0.        ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.         0.61458333 0.51041667 0.5        0.44791667 0.        ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.         0.3125     0.30208333 0.28125    0.27083333 0.        ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.         0.29166667 0.32291667 0.34375    0.35416667 0.        ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.         0.45833333 0.44791667 0.45833333 0.45833333 0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 0 \ttraining acc: [0.         0.48958333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 7 Val acc: [0.    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.501 0.   ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.         0.45833333 0.45833333 0.44791667 0.42708333 0.        ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.         0.47916667 0.45833333 0.4375     0.40625    0.        ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.         0.44791667 0.45833333 0.44791667 0.44791667 0.        ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.         0.60416667 0.60416667 0.60416667 0.59375    0.        ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.         0.57291667 0.57291667 0.57291667 0.57291667 0.        ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.         0.32291667 0.35416667 0.35416667 0.375      0.        ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.         0.45833333 0.44791667 0.45833333 0.46875    0.        ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.         0.40625    0.38541667 0.38541667 0.38541667 0.        ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.         0.5625     0.54166667 0.54166667 0.54166667 0.        ]\n",
      "epoch: 8 Val acc: [0.     0.526  0.5396 0.5503 0.558  0.564  0.572  0.5723 0.577  0.5806\n",
      " 0.    ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.         0.60416667 0.59375    0.58333333 0.58333333 0.        ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.         0.47916667 0.45833333 0.44791667 0.44791667 0.        ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.         0.35416667 0.32291667 0.34375    0.38541667 0.        ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.         0.64583333 0.60416667 0.59375    0.57291667 0.        ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.      0.6875  0.6875  0.65625 0.625   0.     ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.         0.33333333 0.38541667 0.42708333 0.44791667 0.        ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.         0.48958333 0.47916667 0.4375     0.42708333 0.        ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.         0.69791667 0.78125    0.84375    0.82291667 0.        ]\n",
      "epoch: 9 Val acc: [0.     0.4763 0.4766 0.4875 0.521  0.55   0.565  0.5723 0.5864 0.5884\n",
      " 0.    ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.         0.53125    0.52083333 0.52083333 0.52083333 0.        ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.     0.6875 0.6875 0.6875 0.6875 0.    ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.         0.75       0.76041667 0.76041667 0.78125    0.        ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.         0.53125    0.55208333 0.55208333 0.55208333 0.        ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.         0.5        0.5        0.51041667 0.52083333 0.        ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.         0.5        0.5        0.5625     0.60416667 0.        ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.         0.46875    0.46875    0.45833333 0.45833333 0.        ]\n",
      "Test acc: [0.     0.4622 0.4368 0.4182 0.4062 0.3945 0.4104 0.4595 0.5024 0.513\n",
      " 0.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_finetune_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 101.76it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1528.82it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 453.46it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 31.98it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 Val acc: [0.     0.5    0.5    0.5    0.5    0.5    0.5    0.4995 0.497  0.4966\n",
      " 0.    ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.         0.45833333 0.46875    0.46875    0.46875    0.        ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.         0.48958333 0.44791667 0.4375     0.44791667 0.        ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.         0.52083333 0.53125    0.42708333 0.41666667 0.        ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.         0.55208333 0.52083333 0.45833333 0.42708333 0.        ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.         0.59375    0.59375    0.625      0.67708333 0.        ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.         0.5        0.5        0.52083333 0.5625     0.        ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.         0.55208333 0.55208333 0.53125    0.57291667 0.        ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.         0.48958333 0.46875    0.5        0.55208333 0.        ]\n",
      "epoch: 1 Val acc: [0.     0.5005 0.5034 0.5117 0.5234 0.5356 0.549  0.558  0.561  0.5693\n",
      " 0.    ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.         0.375      0.47916667 0.5        0.5        0.        ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.         0.44791667 0.40625    0.40625    0.39583333 0.        ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.      0.5     0.5     0.40625 0.5     0.     ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.         0.40625    0.41666667 0.42708333 0.44791667 0.        ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.         0.30208333 0.30208333 0.30208333 0.28125    0.        ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.         0.39583333 0.32291667 0.375      0.375      0.        ]\n",
      "epoch: 2 Val acc: [0.     0.504  0.531  0.5576 0.574  0.5894 0.5884 0.5786 0.5737 0.5674\n",
      " 0.    ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.         0.5        0.48958333 0.5        0.5        0.        ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.         0.46875    0.42708333 0.36458333 0.28125    0.        ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.         0.46875    0.48958333 0.48958333 0.48958333 0.        ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.         0.375      0.375      0.44791667 0.44791667 0.        ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.         0.40625    0.41666667 0.45833333 0.44791667 0.        ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.         0.72916667 0.73958333 0.75       0.67708333 0.        ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 Val acc: [0.     0.5    0.5    0.5015 0.506  0.509  0.5127 0.525  0.5293 0.535\n",
      " 0.    ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.         0.35416667 0.41666667 0.41666667 0.4375     0.        ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.         0.55208333 0.52083333 0.48958333 0.46875    0.        ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.         0.5        0.54166667 0.5        0.5        0.        ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.         0.41666667 0.45833333 0.48958333 0.48958333 0.        ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.         0.42708333 0.48958333 0.48958333 0.5        0.        ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.         0.5625     0.55208333 0.54166667 0.51041667 0.        ]\n",
      "epoch: 4 Val acc: [0.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.         0.5        0.5        0.5        0.48958333 0.        ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.         0.59375    0.57291667 0.57291667 0.5625     0.        ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.    0.625 0.625 0.625 0.625 0.   ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.         0.47916667 0.53125    0.54166667 0.54166667 0.        ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.         0.625      0.625      0.61458333 0.60416667 0.        ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.         0.53125    0.53125    0.51041667 0.5        0.        ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.         0.38541667 0.35416667 0.35416667 0.35416667 0.        ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.         0.76041667 0.75       0.73958333 0.71875    0.        ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.         0.55208333 0.5625     0.58333333 0.57291667 0.        ]\n",
      "epoch: 5 Val acc: [0.     0.4812 0.474  0.4624 0.453  0.4412 0.4329 0.42   0.4128 0.4092\n",
      " 0.    ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.         0.47916667 0.5        0.5        0.5        0.        ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.         0.36458333 0.36458333 0.375      0.38541667 0.        ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.         0.40625    0.40625    0.36458333 0.35416667 0.        ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.         0.46875    0.5        0.51041667 0.48958333 0.        ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.         0.45833333 0.4375     0.42708333 0.42708333 0.        ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.         0.57291667 0.57291667 0.57291667 0.57291667 0.        ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.         0.42708333 0.42708333 0.45833333 0.46875    0.        ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.         0.29166667 0.28125    0.28125    0.27083333 0.        ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 Val acc: [0.     0.5    0.5    0.5024 0.5044 0.5117 0.52   0.5215 0.52   0.525\n",
      " 0.    ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.         0.75       0.72916667 0.71875    0.71875    0.        ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.         0.63541667 0.67708333 0.6875     0.70833333 0.        ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.         0.45833333 0.46875    0.47916667 0.5        0.        ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.         0.63541667 0.61458333 0.61458333 0.60416667 0.        ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.         0.54166667 0.52083333 0.51041667 0.5        0.        ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.         0.41666667 0.39583333 0.38541667 0.35416667 0.        ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.         0.42708333 0.42708333 0.41666667 0.38541667 0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 0 \ttraining acc: [0.         0.30208333 0.30208333 0.29166667 0.34375    0.        ]\n",
      "epoch: 7 Val acc: [0.     0.504  0.509  0.5137 0.5215 0.5327 0.5444 0.555  0.5674 0.5713\n",
      " 0.    ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.      0.625   0.65625 0.625   0.625   0.     ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.         0.58333333 0.625      0.625      0.625      0.        ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.         0.53125    0.5        0.48958333 0.46875    0.        ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.         0.40625    0.375      0.36458333 0.34375    0.        ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.         0.75       0.75       0.75       0.67708333 0.        ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.         0.16666667 0.16666667 0.15625    0.15625    0.        ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.         0.84375    0.84375    0.83333333 0.83333333 0.        ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.         0.375      0.375      0.39583333 0.41666667 0.        ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.         0.70833333 0.69791667 0.69791667 0.69791667 0.        ]\n",
      "epoch: 8 Val acc: [0.     0.501  0.4988 0.4941 0.4907 0.483  0.4805 0.4724 0.467  0.4617\n",
      " 0.    ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.         0.54166667 0.55208333 0.53125    0.55208333 0.        ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.         0.79166667 0.79166667 0.77083333 0.75       0.        ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.         0.30208333 0.29166667 0.28125    0.28125    0.        ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.         0.59375    0.59375    0.58333333 0.53125    0.        ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.         0.51041667 0.51041667 0.51041667 0.52083333 0.        ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.         0.39583333 0.39583333 0.36458333 0.41666667 0.        ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.      0.53125 0.53125 0.53125 0.53125 0.     ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.         0.51041667 0.51041667 0.52083333 0.54166667 0.        ]\n",
      "epoch: 9 Val acc: [0.     0.5005 0.5176 0.5303 0.5386 0.549  0.547  0.5483 0.552  0.554\n",
      " 0.    ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.         0.30208333 0.3125     0.33333333 0.34375    0.        ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.         0.48958333 0.48958333 0.48958333 0.48958333 0.        ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.         0.58333333 0.58333333 0.58333333 0.58333333 0.        ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.         0.5        0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.         0.52083333 0.52083333 0.52083333 0.52083333 0.        ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.      0.53125 0.53125 0.53125 0.53125 0.     ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.         0.53125    0.54166667 0.53125    0.51041667 0.        ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.         0.58333333 0.60416667 0.61458333 0.61458333 0.        ]\n",
      "Test acc: [0.     0.503  0.5054 0.508  0.5127 0.5156 0.5186 0.5225 0.53   0.532\n",
      " 0.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_finetune_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 614.19it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 912.30it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 391.53it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 35.71it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.         0.5        0.45833333 0.4375     0.4375     0.        ]\n",
      "epoch: 0 Val acc: [0.     0.5    0.4822 0.4468 0.4404 0.4563 0.4634 0.464  0.4622 0.464\n",
      " 0.    ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.         0.5        0.51041667 0.51041667 0.51041667 0.        ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.         0.67708333 0.61458333 0.57291667 0.57291667 0.        ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.         0.54166667 0.5        0.42708333 0.41666667 0.        ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.         0.40625    0.38541667 0.38541667 0.375      0.        ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.         0.52083333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 Val acc: [0.    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.501 0.   ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.         0.52083333 0.5        0.59375    0.5        0.        ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.         0.55208333 0.55208333 0.55208333 0.55208333 0.        ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.         0.55208333 0.58333333 0.61458333 0.625      0.        ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.         0.52083333 0.55208333 0.60416667 0.64583333 0.        ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.         0.23958333 0.26041667 0.29166667 0.33333333 0.        ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.         0.5        0.57291667 0.58333333 0.51041667 0.        ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.         0.48958333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.         0.5        0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 2 Val acc: [0.     0.4663 0.4438 0.4229 0.4133 0.4055 0.4058 0.415  0.422  0.427\n",
      " 0.    ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.         0.5        0.38541667 0.51041667 0.54166667 0.        ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.         0.5        0.51041667 0.51041667 0.5        0.        ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.         0.71875    0.75       0.77083333 0.79166667 0.        ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.         0.5        0.5        0.51041667 0.52083333 0.        ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.         0.5        0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.         0.5        0.53125    0.58333333 0.52083333 0.        ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.         0.61458333 0.58333333 0.57291667 0.5625     0.        ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.         0.58333333 0.625      0.61458333 0.58333333 0.        ]\n",
      "epoch: 3 Val acc: [0.     0.4333 0.4563 0.471  0.477  0.483  0.4841 0.4888 0.4893 0.4893\n",
      " 0.    ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.         0.40625    0.39583333 0.375      0.35416667 0.        ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.         0.42708333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.         0.54166667 0.54166667 0.54166667 0.54166667 0.        ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.         0.45833333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.         0.82291667 0.79166667 0.73958333 0.71875    0.        ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.         0.32291667 0.375      0.41666667 0.48958333 0.        ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.         0.42708333 0.48958333 0.48958333 0.5        0.        ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.         0.32291667 0.32291667 0.32291667 0.3125     0.        ]\n",
      "epoch: 4 Val acc: [0.     0.5    0.5    0.5    0.5    0.5    0.4993 0.4976 0.4937 0.4893\n",
      " 0.    ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.         0.46875    0.47916667 0.48958333 0.47916667 0.        ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.         0.44791667 0.46875    0.48958333 0.5        0.        ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.         0.73958333 0.73958333 0.76041667 0.75       0.        ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.         0.3125     0.32291667 0.39583333 0.4375     0.        ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.         0.44791667 0.44791667 0.41666667 0.40625    0.        ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.         0.34375    0.34375    0.33333333 0.35416667 0.        ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.         0.59375    0.59375    0.58333333 0.58333333 0.        ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.         0.48958333 0.48958333 0.47916667 0.48958333 0.        ]\n",
      "epoch: 5 Val acc: [0.     0.5273 0.545  0.558  0.575  0.582  0.588  0.592  0.597  0.5996\n",
      " 0.    ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.         0.3125     0.375      0.47916667 0.58333333 0.        ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.         0.65625    0.65625    0.65625    0.64583333 0.        ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.         0.67708333 0.67708333 0.67708333 0.67708333 0.        ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.         0.32291667 0.33333333 0.34375    0.34375    0.        ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.         0.57291667 0.57291667 0.5625     0.5625     0.        ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.         0.36458333 0.36458333 0.375      0.375      0.        ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.      0.53125 0.53125 0.53125 0.53125 0.     ]\n",
      "epoch: 6 Val acc: [0.     0.514  0.5234 0.535  0.544  0.5527 0.557  0.564  0.5664 0.569\n",
      " 0.    ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.         0.45833333 0.46875    0.47916667 0.47916667 0.        ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.         0.3125     0.38541667 0.45833333 0.45833333 0.        ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.         0.64583333 0.64583333 0.59375    0.58333333 0.        ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.         0.8125     0.80208333 0.77083333 0.73958333 0.        ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.         0.55208333 0.55208333 0.55208333 0.55208333 0.        ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.         0.35416667 0.39583333 0.40625    0.4375     0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 210 \ttraining acc: [0.         0.44791667 0.5        0.5        0.5        0.        ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.         0.53125    0.52083333 0.5        0.5        0.        ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.      0.59375 0.59375 0.59375 0.59375 0.     ]\n",
      "epoch: 7 Val acc: [0.     0.4976 0.497  0.4954 0.4912 0.4854 0.48   0.473  0.4675 0.4612\n",
      " 0.    ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.         0.60416667 0.63541667 0.65625    0.625      0.        ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.         0.4375     0.4375     0.44791667 0.44791667 0.        ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.         0.41666667 0.45833333 0.51041667 0.55208333 0.        ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.         0.38541667 0.39583333 0.42708333 0.52083333 0.        ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.         0.70833333 0.69791667 0.66666667 0.63541667 0.        ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.         0.47916667 0.5        0.5        0.51041667 0.        ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.   0.75 0.75 0.75 0.75 0.  ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.         0.72916667 0.72916667 0.72916667 0.72916667 0.        ]\n",
      "epoch: 8 Val acc: [0.     0.4734 0.4734 0.4717 0.4692 0.4653 0.465  0.4612 0.4624 0.4592\n",
      " 0.    ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.         0.35416667 0.35416667 0.35416667 0.34375    0.        ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.         0.34375    0.34375    0.34375    0.35416667 0.        ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.         0.51041667 0.51041667 0.48958333 0.5        0.        ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.         0.38541667 0.38541667 0.38541667 0.39583333 0.        ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.         0.33333333 0.33333333 0.33333333 0.34375    0.        ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.         0.40625    0.40625    0.39583333 0.39583333 0.        ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.         0.64583333 0.65625    0.65625    0.64583333 0.        ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.      0.28125 0.28125 0.28125 0.28125 0.     ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.         0.35416667 0.35416667 0.40625    0.38541667 0.        ]\n",
      "epoch: 9 Val acc: [0.     0.5205 0.5234 0.5293 0.535  0.5405 0.548  0.5527 0.556  0.563\n",
      " 0.    ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.         0.35416667 0.35416667 0.35416667 0.34375    0.        ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.         0.39583333 0.39583333 0.39583333 0.39583333 0.        ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.         0.36458333 0.36458333 0.39583333 0.41666667 0.        ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.         0.60416667 0.65625    0.72916667 0.75       0.        ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.         0.42708333 0.41666667 0.39583333 0.375      0.        ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.     0.3125 0.3125 0.3125 0.3125 0.    ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.         0.57291667 0.5625     0.55208333 0.55208333 0.        ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.     0.4375 0.4375 0.4375 0.4375 0.    ]\n",
      "Test acc: [0.     0.474  0.4624 0.4563 0.451  0.4438 0.4363 0.4238 0.4163 0.41\n",
      " 0.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_finetune_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 764.69it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1125.99it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 331.65it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 29.73it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.         0.5        0.5        0.5        0.44791667 0.        ]\n",
      "epoch: 0 Val acc: [0.     0.407  0.424  0.4475 0.463  0.4788 0.4863 0.4917 0.4993 0.5\n",
      " 0.    ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.         0.53125    0.5625     0.57291667 0.57291667 0.        ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.         0.42708333 0.42708333 0.47916667 0.51041667 0.        ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.         0.59375    0.59375    0.5        0.44791667 0.        ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.         0.40625    0.27083333 0.22916667 0.19791667 0.        ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.         0.41666667 0.5        0.5        0.5        0.        ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.         0.375      0.39583333 0.45833333 0.5        0.        ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.         0.65625    0.64583333 0.59375    0.59375    0.        ]\n",
      "epoch: 1 Val acc: [0.     0.5    0.5    0.5    0.5    0.5    0.4993 0.4958 0.4934 0.488\n",
      " 0.    ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.         0.5        0.47916667 0.44791667 0.44791667 0.        ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.         0.47916667 0.47916667 0.4375     0.52083333 0.        ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.         0.4375     0.58333333 0.54166667 0.5        0.        ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.         0.4375     0.47916667 0.5        0.5        0.        ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.         0.33333333 0.32291667 0.32291667 0.34375    0.        ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.         0.63541667 0.61458333 0.58333333 0.54166667 0.        ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.         0.48958333 0.58333333 0.6875     0.67708333 0.        ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.         0.66666667 0.69791667 0.72916667 0.79166667 0.        ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.         0.51041667 0.48958333 0.45833333 0.42708333 0.        ]\n",
      "epoch: 2 Val acc: [0.     0.5    0.4988 0.4836 0.4604 0.434  0.4211 0.4087 0.4084 0.412\n",
      " 0.    ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.         0.5        0.625      0.63541667 0.63541667 0.        ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.         0.52083333 0.4375     0.39583333 0.39583333 0.        ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.         0.41666667 0.54166667 0.66666667 0.72916667 0.        ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.         0.38541667 0.38541667 0.41666667 0.46875    0.        ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.         0.51041667 0.51041667 0.51041667 0.51041667 0.        ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.         0.36458333 0.375      0.35416667 0.35416667 0.        ]\n",
      "epoch: 3 Val acc: [0.     0.5    0.5    0.5    0.5005 0.5015 0.504  0.5044 0.507  0.512\n",
      " 0.    ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.         0.45833333 0.4375     0.61458333 0.58333333 0.        ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.         0.39583333 0.36458333 0.35416667 0.33333333 0.        ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.         0.4375     0.47916667 0.53125    0.54166667 0.        ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.         0.5        0.4375     0.38541667 0.28125    0.        ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.         0.5        0.5        0.5        0.45833333 0.        ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.    0.625 0.625 0.625 0.625 0.   ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.         0.46875    0.46875    0.46875    0.47916667 0.        ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.         0.61458333 0.59375    0.57291667 0.57291667 0.        ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.         0.35416667 0.375      0.40625    0.4375     0.        ]\n",
      "epoch: 4 Val acc: [0.     0.5    0.5    0.5015 0.503  0.505  0.508  0.511  0.5156 0.5205\n",
      " 0.    ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.         0.48958333 0.5        0.5        0.5        0.        ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.         0.61458333 0.60416667 0.57291667 0.57291667 0.        ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.         0.63541667 0.64583333 0.70833333 0.71875    0.        ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.         0.61458333 0.57291667 0.53125    0.52083333 0.        ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.      0.46875 0.46875 0.46875 0.46875 0.     ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.         0.51041667 0.51041667 0.51041667 0.51041667 0.        ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.         0.67708333 0.70833333 0.72916667 0.72916667 0.        ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.         0.57291667 0.5625     0.5625     0.55208333 0.        ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 Val acc: [0.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.      0.5     0.5     0.5     0.40625 0.     ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.         0.5        0.625      0.58333333 0.58333333 0.        ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.         0.66666667 0.64583333 0.64583333 0.64583333 0.        ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.      0.6875  0.6875  0.6875  0.65625 0.     ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.         0.54166667 0.54166667 0.57291667 0.55208333 0.        ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.         0.64583333 0.64583333 0.63541667 0.63541667 0.        ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.         0.32291667 0.35416667 0.375      0.38541667 0.        ]\n",
      "epoch: 6 Val acc: [0.     0.5024 0.5083 0.518  0.523  0.526  0.5317 0.541  0.548  0.556\n",
      " 0.    ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.         0.40625    0.40625    0.38541667 0.375      0.        ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.         0.42708333 0.40625    0.39583333 0.38541667 0.        ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.         0.25       0.28125    0.30208333 0.33333333 0.        ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.         0.58333333 0.58333333 0.58333333 0.59375    0.        ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.         0.47916667 0.47916667 0.47916667 0.45833333 0.        ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.         0.57291667 0.5625     0.5625     0.5625     0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 210 \ttraining acc: [0.         0.47916667 0.47916667 0.48958333 0.5        0.        ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.         0.125      0.13541667 0.17708333 0.19791667 0.        ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.         0.60416667 0.60416667 0.59375    0.58333333 0.        ]\n",
      "epoch: 7 Val acc: [0.     0.4792 0.475  0.4736 0.4692 0.4663 0.46   0.4512 0.445  0.4375\n",
      " 0.    ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.         0.36458333 0.375      0.375      0.36458333 0.        ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.         0.53125    0.52083333 0.57291667 0.61458333 0.        ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.      0.78125 0.78125 0.78125 0.78125 0.     ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.         0.55208333 0.55208333 0.55208333 0.55208333 0.        ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.         0.5        0.5        0.47916667 0.4375     0.        ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.         0.52083333 0.55208333 0.625      0.58333333 0.        ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.    0.625 0.625 0.625 0.625 0.   ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.         0.40625    0.44791667 0.46875    0.5        0.        ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.         0.72916667 0.72916667 0.72916667 0.69791667 0.        ]\n",
      "epoch: 8 Val acc: [0.     0.536  0.555  0.5693 0.5845 0.5967 0.597  0.5986 0.598  0.602\n",
      " 0.    ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.         0.57291667 0.57291667 0.57291667 0.57291667 0.        ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.         0.5        0.54166667 0.61458333 0.61458333 0.        ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.         0.375      0.41666667 0.54166667 0.63541667 0.        ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.         0.75       0.76041667 0.76041667 0.76041667 0.        ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.         0.72916667 0.71875    0.71875    0.71875    0.        ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.      0.40625 0.40625 0.40625 0.40625 0.     ]\n",
      "epoch: 9 Val acc: [0.  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.         0.32291667 0.40625    0.52083333 0.53125    0.        ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.         0.30208333 0.34375    0.4375     0.47916667 0.        ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.         0.39583333 0.38541667 0.38541667 0.38541667 0.        ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.         0.51041667 0.48958333 0.46875    0.46875    0.        ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.         0.63541667 0.63541667 0.625      0.625      0.        ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.         0.51041667 0.51041667 0.51041667 0.51041667 0.        ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.         0.42708333 0.41666667 0.40625    0.40625    0.        ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.         0.375      0.35416667 0.34375    0.34375    0.        ]\n",
      "Test acc: [0.     0.5093 0.512  0.5127 0.511  0.5073 0.51   0.5083 0.507  0.506\n",
      " 0.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_finetune_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 747.91it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1190.55it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 420.48it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.74it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.         0.5        0.5        0.44791667 0.44791667 0.        ]\n",
      "epoch: 0 Val acc: [0.     0.4158 0.3687 0.4653 0.4995 0.5    0.5    0.5    0.5    0.5\n",
      " 0.    ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.         0.47916667 0.5        0.5        0.5        0.        ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.         0.5        0.5        0.5        0.45833333 0.        ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.         0.39583333 0.39583333 0.35416667 0.34375    0.        ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.         0.65625    0.64583333 0.625      0.60416667 0.        ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.         0.55208333 0.45833333 0.39583333 0.36458333 0.        ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.         0.40625    0.47916667 0.5        0.5        0.        ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.         0.5        0.42708333 0.58333333 0.5625     0.        ]\n",
      "epoch: 1 Val acc: [0.     0.2947 0.451  0.5    0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.    ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.      0.65625 0.65625 0.65625 0.65625 0.     ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.         0.41666667 0.38541667 0.375      0.41666667 0.        ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.         0.52083333 0.51041667 0.54166667 0.48958333 0.        ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.         0.70833333 0.66666667 0.71875    0.73958333 0.        ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.         0.60416667 0.5        0.5        0.5        0.        ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.         0.61458333 0.4375     0.38541667 0.45833333 0.        ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.         0.42708333 0.5        0.4375     0.44791667 0.        ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.         0.5        0.5        0.48958333 0.46875    0.        ]\n",
      "epoch: 2 Val acc: [0.     0.3838 0.336  0.2654 0.272  0.3708 0.4229 0.4558 0.4893 0.5\n",
      " 0.    ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.         0.52083333 0.51041667 0.51041667 0.5        0.        ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.         0.51041667 0.46875    0.45833333 0.45833333 0.        ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.         0.66666667 0.64583333 0.60416667 0.57291667 0.        ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.         0.60416667 0.625      0.63541667 0.76041667 0.        ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.         0.77083333 0.72916667 0.72916667 0.70833333 0.        ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.         0.46875    0.4375     0.4375     0.39583333 0.        ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.     0.5    0.5    0.4375 0.5    0.    ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.         0.5        0.5        0.5        0.39583333 0.        ]\n",
      "epoch: 3 Val acc: [0.     0.5    0.5073 0.509  0.504  0.5    0.5    0.5    0.5    0.5\n",
      " 0.    ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.         0.51041667 0.51041667 0.51041667 0.51041667 0.        ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.         0.5625     0.55208333 0.55208333 0.55208333 0.        ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.         0.6875     0.67708333 0.66666667 0.65625    0.        ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.         0.46875    0.47916667 0.54166667 0.54166667 0.        ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.         0.60416667 0.60416667 0.60416667 0.60416667 0.        ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.         0.36458333 0.36458333 0.34375    0.34375    0.        ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.      0.40625 0.40625 0.4375  0.46875 0.     ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.         0.5625     0.59375    0.61458333 0.61458333 0.        ]\n",
      "epoch: 4 Val acc: [0.     0.4268 0.422  0.4238 0.483  0.544  0.592  0.6123 0.6196 0.6206\n",
      " 0.    ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.         0.67708333 0.66666667 0.66666667 0.66666667 0.        ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.         0.375      0.41666667 0.47916667 0.48958333 0.        ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.         0.42708333 0.41666667 0.40625    0.41666667 0.        ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.         0.58333333 0.58333333 0.57291667 0.58333333 0.        ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.         0.32291667 0.3125     0.3125     0.3125     0.        ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.         0.51041667 0.53125    0.57291667 0.58333333 0.        ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.         0.625      0.625      0.625      0.61458333 0.        ]\n",
      "epoch: 5 Val acc: [0.     0.48   0.48   0.4805 0.493  0.528  0.551  0.58   0.6133 0.639\n",
      " 0.    ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.         0.40625    0.42708333 0.4375     0.48958333 0.        ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.         0.57291667 0.60416667 0.625      0.625      0.        ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.         0.57291667 0.57291667 0.5625     0.55208333 0.        ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.         0.48958333 0.38541667 0.34375    0.27083333 0.        ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.         0.51041667 0.5        0.5        0.41666667 0.        ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.         0.42708333 0.42708333 0.42708333 0.4375     0.        ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.         0.625      0.57291667 0.5        0.5        0.        ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.         0.375      0.55208333 0.59375    0.58333333 0.        ]\n",
      "epoch: 6 Val acc: [0.     0.5    0.5    0.5    0.5    0.5464 0.655  0.69   0.7007 0.7124\n",
      " 0.    ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.         0.39583333 0.39583333 0.40625    0.44791667 0.        ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.         0.4375     0.42708333 0.40625    0.375      0.        ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.         0.65625    0.64583333 0.64583333 0.65625    0.        ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.         0.4375     0.57291667 0.60416667 0.54166667 0.        ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.         0.63541667 0.64583333 0.64583333 0.63541667 0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.         0.4375     0.5        0.48958333 0.53125    0.        ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 7 Val acc: [0.     0.4958 0.4758 0.4453 0.4104 0.38   0.348  0.3174 0.2983 0.2795\n",
      " 0.    ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.         0.80208333 0.77083333 0.75       0.67708333 0.        ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.         0.40625    0.42708333 0.44791667 0.45833333 0.        ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.         0.625      0.61458333 0.60416667 0.59375    0.        ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.         0.58333333 0.5625     0.54166667 0.53125    0.        ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.         0.63541667 0.63541667 0.63541667 0.63541667 0.        ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.         0.75       0.73958333 0.71875    0.70833333 0.        ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.         0.42708333 0.42708333 0.4375     0.4375     0.        ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.         0.44791667 0.45833333 0.47916667 0.48958333 0.        ]\n",
      "epoch: 8 Val acc: [0.    0.55  0.55  0.55  0.551 0.558 0.576 0.601 0.621 0.643 0.   ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.         0.5625     0.61458333 0.64583333 0.67708333 0.        ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.         0.5625     0.59375    0.60416667 0.63541667 0.        ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.         0.51041667 0.52083333 0.5        0.5        0.        ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.         0.47916667 0.47916667 0.48958333 0.5        0.        ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.         0.625      0.63541667 0.66666667 0.69791667 0.        ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.         0.57291667 0.57291667 0.57291667 0.57291667 0.        ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.         0.40625    0.40625    0.40625    0.41666667 0.        ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 Val acc: [0.    0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.5   0.497 0.   ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.         0.42708333 0.42708333 0.41666667 0.42708333 0.        ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.         0.625      0.64583333 0.64583333 0.63541667 0.        ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.         0.46875    0.48958333 0.48958333 0.48958333 0.        ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.         0.45833333 0.45833333 0.44791667 0.42708333 0.        ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.  0.5 0.5 0.5 0.5 0. ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.         0.51041667 0.5        0.5        0.51041667 0.        ]\n",
      "Test acc: [0.     0.5    0.5    0.5    0.5    0.5117 0.5747 0.641  0.652  0.624\n",
      " 0.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_finetune_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 121.12it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1146.77it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 390.36it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 36.88it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.4375     0.53125    0.625      0.61458333 0.61458333 0.5625    ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.53125    0.47916667 0.4375     0.4375     0.45833333 0.48958333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.25    0.46875 0.5     0.5     0.5     0.5    ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.60416667 0.73958333 0.6875     0.59375    0.59375    0.59375   ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5        0.55208333 0.61458333 0.61458333 0.61458333 0.61458333]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.5    0.5    0.4375 0.5    0.5    0.5   ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5        0.5        0.61458333 0.58333333 0.5        0.5       ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.64583333 0.67708333 0.75       0.69791667 0.69791667 0.69791667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.38541667 0.52083333 0.48958333 0.48958333 0.48958333 0.48958333]\n",
      "epoch: 1 Val acc: [0.4988 0.582  0.5625 0.5356 0.5225 0.5093 0.5044 0.5    0.497  0.497\n",
      " 0.4958]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.34375    0.38541667 0.375      0.375      0.375      0.38541667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.57291667 0.66666667 0.67708333 0.57291667 0.57291667 0.57291667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.45833333 0.60416667 0.53125    0.53125    0.54166667 0.53125   ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5        0.60416667 0.625      0.64583333 0.67708333 0.65625   ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.57291667 0.64583333 0.5        0.45833333 0.45833333 0.45833333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.36458333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.71875    0.71875    0.69791667 0.69791667 0.69791667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.5        0.5        0.55208333 0.60416667 0.58333333 0.61458333]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5        0.5        0.67708333 0.69791667 0.78125    0.85416667]\n",
      "epoch: 2 Val acc: [0.5    0.5005 0.538  0.5825 0.573  0.553  0.537  0.5435 0.5366 0.567\n",
      " 0.5596]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.625      0.59375    0.57291667 0.55208333 0.5625    ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.875      0.76041667 0.65625    0.64583333 0.64583333]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.40625    0.38541667 0.5625     0.5625     0.58333333]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.47916667 0.55208333 0.52083333 0.51041667 0.51041667 0.51041667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.75 0.5  0.5  0.5  0.5  0.5 ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.64583333 0.5        0.52083333 0.5625     0.58333333 0.59375   ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.54166667 0.53125    0.53125    0.59375    0.55208333 0.55208333]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.46875    0.58333333 0.66666667 0.67708333 0.69791667 0.69791667]\n",
      "epoch: 3 Val acc: [0.4692 0.4495 0.4758 0.4983 0.502  0.5073 0.51   0.5127 0.5146 0.5195\n",
      " 0.5215]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.45833333 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.5625     0.59375    0.59375    0.54166667 0.57291667]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.51041667 0.65625    0.61458333 0.61458333 0.69791667 0.70833333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.66666667 0.60416667 0.61458333 0.63541667 0.6875    ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.44791667 0.53125    0.44791667 0.54166667 0.54166667 0.54166667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.54166667 0.51041667 0.5625     0.67708333 0.5625     0.625     ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.67708333 0.67708333 0.67708333 0.71875    0.76041667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.5        0.5        0.51041667 0.54166667 0.60416667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.51041667 0.75       0.70833333 0.77083333 0.73958333 0.77083333]\n",
      "epoch: 4 Val acc: [0.5    0.544  0.567  0.571  0.5825 0.5845 0.5903 0.5923 0.597  0.6035\n",
      " 0.6123]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.42708333 0.55208333 0.5625     0.5625     0.5625     0.55208333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.39583333 0.55208333 0.83333333 0.79166667 0.59375    0.8125    ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.66666667 0.86458333 0.76041667 0.61458333 0.61458333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.45833333 0.66666667 0.6875     0.69791667 0.67708333 0.69791667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.5        0.57291667 0.71875    0.72916667 0.83333333]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.46875    0.625      0.625      0.60416667 0.59375    0.58333333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.5        0.59375    0.59375    0.59375    0.61458333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.67708333 0.6875     0.72916667 0.73958333 0.64583333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.61458333 0.64583333 0.5625     0.57291667 0.57291667]\n",
      "epoch: 5 Val acc: [0.5    0.4646 0.4346 0.4766 0.518  0.5376 0.5425 0.533  0.5454 0.561\n",
      " 0.566 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.42708333 0.51041667 0.48958333 0.51041667 0.52083333 0.54166667]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.52083333 0.61458333 0.64583333 0.63541667 0.64583333 0.64583333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.36458333 0.4375     0.54166667 0.58333333 0.64583333 0.64583333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.625      0.70833333 0.71875    0.72916667 0.77083333 0.66666667]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.47916667 0.44791667 0.47916667 0.65625    0.64583333 0.65625   ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.63541667 0.69791667 0.6875     0.66666667 0.64583333 0.64583333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.39583333 0.46875    0.55208333 0.61458333 0.6875     0.67708333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.16666667 0.5        0.5        0.5625     0.59375    0.625     ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.57291667 0.60416667 0.64583333 0.65625    0.65625   ]\n",
      "epoch: 6 Val acc: [0.508  0.5273 0.536  0.5527 0.564  0.577  0.586  0.5913 0.5967 0.5977\n",
      " 0.601 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.3125     0.5625     0.625      0.65625    0.61458333 0.69791667]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.38541667 0.59375    0.57291667 0.78125    0.66666667]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.53125    0.55208333 0.64583333 0.64583333 0.65625    0.67708333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.36458333 0.35416667 0.52083333 0.59375    0.51041667 0.55208333]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.71875    0.83333333 0.83333333 0.83333333 0.875     ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.59375    0.55208333 0.53125    0.52083333 0.52083333 0.57291667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.77083333 0.73958333 0.71875    0.72916667 0.73958333 0.73958333]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.60416667 0.72916667 0.73958333 0.76041667 0.73958333 0.77083333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.65625    0.80208333 0.84375    0.86458333 0.86458333 0.86458333]\n",
      "epoch: 7 Val acc: [0.5234 0.5015 0.5127 0.531  0.55   0.56   0.563  0.558  0.5654 0.571\n",
      " 0.575 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.36458333 0.46875    0.54166667 0.67708333 0.75       0.70833333]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.38541667 0.57291667 0.5625     0.57291667 0.57291667 0.60416667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.46875    0.54166667 0.55208333 0.5625     0.5625     0.64583333]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.6875     0.79166667 0.78125    0.79166667 0.85416667 0.86458333]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.30208333 0.625      0.70833333 0.73958333 0.85416667 0.78125   ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.6875     0.76041667 0.80208333 0.8125     0.84375    0.875     ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.32291667 0.76041667 0.70833333 0.82291667 0.88541667 0.82291667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.46875    0.71875    0.82291667 0.875      0.90625    0.90625   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.22916667 0.67708333 0.72916667 0.77083333 0.79166667 0.78125   ]\n",
      "epoch: 8 Val acc: [0.4988 0.4783 0.487  0.4983 0.5    0.5186 0.5234 0.548  0.547  0.561\n",
      " 0.5693]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.36458333 0.32291667 0.3125     0.35416667 0.51041667 0.73958333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.20833333 0.35416667 0.625      0.69791667 0.71875    0.71875   ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.39583333 0.41666667 0.54166667 0.63541667 0.65625    0.65625   ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.72916667 0.71875    0.72916667 0.71875    0.71875    0.71875   ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.34375    0.61458333 0.65625    0.67708333 0.6875     0.67708333]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.61458333 0.69791667 0.70833333 0.71875    0.79166667 0.78125   ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.625      0.76041667 0.89583333 0.875      0.88541667 0.86458333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.63541667 0.73958333 0.77083333 0.78125    0.84375    0.88541667]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.35416667 0.76041667 0.76041667 0.76041667 0.84375    0.79166667]\n",
      "epoch: 9 Val acc: [0.508  0.5215 0.581  0.6323 0.6353 0.619  0.6104 0.6265 0.6323 0.639\n",
      " 0.6426]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.83333333 0.84375    0.84375    0.84375    0.95833333 0.96875   ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.53125    0.75       0.76041667 0.82291667 0.8125     0.85416667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.26041667 0.55208333 0.45833333 0.48958333 0.45833333 0.46875   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.38541667 0.77083333 0.75       0.77083333 0.77083333 0.80208333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.47916667 0.79166667 0.85416667 0.85416667 0.85416667 0.85416667]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.58333333 0.54166667 0.52083333 0.55208333 0.5        0.52083333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.48958333 0.58333333 0.73958333 0.76041667 0.66666667 0.71875   ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.4375     0.58333333 0.61458333 0.57291667 0.60416667 0.58333333]\n",
      "Test acc: [0.4978 0.5225 0.6123 0.627  0.6523 0.6704 0.723  0.7124 0.7393 0.7124\n",
      " 0.7407]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 547.06it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 924.26it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 353.51it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.20it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.46875    0.53125    0.58333333 0.61458333 0.65625    0.65625   ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.65625    0.73958333 0.76041667 0.72916667 0.70833333 0.65625   ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.45833333 0.45833333 0.53125    0.61458333 0.60416667 0.63541667]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.44791667 0.61458333 0.55208333 0.52083333 0.5        0.5       ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5        0.76041667 0.65625    0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.27083333 0.27083333 0.33333333 0.44791667 0.47916667 0.47916667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.26041667 0.38541667 0.5625     0.61458333 0.61458333 0.58333333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.41666667 0.52083333 0.5        0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.45833333 0.45833333 0.48958333 0.5        0.5        0.5       ]\n",
      "epoch: 1 Val acc: [0.5    0.5156 0.546  0.53   0.5146 0.523  0.5156 0.504  0.502  0.5015\n",
      " 0.506 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.64583333 0.65625    0.70833333 0.69791667 0.69791667 0.67708333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.57291667 0.5        0.4375     0.4375     0.41666667 0.42708333]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.25       0.36458333 0.44791667 0.46875    0.45833333 0.46875   ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.29166667 0.40625    0.64583333 0.58333333 0.63541667 0.63541667]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.57291667 0.83333333 0.79166667 0.77083333 0.76041667 0.76041667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.60416667 0.80208333 0.69791667 0.73958333 0.63541667 0.79166667]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.47916667 0.48958333 0.52083333 0.57291667 0.59375   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.5        0.54166667 0.67708333 0.77083333 0.875      0.88541667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5        0.66666667 0.5        0.52083333 0.46875    0.55208333]\n",
      "epoch: 2 Val acc: [0.4736 0.6523 0.597  0.6367 0.6665 0.5854 0.68   0.659  0.709  0.663\n",
      " 0.706 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.51041667 0.63541667 0.58333333 0.58333333 0.59375   ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.45833333 0.46875    0.61458333 0.65625    0.59375    0.53125   ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.625      0.67708333 0.70833333 0.69791667 0.70833333 0.76041667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.72916667 0.79166667 0.72916667 0.72916667 0.73958333 0.72916667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.5        0.54166667 0.55208333 0.58333333 0.5625    ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.57291667 0.57291667 0.57291667 0.59375    0.60416667 0.60416667]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.51041667 0.57291667 0.625      0.63541667 0.625     ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.60416667 0.82291667 0.82291667 0.88541667 0.83333333]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.58333333 0.63541667 0.57291667 0.5625     0.53125    0.51041667]\n",
      "epoch: 3 Val acc: [0.4858 0.5596 0.602  0.6196 0.6772 0.727  0.7593 0.744  0.7495 0.748\n",
      " 0.7427]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.42708333 0.42708333 0.51041667 0.54166667 0.51041667 0.52083333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.45833333 0.5625     0.70833333 0.84375    0.82291667 0.83333333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.25       0.6875     0.76041667 0.80208333 0.85416667 0.85416667]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.57291667 0.5        0.55208333 0.57291667 0.63541667 0.5625    ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.5        0.5        0.5        0.48958333 0.5       ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.73958333 0.5        0.59375    0.53125    0.57291667 0.57291667]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.58333333 0.66666667 0.5625     0.46875    0.5       ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.45833333 0.65625    0.72916667 0.73958333 0.73958333 0.73958333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.5        0.5        0.51041667 0.57291667 0.61458333]\n",
      "epoch: 4 Val acc: [0.4624 0.567  0.6035 0.6226 0.6562 0.6943 0.6997 0.7036 0.7017 0.7\n",
      " 0.7   ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.41666667 0.5625     0.72916667 0.78125    0.75       0.70833333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.57291667 0.71875    0.75       0.71875    0.70833333 0.71875   ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.41666667 0.46875    0.67708333 0.6875     0.69791667 0.67708333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.5        0.48958333 0.5        0.58333333 0.65625   ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.65625    0.71875    0.77083333 0.8125     0.8125    ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.71875    0.5625     0.61458333 0.64583333 0.70833333 0.70833333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.53125    0.5        0.5        0.58333333 0.5        0.52083333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.58333333 0.55208333 0.38541667 0.48958333 0.4375     0.57291667]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.58333333 0.41666667 0.5        0.46875    0.58333333 0.5625    ]\n",
      "epoch: 5 Val acc: [0.507  0.5576 0.567  0.576  0.581  0.595  0.5986 0.625  0.615  0.617\n",
      " 0.6216]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.64583333 0.5        0.5        0.55208333 0.61458333 0.58333333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.34375    0.6875     0.72916667 0.69791667 0.69791667 0.6875    ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.63541667 0.67708333 0.625      0.5625     0.55208333 0.54166667]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5     0.5     0.5     0.5     0.5     0.53125]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.54166667 0.48958333 0.45833333 0.40625    0.39583333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5     0.5     0.5     0.5     0.5     0.46875]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.59375    0.64583333 0.60416667 0.61458333 0.625      0.625     ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.58333333 0.66666667 0.63541667 0.65625    0.66666667 0.69791667]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.375      0.58333333 0.55208333 0.54166667 0.54166667 0.55208333]\n",
      "epoch: 6 Val acc: [0.4907 0.6313 0.637  0.6104 0.598  0.5957 0.6104 0.6343 0.6436 0.6523\n",
      " 0.666 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.3125     0.5625     0.60416667 0.60416667 0.60416667 0.61458333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.59375    0.76041667 0.60416667 0.78125    0.67708333 0.66666667]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.52083333 0.77083333 0.71875    0.6875     0.72916667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.30208333 0.39583333 0.46875    0.53125    0.61458333]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.40625    0.6875     0.69791667 0.66666667 0.65625   ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.38541667 0.66666667 0.69791667 0.71875    0.73958333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.5        0.47916667 0.57291667 0.57291667 0.64583333]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.52083333 0.3125     0.32291667 0.33333333 0.34375   ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.48958333 0.65625    0.71875    0.76041667 0.78125    0.78125   ]\n",
      "epoch: 7 Val acc: [0.503  0.4612 0.6167 0.6885 0.734  0.739  0.7534 0.75   0.7573 0.756\n",
      " 0.753 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.5625     0.625      0.6875     0.70833333 0.71875   ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.34375    0.5625     0.67708333 0.67708333 0.65625    0.65625   ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.57291667 0.63541667 0.72916667 0.70833333 0.71875   ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.36458333 0.6875     0.89583333 0.97916667 0.91666667 0.94791667]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5        0.60416667 0.77083333 0.83333333 0.84375    0.84375   ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.58333333 0.58333333 0.66666667 0.64583333 0.59375    0.60416667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5        0.78125    0.90625    0.96875    0.95833333 0.95833333]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.44791667 0.48958333 0.625      0.67708333 0.77083333 0.77083333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.45833333 0.78125    0.8125     0.79166667 0.88541667]\n",
      "epoch: 8 Val acc: [0.464  0.488  0.53   0.5327 0.5186 0.565  0.605  0.657  0.684  0.673\n",
      " 0.6953]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.4375     0.54166667 0.54166667 0.55208333 0.55208333 0.60416667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.54166667 0.70833333 0.77083333 0.83333333 0.8125     0.80208333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.57291667 0.92708333 0.92708333 0.92708333 0.92708333 0.92708333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.71875    0.8125     0.9375     0.89583333 0.89583333 0.89583333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.58333333 0.86458333 0.82291667 0.88541667 0.88541667 0.88541667]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.40625    0.66666667 0.80208333 0.75       0.8125     0.70833333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.76041667 0.78125    0.77083333 0.8125     0.77083333 0.8125    ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.82291667 0.78125    0.875      0.90625    0.89583333]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.17708333 0.36458333 0.69791667 0.69791667 0.65625    0.65625   ]\n",
      "epoch: 9 Val acc: [0.5215 0.527  0.6353 0.6196 0.6777 0.6533 0.685  0.6597 0.687  0.6665\n",
      " 0.69  ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5625     0.73958333 0.85416667 0.90625    0.92708333 0.91666667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.44791667 0.52083333 0.64583333 0.64583333 0.65625    0.66666667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.22916667 0.23958333 0.39583333 0.55208333 0.64583333 0.71875   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.25       0.5        0.53125    0.53125    0.57291667 0.5625    ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.3125     0.77083333 0.80208333 0.86458333 0.86458333 0.90625   ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.58333333 0.64583333 0.67708333 0.82291667 0.70833333 0.80208333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.45833333 0.69791667 0.88541667 0.92708333 0.85416667 0.91666667]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.48958333 0.59375    0.53125    0.60416667 0.52083333 0.625     ]\n",
      "Test acc: [0.4963 0.9805 0.991  0.9927 0.9927 0.9927 0.991  0.9917 0.9917 0.992\n",
      " 0.992 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 725.16it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1175.86it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 409.46it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 34.56it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.54166667 0.61458333 0.8125     0.78125    0.73958333 0.71875   ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.42708333 0.42708333 0.38541667 0.34375    0.3125     0.35416667]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.38541667 0.33333333 0.54166667 0.58333333 0.625      0.625     ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.5        0.51041667 0.5        0.51041667 0.5        0.5       ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.625      0.61458333 0.58333333 0.59375    0.5625     0.58333333]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.51041667 0.6875     0.65625    0.63541667 0.63541667 0.60416667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.38541667 0.45833333 0.52083333 0.5625     0.57291667 0.58333333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.35416667 0.35416667 0.42708333 0.46875    0.58333333 0.60416667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.30208333 0.30208333 0.33333333 0.40625    0.48958333 0.54166667]\n",
      "epoch: 1 Val acc: [0.5107 0.55   0.5713 0.5796 0.5835 0.589  0.5884 0.5845 0.581  0.575\n",
      " 0.569 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.75       0.6875     0.64583333 0.625      0.60416667 0.57291667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.53125    0.57291667 0.47916667 0.45833333 0.52083333 0.54166667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5        0.52083333 0.625      0.61458333 0.625      0.65625   ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.61458333 0.71875    0.55208333 0.58333333 0.57291667 0.57291667]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5        0.5        0.5        0.44791667 0.5        0.5       ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.73958333 0.5        0.5        0.60416667 0.5        0.5       ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.5        0.53125    0.5625     0.58333333 0.58333333]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.5        0.85416667 0.75       0.86458333 0.71875    0.73958333]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5        0.47916667 0.5        0.5        0.5        0.5       ]\n",
      "epoch: 2 Val acc: [0.5    0.514  0.554  0.5312 0.5386 0.533  0.519  0.524  0.5215 0.53\n",
      " 0.5303]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.5        0.5        0.57291667 0.5        0.52083333]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.40625    0.73958333 0.72916667 0.73958333 0.76041667 0.76041667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.48958333 0.45833333 0.59375    0.64583333 0.67708333 0.76041667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5   0.5   0.5   0.75  0.75  0.875]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5        0.48958333 0.55208333 0.63541667 0.75       0.71875   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.6875     0.79166667 0.88541667 0.83333333 0.82291667]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.61458333 0.69791667 0.84375    0.82291667 0.83333333]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5        0.72916667 0.70833333 0.76041667 0.75       0.75      ]\n",
      "epoch: 3 Val acc: [0.5    0.4736 0.505  0.5728 0.5806 0.6025 0.64   0.6514 0.692  0.696\n",
      " 0.707 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.84375    0.875      0.84375    0.85416667 0.86458333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.51041667 0.70833333 0.67708333 0.69791667 0.76041667]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.83333333 0.85416667 0.90625    0.89583333 0.90625   ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.8125     0.875      0.875      0.88541667 0.97916667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.71875    0.94791667 0.96875    0.9375     0.95833333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.5        0.96875    0.9375     0.9375     0.92708333]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.51041667 0.61458333 0.75       0.70833333 0.73958333 0.73958333]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.66666667 0.72916667 0.72916667 0.76041667 0.75      ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.44791667 0.59375    0.625      0.64583333 0.82291667]\n",
      "epoch: 4 Val acc: [0.5    0.505  0.558  0.5728 0.6206 0.639  0.682  0.6904 0.71   0.723\n",
      " 0.7314]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.72916667 0.77083333 0.88541667 0.77083333 0.88541667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.75       0.9375     0.9375     0.94791667 0.9375    ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.625      0.66666667 0.67708333 0.6875     0.69791667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.57291667 0.6875     0.625      0.71875    0.65625   ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.52083333 0.59375    0.63541667 0.69791667 0.84375    0.82291667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.67708333 0.625      0.65625    0.61458333 0.6875    ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.41666667 0.61458333 0.625      0.625      0.625     ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.57291667 0.65625    0.53125    0.65625    0.60416667]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.51041667 0.70833333 0.875      1.         1.         0.9375    ]\n",
      "epoch: 5 Val acc: [0.5    0.5513 0.675  0.746  0.7583 0.7524 0.747  0.7427 0.7427 0.745\n",
      " 0.741 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.75       0.875      0.9375     0.91666667 0.875     ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.70833333 0.61458333 0.63541667 0.61458333 0.63541667]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.75       0.70833333 0.91666667 0.80208333 0.78125   ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.46875    0.28125    0.64583333 0.71875    0.88541667 0.72916667]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.64583333 0.76041667 0.80208333 0.82291667 0.80208333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.53125    0.63541667 0.83333333 0.78125    0.875      0.82291667]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.67708333 0.79166667 0.9375     0.90625    0.9375    ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.39583333 0.5        0.59375    0.625      0.625      0.59375   ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.55208333 0.48958333 0.67708333 0.65625    0.66666667]\n",
      "epoch: 6 Val acc: [0.5    0.557  0.6187 0.7344 0.7373 0.747  0.7534 0.7505 0.754  0.7485\n",
      " 0.7515]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.69791667 0.97916667 0.97916667 0.96875    0.96875   ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.42708333 0.58333333 0.92708333 0.90625    0.90625    0.91666667]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.61458333 0.80208333 0.6875     0.76041667 0.80208333 0.82291667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.58333333 0.79166667 0.8125     0.77083333 0.77083333 0.78125   ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.51041667 0.70833333 0.84375    0.82291667 0.91666667 0.90625   ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.61458333 0.61458333 0.82291667 0.77083333 0.8125     0.76041667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.75       0.78125    0.90625    0.92708333 0.94791667 0.91666667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.51041667 0.86458333 0.875      0.98958333 0.98958333 0.97916667]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.53125    0.58333333 0.57291667 0.64583333 0.66666667]\n",
      "epoch: 7 Val acc: [0.5    0.5464 0.569  0.7095 0.647  0.7334 0.7065 0.733  0.731  0.737\n",
      " 0.7153]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.44791667 0.46875    0.55208333 0.45833333 0.48958333 0.46875   ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.60416667 0.625      0.73958333 0.71875    0.69791667 0.66666667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.51041667 0.55208333 0.5625     0.5625     0.59375    0.5625    ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.28125    0.625      0.85416667 0.84375    0.84375    0.88541667]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.39583333 0.67708333 0.79166667 0.83333333 0.77083333 0.8125    ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.47916667 0.82291667 0.84375    0.875      0.84375    0.91666667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.375      0.5625     0.83333333 0.8125     0.84375    0.85416667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.14583333 0.45833333 0.78125    0.86458333 0.875      0.90625   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.21875    0.5625     0.73958333 0.84375    0.8125     0.84375   ]\n",
      "epoch: 8 Val acc: [0.533  0.6094 0.669  0.695  0.7227 0.7446 0.735  0.7373 0.717  0.727\n",
      " 0.7183]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.4375     0.98958333 0.94791667 0.92708333 0.9375     0.92708333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.51041667 0.66666667 0.64583333 0.63541667 0.66666667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.5        0.8125     1.         0.98958333 1.         1.        ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.67708333 0.625      0.67708333 0.61458333 0.78125   ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.72916667 0.77083333 0.80208333 0.78125    0.79166667]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5        0.65625    0.625      0.63541667 0.64583333 0.73958333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5        0.75       0.75       0.83333333 0.78125    0.86458333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.65625    0.71875    0.875      0.76041667 0.875      0.77083333]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5625     0.8125     0.86458333 0.82291667 0.83333333 0.79166667]\n",
      "epoch: 9 Val acc: [0.4941 0.55   0.673  0.6875 0.712  0.732  0.732  0.73   0.7256 0.7354\n",
      " 0.723 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.48958333 0.69791667 0.72916667 0.67708333 0.66666667 0.625     ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.72916667 0.89583333 0.89583333 0.88541667 0.89583333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.75       0.94791667 0.92708333 0.96875    0.96875   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.35416667 0.97916667 0.90625    0.96875    0.98958333 0.98958333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.67708333 0.61458333 0.65625    0.6875     0.78125    0.89583333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.67708333 0.96875    0.97916667 0.98958333 0.98958333 0.98958333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.61458333 0.73958333 0.76041667 0.75       0.75       0.75      ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.42708333 0.5        0.6875     0.57291667 0.71875    0.70833333]\n",
      "Test acc: [0.4805 0.997  0.9976 0.9976 0.9976 0.997  0.9966 0.9966 0.996  0.996\n",
      " 0.996 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 550.65it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 904.63it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 384.81it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 36.94it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.58333333 0.73958333 0.85416667 0.84375    0.79166667 0.75      ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.52083333 0.52083333 0.55208333 0.57291667 0.58333333 0.60416667]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.25       0.25       0.40625    0.46875    0.48958333 0.48958333]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.52083333 0.64583333 0.65625    0.5625     0.51041667 0.5       ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.47916667 0.625      0.60416667 0.59375    0.60416667 0.61458333]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.375      0.39583333 0.51041667 0.52083333 0.52083333 0.52083333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.54166667 0.64583333 0.53125    0.53125    0.52083333 0.52083333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.35416667 0.46875    0.53125    0.48958333 0.51041667 0.47916667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 Val acc: [0.5    0.5    0.5034 0.524  0.533  0.522  0.535  0.506  0.5093 0.514\n",
      " 0.5063]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.5        0.625      0.55208333 0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.45833333 0.5        0.5        0.48958333 0.4375     0.5       ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5        0.52083333 0.5        0.5625     0.5        0.5       ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.52083333 0.52083333 0.52083333 0.52083333 0.52083333]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.48958333 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5        0.5        0.57291667 0.5        0.5        0.5       ]\n",
      "epoch: 2 Val acc: [0.5    0.5015 0.4988 0.4946 0.4954 0.5054 0.501  0.4995 0.4995 0.4995\n",
      " 0.4993]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.125 0.5   0.5   0.5   0.5   0.5  ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.54166667 0.54166667 0.46875    0.47916667 0.5        0.5       ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.54166667 0.67708333 0.69791667 0.72916667 0.77083333 0.77083333]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5        0.53125    0.61458333 0.69791667 0.85416667 0.70833333]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.5        0.5        0.66666667 0.69791667 0.72916667]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5        0.52083333 0.47916667 0.44791667 0.55208333 0.53125   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.53125    0.61458333 0.60416667 0.67708333 0.67708333]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.72916667 0.86458333 0.875      0.875      0.875     ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5        0.5        0.77083333 0.79166667 0.84375    0.78125   ]\n",
      "epoch: 3 Val acc: [0.5    0.5    0.555  0.6826 0.7417 0.7173 0.7803 0.7495 0.7876 0.77\n",
      " 0.7856]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.72916667 0.625      0.71875    0.78125    0.78125   ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.375      0.44791667 0.46875    0.64583333 0.59375   ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.61458333 0.85416667 0.98958333 0.97916667 0.98958333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.63541667 0.85416667 0.96875    0.97916667 0.94791667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.79166667 0.82291667 0.78125    0.86458333 0.83333333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5   0.875 1.    1.    1.    1.   ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.63541667 0.8125     0.84375    0.86458333 0.91666667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.60416667 0.78125    0.76041667 0.88541667 0.82291667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.48958333 0.63541667 0.80208333 0.79166667 0.78125   ]\n",
      "epoch: 4 Val acc: [0.5    0.522  0.598  0.598  0.675  0.6914 0.706  0.7295 0.731  0.755\n",
      " 0.7617]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.5625     0.72916667 0.72916667 0.72916667 0.67708333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.9375     0.92708333 0.95833333 0.95833333 0.95833333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.67708333 0.75       0.73958333 0.86458333 0.8125    ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.54166667 0.5        0.59375    0.72916667 0.58333333]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.5        0.48958333 0.42708333 0.42708333 0.4375    ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.64583333 0.79166667 0.8125     0.79166667 0.80208333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.875      0.91666667 0.90625    0.91666667 0.91666667]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.85416667 0.85416667 0.82291667 0.82291667 0.8125    ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.69791667 0.83333333 0.82291667 0.85416667 0.9375    ]\n",
      "epoch: 5 Val acc: [0.5    0.4978 0.589  0.6353 0.642  0.6694 0.66   0.642  0.661  0.692\n",
      " 0.6797]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.71875    0.76041667 0.86458333 0.875      0.875     ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.54166667 0.75       0.83333333 0.6875     0.71875   ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.625      0.72916667 0.69791667 0.72916667 0.73958333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.5        1.         1.         1.         0.98958333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.71875    0.73958333 0.72916667 0.80208333 0.77083333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.61458333 0.83333333 0.8125     0.89583333 0.85416667]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.5        0.76041667 0.76041667 0.83333333 0.76041667]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.5        0.73958333 0.73958333 0.77083333 0.80208333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.44791667 0.72916667 0.75       0.75       0.86458333]\n",
      "epoch: 6 Val acc: [0.5    0.5005 0.5864 0.6543 0.776  0.778  0.794  0.785  0.791  0.7817\n",
      " 0.784 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.57291667 0.5        0.54166667 0.54166667 0.71875   ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.45833333 0.55208333 0.54166667 0.72916667 0.89583333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.625      0.71875    0.61458333 0.65625    0.625     ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.5        0.54166667 0.5        0.5        0.46875   ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.45833333 0.75       0.73958333 0.80208333 0.82291667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.5        0.5625     0.70833333 0.77083333 0.90625   ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.58333333 0.45833333 0.625      0.6875     0.75      ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.78125    0.875      0.875      0.86458333 0.875     ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.625      0.54166667 0.625      0.61458333 0.61458333]\n",
      "epoch: 7 Val acc: [0.5    0.5127 0.5703 0.6343 0.663  0.6665 0.6665 0.6826 0.718  0.7485\n",
      " 0.7446]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.625      0.70833333 0.8125     0.84375    0.84375   ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.69791667 0.5625     0.63541667 0.61458333 0.63541667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.71875    0.78125    0.75       0.80208333 0.79166667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.67708333 0.67708333 0.78125    0.69791667 0.8125    ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5        0.625      0.80208333 0.82291667 0.78125    0.83333333]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5        0.66666667 0.875      0.80208333 0.8125     0.82291667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5        0.54166667 0.64583333 0.67708333 0.78125    0.75      ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.8125     0.85416667 0.85416667 0.86458333 0.86458333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.71875    0.64583333 0.8125     0.79166667 0.8125    ]\n",
      "epoch: 8 Val acc: [0.5    0.6265 0.7046 0.7886 0.8076 0.8105 0.8047 0.7993 0.7935 0.7935\n",
      " 0.785 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.73958333 0.75       0.80208333 0.71875    0.73958333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.48958333 0.5        0.625      0.48958333 0.63541667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.5        0.71875    0.76041667 0.75       0.85416667 0.71875   ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.44791667 0.72916667 0.73958333 0.67708333 0.89583333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5     0.9375  0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5        0.625      0.76041667 0.67708333 0.84375    0.69791667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5        0.5        0.76041667 0.76041667 0.76041667 0.76041667]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.5        0.84375    0.85416667 0.75       0.82291667]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.61458333 0.8125     0.8125     0.83333333 0.8125    ]\n",
      "epoch: 9 Val acc: [0.5    0.5786 0.663  0.723  0.7095 0.7456 0.745  0.7515 0.755  0.755\n",
      " 0.7456]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.83333333 0.94791667 0.90625    0.85416667 0.85416667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.71875    0.97916667 0.98958333 0.98958333 0.98958333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.40625    0.52083333 0.46875    0.52083333 0.46875   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.66666667 0.8125     0.84375    0.84375    0.85416667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.5        0.66666667 0.6875     0.83333333 0.85416667 0.84375   ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5        0.82291667 0.92708333 0.95833333 0.96875    0.96875   ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.55208333 0.625      0.85416667 0.73958333 0.90625    0.83333333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5        0.70833333 0.77083333 0.8125     0.8125     0.83333333]\n",
      "Test acc: [0.5    0.5    0.522  0.49   0.4963 0.508  0.5044 0.4963 0.518  0.51\n",
      " 0.524 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 602.80it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 935.39it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 390.67it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.16it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.4893 0.427\n",
      " 0.385 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.48958333 0.48958333 0.48958333 0.47916667 0.47916667 0.48958333]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.46875    0.4375     0.39583333 0.38541667 0.375      0.46875   ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.36458333 0.4375     0.47916667 0.5        0.5        0.51041667]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.67708333 0.66666667 0.63541667 0.58333333 0.60416667 0.66666667]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.45833333 0.5625     0.5        0.57291667 0.58333333 0.58333333]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.5     0.5     0.5     0.53125 0.625   0.6875 ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.55208333 0.61458333 0.65625    0.60416667 0.59375    0.60416667]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.625      0.60416667 0.59375    0.59375    0.63541667 0.64583333]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.47916667 0.48958333 0.48958333 0.47916667 0.48958333 0.48958333]\n",
      "epoch: 1 Val acc: [0.51   0.6514 0.737  0.7256 0.6885 0.663  0.647  0.627  0.6006 0.5938\n",
      " 0.591 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.67708333 0.60416667 0.60416667 0.64583333 0.61458333 0.61458333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.375 0.5   0.5   0.5   0.5   0.5  ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.6875     0.65625    0.52083333 0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5        0.69791667 0.54166667 0.54166667 0.5        0.5       ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.17708333 0.53125    0.58333333 0.58333333 0.5        0.5       ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5        0.375      0.5        0.5        0.5        0.51041667]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.61458333 0.60416667 0.59375    0.57291667 0.58333333]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.60416667 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 2 Val acc: [0.5    0.639  0.504  0.51   0.5044 0.521  0.5312 0.551  0.5654 0.59\n",
      " 0.604 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.5        0.5        0.61458333 0.57291667 0.48958333]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.5        0.5        0.44791667 0.40625    0.47916667]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.5        0.60416667 0.5        0.5        0.54166667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.22916667 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.70833333 0.67708333 0.67708333 0.66666667 0.66666667 0.65625   ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.45833333 0.33333333 0.34375    0.39583333 0.44791667 0.47916667]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.51041667 0.625      0.5        0.52083333 0.52083333]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 Val acc: [0.5    0.5    0.5835 0.674  0.637  0.6255 0.635  0.6606 0.692  0.734\n",
      " 0.7656]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.51041667 0.60416667 0.72916667 0.66666667 0.69791667]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.48958333 0.48958333 0.4375     0.35416667 0.39583333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.42708333 0.41666667 0.38541667 0.375      0.40625   ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.625      0.625      0.63541667 0.70833333 0.73958333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.51041667 0.53125    0.625      0.60416667 0.69791667 0.71875   ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.3125     0.38541667 0.42708333 0.48958333 0.67708333 0.66666667]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.5        0.57291667 0.57291667 0.72916667 0.72916667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.5        0.5        0.76041667 0.76041667 0.79166667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5     0.5     0.5     0.5     0.5625  0.53125]\n",
      "epoch: 4 Val acc: [0.5    0.5    0.6323 0.7896 0.833  0.9043 0.946  0.993  0.9824 0.9937\n",
      " 0.9873]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.5        0.58333333 0.54166667 0.5625     0.48958333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.5        0.65625    0.8125     0.94791667 0.94791667]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.57291667 0.66666667 0.75       0.85416667 0.79166667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.5625     0.63541667 0.78125    0.77083333 0.77083333]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.76041667 0.92708333 0.94791667 0.95833333 0.95833333]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.625      0.65625    0.60416667 0.63541667 0.61458333 0.67708333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.625      0.70833333 0.77083333 0.73958333 0.75      ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.65625    0.67708333 0.73958333 0.76041667 0.75      ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.63541667 0.64583333 0.64583333 0.625      0.64583333]\n",
      "epoch: 5 Val acc: [0.5    0.9966 1.     1.     1.     0.999  0.999  0.999  0.999  0.9985\n",
      " 0.9985]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.625      0.63541667 0.79166667 0.76041667 0.79166667]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.51041667 0.73958333 0.73958333 0.72916667 0.73958333 0.75      ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.59375    0.77083333 0.75       0.77083333 0.88541667]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.83333333 0.90625    0.91666667 0.83333333 0.85416667]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.64583333 0.625      0.58333333 0.80208333 0.78125   ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.84375    0.85416667 0.86458333 0.8125     0.85416667]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.59375    0.65625    0.63541667 0.70833333 0.6875    ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5     0.65625 0.96875 1.      1.      1.     ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.78125    0.73958333 0.85416667 0.875      0.86458333]\n",
      "epoch: 6 Val acc: [0.5    0.828  0.996  0.9985 0.9985 0.9985 0.9985 0.9985 0.9985 0.9985\n",
      " 0.9985]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.60416667 0.61458333 0.63541667 0.63541667 0.60416667]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.36458333 0.76041667 0.76041667 0.85416667 0.75       0.83333333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.52083333 0.70833333 0.82291667 0.82291667 0.8125     0.83333333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.6875     0.76041667 0.73958333 0.73958333 0.72916667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.63541667 0.79166667 0.88541667 0.83333333 0.9375    ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.625      0.69791667 0.72916667 0.8125     0.75      ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.55208333 0.72916667 0.75       0.79166667 0.85416667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.625      0.75       0.75       0.79166667 0.77083333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.5        0.66666667 0.73958333 0.73958333 0.75      ]\n",
      "epoch: 7 Val acc: [0.5    0.6855 1.     1.     1.     0.9995 0.9995 0.9995 0.9995 0.999\n",
      " 0.999 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.48958333 0.66666667 0.78125    0.76041667 0.82291667]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.5625     0.63541667 0.625      0.64583333 0.70833333]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.64583333 0.72916667 0.76041667 0.75       0.84375   ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.55208333 0.86458333 0.82291667 0.85416667 0.84375    0.85416667]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.46875    0.72916667 0.79166667 0.83333333 0.8125     0.8125    ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.375      0.625      0.67708333 0.71875    0.69791667 0.72916667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.34375    0.57291667 0.77083333 0.90625    0.91666667 0.9375    ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5625     0.75       0.95833333 0.95833333 0.95833333 0.95833333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.48958333 0.53125    0.65625    0.875      0.84375    0.86458333]\n",
      "epoch: 8 Val acc: [0.45   0.989  1.     0.9985 0.998  0.998  0.998  0.998  0.998  0.998\n",
      " 0.9976]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.36458333 0.88541667 0.83333333 0.91666667 0.83333333 0.86458333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.35416667 0.4375     0.61458333 0.6875     0.72916667 0.75      ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.5        0.76041667 0.79166667 0.75       0.75       0.77083333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.48958333 0.55208333 0.61458333 0.6875     0.61458333 0.67708333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.47916667 0.70833333 0.63541667 0.77083333 0.88541667 0.91666667]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.51041667 0.59375    0.61458333 0.70833333 0.70833333 0.70833333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.42708333 0.71875    0.82291667 0.84375    0.8125     0.80208333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.52083333 0.61458333 0.76041667 0.63541667 0.77083333 0.69791667]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.61458333 0.63541667 0.64583333 0.6875     0.67708333]\n",
      "epoch: 9 Val acc: [0.5005 0.955  0.996  0.9966 0.9966 0.996  0.9956 0.9956 0.9956 0.9956\n",
      " 0.9956]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.72916667 0.83333333 0.84375    0.83333333 0.83333333 0.83333333]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.60416667 0.78125    0.86458333 0.85416667 0.86458333 0.86458333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.5        0.58333333 0.52083333 0.57291667 0.57291667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.44791667 0.55208333 0.59375    0.55208333 0.66666667 0.65625   ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.5        0.875      0.90625    0.91666667 0.90625    0.9375    ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.61458333 0.64583333 0.58333333 0.67708333 0.48958333 0.625     ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.76041667 0.76041667 0.73958333 0.75       0.75       0.875     ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.55208333 0.5        0.48958333 0.53125    0.54166667 0.57291667]\n",
      "Test acc: [0.4817 0.758  0.915  0.9365 0.9453 0.954  0.9604 0.9565 0.958  0.959\n",
      " 0.9604]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune='False', task_num=4, update_lr=0.01, update_step=5, update_step_test=30)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 145.41it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1309.08it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 426.12it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 31.88it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "Test acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.5    0.5    0.4983 0.4976 0.4954 0.4941 0.485  0.4783 0.4783 0.4692\n",
      " 0.474  0.4746 0.4763 0.4753 0.4841 0.4822 0.4753 0.47   0.4705 0.461\n",
      " 0.454 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1 \\\n",
    "        --no_finetune False \\\n",
    "        --update_step_test 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune='False', task_num=4, update_lr=0.01, update_step=5, update_step_test=30)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 937.27it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1592.37it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 487.98it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 34.65it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "Test acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.4917 0.5    0.4736 0.43\n",
      " 0.4346 0.4617 0.4854 0.49   0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.5   ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1 \\\n",
    "        --no_finetune False \\\n",
    "        --update_step_test 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune='False', task_num=4, update_lr=0.01, update_step=5, update_step_test=30)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 588.26it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 894.78it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 336.07it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.64it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "Test acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.4695 0.4553 0.4504 0.4583\n",
      " 0.4783 0.4895 0.4934 0.4924 0.495  0.495  0.4995 0.5    0.5    0.5\n",
      " 0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.5   ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1 \\\n",
    "        --no_finetune False \\\n",
    "        --update_step_test 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune='False', task_num=4, update_lr=0.01, update_step=5, update_step_test=30)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 991.80it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1526.87it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 512.28it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 39.62it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "Test acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5\n",
      " 0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.4988 0.4988 0.5015\n",
      " 0.5015 0.4954 0.501  0.502  0.5015 0.502  0.5015 0.5    0.4995 0.5015\n",
      " 0.5015]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1 \\\n",
    "        --no_finetune False \\\n",
    "        --update_step_test 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune='False', task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 76.28it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 867.31it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 321.49it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 32.80it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "Test acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.465  0.454  0.4492\n",
      " 0.4922]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --epoch 10 \\\n",
    "        --k_spt 1 \\\n",
    "        --no_finetune False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 826.63it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1598.44it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 487.92it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.53it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.7604167 0.7604167 0.7604167 0.7604167 0.7604167 0.7708334]\n",
      "epoch: 0 Val acc: [0.7026 0.7    0.701  0.7    0.7    0.7    0.701  0.7026 0.704  0.703\n",
      " 0.7017]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.6875    0.65625   0.65625   0.65625   0.65625   0.6770834]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.75      0.7604167 0.7604167 0.7604167 0.7604167 0.7604167]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.78125   0.7708334 0.7708334 0.7708334 0.7708334 0.7708334]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.9895833 0.9791666 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9166666 0.8854166 0.8854166 0.8854166 0.8854166 0.8854166]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.8333333 0.8229166 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.6770833 0.65625   0.65625   0.65625   0.65625   0.65625  ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.90625   0.9375    0.9375    0.9270833 0.9270833 0.9270833]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.8854166 0.8541666 0.8541666 0.8541666 0.8541666 0.8541666]\n",
      "epoch: 1 Val acc: [0.7    0.699  0.698  0.6978 0.696  0.6973 0.697  0.6963 0.6978 0.6987\n",
      " 0.6997]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.93750006 0.93750006 0.93750006 0.93750006 0.93750006 0.93750006]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.7083334 0.6979166 0.6979166 0.6979166 0.6979166 0.6979166]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.6979166 0.7604166 0.7604166 0.7604166 0.7604166 0.7604166]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.6145833 0.59375   0.59375   0.59375   0.59375   0.59375  ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.6145834 0.6145834 0.6145834 0.6145834 0.6145834 0.6145834]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.8333333 0.7916667 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.84375   0.71875   0.71875   0.7395833 0.75      0.7604167]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.8541666  0.84374994 0.8541666  0.8541666  0.8541666  0.8541666 ]\n",
      "epoch: 2 Val acc: [0.6978 0.6807 0.6943 0.6934 0.6973 0.6953 0.695  0.6943 0.695  0.695\n",
      " 0.695 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9895833 0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.9583333 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.8020833 0.8125    0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.96875   0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.75      0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.96875   0.9583334 0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.71875    0.71874994 0.7291666  0.71874994 0.71874994 0.7083333 ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8333334 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 3 Val acc: [0.6978 0.7007 0.702  0.7007 0.701  0.7    0.701  0.701  0.703  0.703\n",
      " 0.7   ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.96874994 0.9270833  0.9479166  0.9479166  0.9479166  0.9479166 ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.9166666 0.9166667 0.9166667 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.6875    0.6979166 0.6979166 0.6979166 0.6979166 0.6979166]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8229167 0.78125   0.78125   0.78125   0.78125   0.7916667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.6979167 0.6770834 0.6979167 0.6979167 0.6979167 0.6979167]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.84375   0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 4 Val acc: [0.7017 0.6978 0.696  0.6973 0.6973 0.697  0.697  0.6963 0.699  0.699\n",
      " 0.699 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.71875006 0.71875006 0.71875006 0.71875006 0.71875006 0.71875006]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.7916667  0.78125    0.78125    0.78125    0.78125    0.78125006]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.8229167 0.8125    0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8125    0.78125   0.7916666 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.8854167 0.9375    0.9375    0.9270834 0.9166667 0.9166667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.7708333 0.7708333 0.7708333 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.875     0.8958334 0.8958334 0.8854167 0.8645833 0.8541666]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.8125    0.8125    0.8020833 0.8020833 0.7916666 0.7916666]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.8854166 0.8958334 0.8854167 0.8958334 0.8958334 0.875    ]\n",
      "epoch: 5 Val acc: [0.6973 0.702  0.7    0.6978 0.6978 0.6973 0.6973 0.6963 0.6973 0.6963\n",
      " 0.6978]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9583333 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.6770833 0.7083333 0.7083333 0.7083333 0.7083333 0.71875  ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.8229167 0.84375   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.90624994 0.90624994 0.90624994 0.90624994 0.90624994 0.90624994]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.875     0.8958334 0.8958334 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8229167 0.8125    0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8125    0.8333334 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.90625   0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.8333333 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 6 Val acc: [0.6978 0.6987 0.6978 0.697  0.698  0.6973 0.6963 0.6963 0.6963 0.6973\n",
      " 0.6973]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.9583333 0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.7916667 0.78125   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.8854166 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.90625 0.9375  0.9375  0.9375  0.9375  0.9375 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.78125   0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.9583333 0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.8229167 0.8645834 0.875     0.875     0.875     0.8645833]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9479167 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 Val acc: [0.6973 0.6973 0.6978 0.6973 0.698  0.6978 0.6973 0.696  0.697  0.6973\n",
      " 0.697 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.7291666 0.7291666 0.7291666 0.7291666 0.7291666 0.7291666]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.8333333 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.7291667 0.7291667 0.7291667 0.7291667 0.71875   0.7291667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.84375    0.87500006 0.875      0.875      0.8541667  0.8541667 ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9791667 0.9791667 0.9791667 0.96875  ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.84375   0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8541666 0.8541666 0.8541666 0.8541666 0.8541666 0.8541666]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.8645833 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.8125    0.8333334 0.8333334 0.8333334 0.8333334 0.8333334]\n",
      "epoch: 8 Val acc: [0.6987 0.6836 0.694  0.696  0.695  0.696  0.6963 0.698  0.6973 0.6978\n",
      " 0.698 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.9479166 0.90625   0.90625   0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9375    0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.75      0.8125    0.8125    0.8125    0.8125    0.8229166]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.90625   0.8958334 0.8958334 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.9375    0.9479166 0.9479166 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8229167 0.8333333 0.8125    0.8229167 0.8333333 0.8541667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.8854167 0.8958333 0.8958333 0.8958333 0.8854167 0.8854167]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.8958334 0.8958334 0.8958334 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.9166666 0.9166666 0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 9 Val acc: [0.69   0.6973 0.6973 0.6973 0.696  0.6943 0.695  0.697  0.698  0.6987\n",
      " 0.6978]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.875     0.8854166 0.875     0.875     0.875     0.875    ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5416667 0.5208333 0.5208333 0.5208333 0.5208333 0.5208333]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.7916667 0.7708333 0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.875     0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5208333 0.5104166 0.5104166 0.5104166 0.5104166 0.5104166]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.7291667 0.6979166 0.6979166 0.6979166 0.6979166 0.6979166]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "Test acc: [0.775  0.78   0.78   0.778  0.7754 0.7734 0.77   0.7705 0.768  0.767\n",
      " 0.766 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 856.68it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1700.85it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 520.97it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.34it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.9375    0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 0 Val acc: [0.7856 0.7856 0.7856 0.7856 0.7856 0.785  0.7847 0.7856 0.7856 0.7837\n",
      " 0.783 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.8854166 0.8854166 0.8854166 0.8854166 0.8854166 0.8854166]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.875     0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.6770834 0.6770834 0.6770834 0.6770834 0.6770834 0.6770834]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9479166 0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.7291666 0.7291667 0.7291667 0.7291667 0.7291667 0.7291667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.7604167 0.78125   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.6354167 0.6354167 0.6354167 0.6354167 0.6354167 0.6354167]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.90625 0.90625 0.90625 0.90625 0.90625 0.90625]\n",
      "epoch: 1 Val acc: [0.7124 0.7217 0.7227 0.721  0.722  0.722  0.722  0.722  0.7217 0.722\n",
      " 0.722 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.8958334 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.7291667 0.7291667 0.7291667 0.7291667 0.7291667 0.7291667]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.78125   0.7708333 0.7708333 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.7604167 0.7395834 0.7395834 0.7395834 0.75      0.75     ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8229166 0.7395833 0.8229166 0.8333333 0.8541667 0.8541667]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.7916666 0.8125    0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.9375    0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8854167 0.8854167]\n",
      "epoch: 2 Val acc: [0.672  0.681  0.6807 0.681  0.68   0.6807 0.6816 0.6816 0.682  0.683\n",
      " 0.683 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.6770834 0.6666666 0.6666666 0.6666666 0.6666666 0.6666666]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.71875 0.71875 0.71875 0.71875 0.71875 0.71875]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.7916666 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.93749994 0.9270833  0.9270833  0.9270833  0.9270833  0.9270833 ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.65625006 0.65625    0.65625    0.65625    0.65625    0.65625   ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.8229167 0.84375   0.84375   0.84375   0.84375   0.8333333]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.65625   0.7708333 0.75      0.7083333 0.6875    0.65625  ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.625     0.6354166 0.6354166 0.6354166 0.6354166 0.6354166]\n",
      "epoch: 3 Val acc: [0.7114 0.7163 0.7163 0.717  0.7173 0.7173 0.7173 0.7173 0.718  0.7188\n",
      " 0.7188]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.6354167 0.6458333 0.6458333 0.6458333 0.6458333 0.6458333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.90625 0.90625 0.90625 0.90625 0.90625 0.90625]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.8958333 0.90625   0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8645833 0.8125    0.8541666 0.75      0.8541667 0.8333333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.96874994 0.8958334  0.96875    0.9895833  0.9895833  1.        ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.9583333 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.75000006 0.8229167  0.8125     0.8020833  0.81250006 0.8125    ]\n",
      "epoch: 4 Val acc: [0.909  0.9116 0.9097 0.902  0.9    0.8975 0.896  0.8936 0.8906 0.8906\n",
      " 0.887 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.8229166  0.7916666  0.7916666  0.7916666  0.78125    0.81249994]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.7604167  0.7708333  0.78125    0.78125    0.84375    0.87499994]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.9270834 0.9270834 0.9479167 0.9583334 0.9583334 0.9583334]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.9375    0.90625   0.9270833 0.9479167 0.9583334 0.9583334]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.7604166 0.75      0.75      0.75      0.7604166 0.7604166]\n",
      "epoch: 4 step: 180 \ttraining acc: [1.        0.9895833 1.        1.        1.        1.       ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.96875   0.9479167 0.96875   0.9791667 0.9791667 0.96875  ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.9270834 0.9270834 0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.96875   0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 5 Val acc: [0.8945 0.8936 0.8936 0.8926 0.8926 0.8896 0.889  0.8857 0.887  0.885\n",
      " 0.8867]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9583333  0.9270833  0.93749994 0.9166666  0.9479166  0.9479166 ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.78125 0.78125 0.78125 0.78125 0.78125 0.78125]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.7916667 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.8229167 0.8854167 0.8854167 0.875     0.875     0.875    ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8854166]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8020833 0.7708333 0.7708333 0.78125   0.78125   0.7916666]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.96875   0.9479166 0.9479166 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.875     0.8541666 0.8541666 0.84375   0.84375   0.84375  ]\n",
      "epoch: 6 Val acc: [0.902  0.9004 0.9004 0.901  0.9    0.8994 0.898  0.896  0.8965 0.8965\n",
      " 0.893 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9479167 0.9479167 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.9375     0.9270833  0.90624994 0.90624994 0.90624994 0.90624994]\n",
      "epoch: 6 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.9791666 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 210 \ttraining acc: [0.8229167 0.7916667 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5729167 0.6458334 0.6979167 0.6979167 0.6979167 0.6979167]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.8645833 0.8958333 0.9166667 0.9375    0.9270833 0.9270833]\n",
      "epoch: 7 Val acc: [0.907  0.9077 0.902  0.902  0.9004 0.8984 0.8984 0.895  0.8955 0.8906\n",
      " 0.895 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9479167 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.9166667 0.9375    0.9479166 0.9375    0.9166666 0.9375   ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.9895833 0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.96875   0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.96875 0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9270834 0.9375    0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.8645833 0.8125    0.8020833 0.8229166 0.90625   0.90625  ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.9270833 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 8 Val acc: [0.888  0.899  0.8906 0.9004 0.9004 0.893  0.8877 0.886  0.885  0.893\n",
      " 0.894 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.9791666  0.9583333  0.9479166  0.96874994 0.96874994 0.9583333 ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9479167 0.9166667 0.9375    0.9375    0.9375    0.9479167]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.9791667 0.9791667 0.9583334 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.96875   0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.9270833 0.9166666 0.90625   0.8958333 0.8958333 0.90625  ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8854167 0.875     0.8645833 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.9166666  0.9166666  0.9270833  0.9270833  0.9166666  0.90624994]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.9479167 0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 9 Val acc: [0.896  0.8936 0.891  0.8867 0.888  0.8877 0.8853 0.8843 0.885  0.8857\n",
      " 0.886 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9479166 0.9479166 0.9479166 0.9479167]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.8958333 0.90625   0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.8229166 0.8229167 0.8541667 0.875     0.8854167 0.8854167]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.8229167 0.9479166 0.9583333 0.9583333 0.9270833 0.9270833]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9479166 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.8645833 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.8854166 0.90625   0.8645833 0.8645833 0.8541667 0.8645833]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.75000006 0.75000006 0.75000006 0.75000006 0.75000006 0.75000006]\n",
      "Test acc: [0.9995 0.9995 0.9995 0.9995 0.9995 0.9995 0.9995 0.9995 0.9995 0.9995\n",
      " 0.9995]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 693.04it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1207.86it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 405.81it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 36.91it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.90625   0.8854166 0.875     0.8541667 0.8541667 0.8541667]\n",
      "epoch: 0 Val acc: [0.701  0.709  0.709  0.709  0.708  0.7056 0.706  0.707  0.708  0.7075\n",
      " 0.708 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.7083333  0.7395833  0.7395833  0.7395833  0.74999994 0.74999994]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.8020834 0.6770834 0.7083334 0.7083334 0.71875   0.7291667]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.9375    0.9583333 0.9583333 0.9583333 0.9479167 0.9375   ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.625     0.6354166 0.6354166 0.6354166 0.6354166 0.6354166]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.8229167 0.84375   0.8333333 0.8333333 0.8333333 0.8229167]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.7395833 0.7916666 0.7916666 0.8020833 0.8125    0.8229166]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.9791666 0.9583333 0.9583333 0.96875   0.9791666 0.9791666]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.875     0.8645833 0.8645833 0.875     0.875     0.875    ]\n",
      "epoch: 1 Val acc: [0.78   0.7627 0.7627 0.76   0.762  0.7607 0.7603 0.762  0.7627 0.764\n",
      " 0.765 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.9270833 0.8958333 0.8958333 0.90625   0.9166666 0.9270833]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.74999994 0.78125    0.7708334  0.7604167  0.78124994 0.78124994]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.8541667 0.84375   0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.875     0.8958333 0.8958333 0.8958333 0.8854166 0.8854166]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.7083333 0.6979167 0.6979167 0.6875    0.6875    0.6979167]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8333333 0.8541667 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.8125    0.7604166 0.8229166 0.8541666 0.8541666 0.8541666]\n",
      "epoch: 1 step: 240 \ttraining acc: [1.        0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.78124994 0.78125    0.7916666  0.7916666  0.8020833  0.7916666 ]\n",
      "epoch: 2 Val acc: [0.8145 0.8057 0.8    0.797  0.793  0.794  0.795  0.794  0.794  0.7944\n",
      " 0.7964]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.7291666 0.7916666 0.8020833 0.78125   0.78125   0.78125  ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.8958334 0.8541667 0.8645833 0.875     0.875     0.875    ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.9375 0.9375 0.9375 0.9375 0.9375 0.9375]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.9479167 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.8854167  0.87499994 0.8854166  0.8854167  0.8958333  0.8854167 ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.7604167 0.7604167 0.7604167 0.7604167 0.7604167 0.7604167]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8958333 0.9166666 0.9166666 0.9166666 0.9270833 0.9166666]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.9270834 0.9270834 0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.96875   0.96875   0.9791667 0.9791667 0.9791667 0.96875  ]\n",
      "epoch: 3 Val acc: [0.826  0.8193 0.8223 0.8164 0.8154 0.82   0.8193 0.822  0.821  0.8228\n",
      " 0.82  ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.9479167 0.8854167 0.9270833 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.7291666 0.71875   0.75      0.7604166 0.7604166 0.7604166]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.90624994 0.8958333  0.8958333  0.8958333  0.8854166  0.8854166 ]\n",
      "epoch: 3 step: 120 \ttraining acc: [1.        0.9791667 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.96875   0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9791667 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.7395833 0.7916667 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.7395834 0.6979167 0.7083334 0.7083334 0.7291667 0.7291667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.9479166  0.9270833  0.9270833  0.93749994 0.93749994 0.9479166 ]\n",
      "epoch: 4 Val acc: [0.836  0.815  0.822  0.822  0.8223 0.822  0.8223 0.823  0.825  0.824\n",
      " 0.8228]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9791667 0.9479166 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.9583333 0.90625   0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.7708333 0.7604167 0.7604167 0.7604167 0.7604167 0.7604167]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.78125   0.71875   0.7395833 0.7395833 0.7395833 0.7395833]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.875     0.8541667 0.8541667 0.8541667 0.8645834 0.8645834]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.7395834 0.7916667 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.7916666 0.7916666 0.7916666 0.78125   0.7708333 0.7708333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.8229167 0.8125    0.8125    0.8020834 0.8020834 0.78125  ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.875     0.78125   0.9375    0.96875   0.9479167 0.9166667]\n",
      "epoch: 5 Val acc: [0.852  0.6113 0.8423 0.85   0.8467 0.855  0.8477 0.8516 0.8496 0.849\n",
      " 0.845 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.8958333 0.8854167 0.90625   0.9270833 0.9166666 0.9270833]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8958333 0.84375   0.9166667 0.9375    0.9375    0.9375   ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9791666 0.75      0.8854167 0.9583333 0.9791666 0.9791666]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.8229167 0.6354167 0.8645834 0.9375    0.8541667 0.96875  ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.8229166 0.8125    0.8020833 0.8125    0.8125    0.84375  ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8125    0.875     0.875     0.875     0.8645833 0.8645833]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.75      0.75      0.75      0.7291666 0.7395833 0.7291666]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5729167 0.5208333 0.5520833 0.5520833 0.5520833 0.5520833]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.7083333 0.65625   0.6770834 0.6979167 0.71875   0.7291667]\n",
      "epoch: 6 Val acc: [0.783  0.76   0.76   0.7554 0.7544 0.7554 0.7583 0.758  0.756  0.7554\n",
      " 0.7544]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9895833  0.9166666  0.9270833  0.96874994 0.96874994 0.9791666 ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.9375    0.9166667 0.8958333 0.8958333 0.9270833 0.9479166]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.90625   0.8020834 0.875     0.8958334 0.8958334 0.8958334]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.96875 0.9375  0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.9166666  0.7604166  0.8541666  0.8541666  0.90624994 0.8854166 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.875     0.5729167 0.6666666 0.6145833 0.6770833 0.75     ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9479167 0.9479167]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.9895833 0.9270833 0.9895833 0.9895833 0.9270833 0.9895833]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.7604166  0.71874994 0.7604166  0.7291666  0.7395833  0.7708333 ]\n",
      "epoch: 7 Val acc: [0.8027 0.743  0.6704 0.7783 0.783  0.7837 0.783  0.783  0.7837 0.7827\n",
      " 0.786 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.53125   0.5520833 0.5729166 0.5625    0.59375   0.5416667]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.8541667  0.7291667  0.7604167  0.7291667  0.75       0.71875006]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.62499994 0.625      0.6458333  0.6458333  0.6458333  0.6354166 ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.7916667 0.6666667 0.6875    0.9166666 0.9166666 0.9166666]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.75      0.75      0.7604167 0.7708333 0.78125   0.7916667]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9479167 0.9166667 0.9375    0.9479167 0.9479167 0.9479167]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.9583333 0.8541666 0.9583333 0.9583333 0.9791667 0.9583333]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.8020833 0.875     0.8229167 0.8125    0.8125    0.7916667]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.8020833 0.8020833 0.8125    0.8229167 0.8229167 0.75     ]\n",
      "epoch: 8 Val acc: [0.865  0.79   0.8403 0.843  0.8457 0.8423 0.848  0.8467 0.845  0.846\n",
      " 0.846 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.96875   0.9791667 0.96875   0.9583334 0.9583334 0.9583334]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.7916667 0.71875   0.7395834 0.75      0.7708334 0.78125  ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.96875   0.9479167 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.8229166 0.8333333 0.8333333 0.8333333 0.8229166 0.8229166]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.84375006 0.84375006 0.84375006 0.84375006 0.84375006 0.84375006]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8645833 0.71875   0.7916667 0.8541667 0.8645833 0.8645833]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.9166667 0.8958334 0.8958334 0.8958334 0.8958334 0.90625  ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.7916666 0.7708333 0.7708333 0.7708333 0.7708333 0.8229166]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8333334 0.8333334 0.8645834 0.8541667 0.8645834 0.8645834]\n",
      "epoch: 9 Val acc: [0.863  0.857  0.8535 0.8545 0.851  0.8545 0.8525 0.8535 0.8525 0.853\n",
      " 0.855 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.7916666 0.8020833 0.8541666 0.8229166 0.8958333 0.875    ]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.9166667 0.9375    0.90625   0.90625   0.9166667 0.90625  ]\n",
      "epoch: 9 step: 90 \ttraining acc: [1.      1.      0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9375    0.90625   0.8958333 0.9479167 0.90625   0.96875  ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9375    0.9375    0.9375    0.9166667 0.9375    0.9375   ]\n",
      "epoch: 9 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9375    0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.8958333 0.8020833 0.8645834 0.875     0.8854167 0.875    ]\n",
      "Test acc: [0.8755 0.9233 0.92   0.921  0.922  0.9224 0.925  0.925  0.926  0.9272\n",
      " 0.9272]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 710.66it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1275.45it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 430.79it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.50it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.59375   0.6145833 0.6145833 0.6145833 0.6145833 0.625    ]\n",
      "epoch: 0 Val acc: [0.7676 0.7627 0.7617 0.762  0.7627 0.764  0.765  0.762  0.762  0.7637\n",
      " 0.762 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9479167 0.9479166 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.9895833 0.9791667 0.9791667 0.9791667 0.9791667 0.9895833]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9479167 0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.6979167 0.6979167 0.6979166 0.6979167 0.6875    0.6875   ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.6666666 0.6979167 0.6875    0.6875    0.6875    0.65625  ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.84375   0.8541666 0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.8854166  0.87499994 0.87499994 0.87499994 0.87499994 0.87499994]\n",
      "epoch: 1 Val acc: [0.7603 0.7544 0.7544 0.753  0.754  0.7554 0.7534 0.7544 0.7544 0.7563\n",
      " 0.757 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.78125 0.78125 0.78125 0.78125 0.78125 0.78125]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.74999994 0.7604166  0.7604166  0.7604166  0.7604166  0.7604166 ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9479166 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.7395834  0.75000006 0.75000006 0.7395834  0.75000006 0.75000006]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9270833 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.7291667  0.75000006 0.75000006 0.7291667  0.7291667  0.7291667 ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.9166666 0.9166666 0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.8125    0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 2 Val acc: [0.7637 0.7505 0.754  0.754  0.7544 0.7544 0.7544 0.7563 0.7573 0.759\n",
      " 0.76  ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.9583333 0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5520833 0.5729167 0.5729167 0.5625    0.5625    0.5625   ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.8958333 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.8125    0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.84375   0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.6770833 0.6979166 0.6979166 0.6979166 0.6979166 0.6979166]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8541666 0.8229166 0.8229166 0.8229166 0.8229166 0.8333333]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8020833 0.7916666 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 3 Val acc: [0.758  0.7563 0.7593 0.76   0.7573 0.755  0.7544 0.755  0.754  0.7534\n",
      " 0.753 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.78125   0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.7604166 0.7916667 0.7916667 0.7916667 0.8020833 0.7916666]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.9583333 0.9791666 0.9791666 0.9791666 0.9791666 0.9791666]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9791667 0.96875   0.96875   0.96875   0.9791667 0.9791667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.90625   0.96875   0.9479167 0.9479167 0.9270834 0.9270834]\n",
      "epoch: 3 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.9583333 0.9791666 0.9791666 0.9791666 0.9791666 0.96875  ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.6458333 0.7083333 0.7083333 0.6979167 0.6875    0.6666666]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.90624994 0.8333333  0.84375    0.8541666  0.8645833  0.8645833 ]\n",
      "epoch: 4 Val acc: [0.76   0.7485 0.7495 0.752  0.7524 0.7534 0.755  0.7544 0.758  0.7583\n",
      " 0.759 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.8020833 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.7395833 0.7395833 0.7395833 0.7395833 0.7395833 0.7395833]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.8020834 0.8020834 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8333334 0.90625   0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.65625 0.65625 0.65625 0.65625 0.65625 0.65625]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.8854166 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8958333 0.9166666 0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.84375006 0.84375006 0.84375006 0.84375006 0.84375006 0.84375006]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.9479166 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 5 Val acc: [0.7603 0.7524 0.754  0.7544 0.755  0.7573 0.7563 0.7573 0.759  0.7593\n",
      " 0.758 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9479166 0.90625   0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.84375   0.8020833 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8229167 0.8229167]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.93749994 0.93749994 0.93749994 0.93749994 0.93749994 0.93749994]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.9166667 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.81249994 0.8020833  0.8020833  0.8020833  0.81249994 0.81249994]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9479166  0.93749994 0.93749994 0.93749994 0.93749994 0.93749994]\n",
      "epoch: 6 Val acc: [0.7603 0.7515 0.754  0.7534 0.752  0.7515 0.753  0.754  0.754  0.756\n",
      " 0.7554]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.71875   0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8229166 0.8229166 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.6770833 0.6458333 0.65625   0.65625   0.65625   0.65625  ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.65625   0.65625   0.6458334 0.65625   0.65625   0.65625  ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.8958333  0.90624994 0.90624994 0.8958333  0.8958333  0.8958333 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.9166666 0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.8333333  0.8541666  0.84375    0.8229166  0.81249994 0.81249994]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.75      0.7291666 0.7291666 0.7291666 0.7291666 0.7291666]\n",
      "epoch: 7 Val acc: [0.76   0.7524 0.752  0.753  0.7544 0.7554 0.757  0.7573 0.7573 0.7593\n",
      " 0.76  ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.8020833 0.7395833 0.75      0.75      0.7708334 0.7708334]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.7083333 0.6979167 0.6979167 0.6979167 0.6979167 0.6979167]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.9791666  0.96874994 0.96874994 0.96874994 0.96874994 0.96874994]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.8854166 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.8645833 0.8333333 0.8333333 0.84375   0.84375   0.84375  ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.8645834 0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8229167 0.8229167 0.8229167 0.8229167 0.8229167 0.8125   ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.8333333 0.8229166 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 Val acc: [0.752  0.7515 0.7515 0.7495 0.7495 0.7544 0.7573 0.757  0.757  0.7573\n",
      " 0.756 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.8125    0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.8541666 0.84375   0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.8125    0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.90625    0.90624994 0.90624994 0.90624994 0.90624994 0.90624994]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.9166666 0.90625   0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.7708334 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.8854166 0.9166666 0.9166666 0.9166666 0.9166666 0.8854166]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8645834 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 9 Val acc: [0.7603 0.7544 0.7544 0.7554 0.756  0.757  0.7573 0.758  0.7583 0.758\n",
      " 0.7573]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.7291667 0.7395833 0.7395833 0.7395833 0.7395833 0.7395833]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.8854166 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.8645833 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.96875 0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "Test acc: [0.52   0.5205 0.521  0.5205 0.521  0.521  0.5205 0.5205 0.5215 0.521\n",
      " 0.5205]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/single_graph/cycle_random1000/META_SETUP_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 571.12it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 995.09it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 394.67it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.80it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.8645834 0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 0 Val acc: [0.9985 0.996  0.996  0.996  0.996  0.997  0.9976 0.9976 0.9976 0.9976\n",
      " 0.997 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.81249994 0.7916666  0.7916666  0.7916666  0.7916666  0.7916666 ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.8229167 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.8645833  0.87499994 0.8645833  0.875      0.875      0.875     ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9479166  0.93749994 0.9479166  0.9479166  0.9479166  0.9479166 ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.9583333 0.9479166 0.9479166 0.9479166 0.9583333 0.9583333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.90625   0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.8333334 0.8229167 0.8333334 0.8333334 0.8333334 0.8333334]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.7083333 0.6979167 0.6979167 0.7395833 0.75      0.75     ]\n",
      "epoch: 1 Val acc: [0.8833 0.8823 0.899  0.9204 0.93   0.939  0.947  0.949  0.9536 0.956\n",
      " 0.9585]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.7291667 0.7291667 0.71875   0.7291667 0.7291667 0.7291667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.75   0.8125 0.8125 0.8125 0.8125 0.8125]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.75      0.75      0.7604166 0.7604166 0.7604166 0.7604166]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.8541666 0.8541666 0.8541666 0.8541666 0.8541666 0.8541666]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8958333 0.9166667 0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.59375   0.6354167 0.6354167 0.625     0.6458333 0.6354166]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.90625   0.90625   0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.6979167 0.6770834 0.6770834 0.6770834 0.6770834 0.6770834]\n",
      "epoch: 2 Val acc: [0.845  0.8135 0.8677 0.912  0.934  0.946  0.951  0.956  0.9575 0.96\n",
      " 0.9604]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.6354166  0.62499994 0.62499994 0.62499994 0.62499994 0.62499994]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.7916667 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.71875   0.7083334 0.71875   0.7604166 0.7604166 0.75     ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.9895833 0.9791666 0.9791666 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.71875   0.7291666 0.7083333 0.75      0.75      0.7604167]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8854166 0.8125    0.7708333 0.78125   0.8645833 0.8645833]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.90625 0.90625 0.90625 0.90625 0.90625 0.90625]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8333333 0.7708333 0.8229166 0.8333333 0.84375   0.84375  ]\n",
      "epoch: 3 Val acc: [0.901  0.7563 0.9214 0.942  0.958  0.9663 0.969  0.969  0.969  0.97\n",
      " 0.971 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.8333333 0.8229167 0.84375   0.8541667 0.875     0.8958333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.7604166  0.6875     0.68749994 0.6979166  0.7083333  0.7395833 ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.7395833 0.7291667 0.7291667 0.7291667 0.7395833 0.7395833]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.84375   0.9270834 0.8854167 0.90625   0.8958333 0.8958333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.9166666 0.8541667 0.8645833 0.875     0.8854166 0.8333333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9166666  0.90624994 0.8229166  0.84374994 0.87500006 0.9270833 ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.6875    0.6458333 0.6770833 0.6770833 0.6770833 0.6770833]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.9479167 0.8645833 0.8958333 0.8854167 0.90625   0.90625  ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.65625   0.6458334 0.6458334 0.6458334 0.6666667 0.6875   ]\n",
      "epoch: 4 Val acc: [0.5786 0.561  0.5923 0.6514 0.672  0.7095 0.7407 0.758  0.7715 0.7803\n",
      " 0.794 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9583333 0.8958333 0.8958333 0.8958333 0.8958333 0.9270833]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.9375    0.90625   0.9791666 0.9791666 0.9791666 0.9791666]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.8333333 0.8541666 0.8541667 0.8958333 0.9166666 0.9166666]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.78125   0.7916667 0.78125   0.78125   0.7708333 0.7604166]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.7708334 0.75      0.84375   0.8541667 0.8541667 0.8541667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.8333333  0.81249994 0.81249994 0.81249994 0.81249994 0.8333333 ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.625     0.625     0.625     0.625     0.6875    0.6354166]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.8333334  0.7916666  0.8125     0.8541666  0.8541666  0.84374994]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.71875   0.6770833 0.6770833 0.7916666 0.7916666 0.7916666]\n",
      "epoch: 5 Val acc: [0.8135 0.7344 0.8555 0.879  0.893  0.8994 0.908  0.915  0.9185 0.922\n",
      " 0.9253]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.875     0.8333333 0.8333334 0.8333334 0.8333334 0.8333334]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.9479166 0.9583333 0.9479166 0.9375    0.9375    0.9583333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9583334 0.8854167 0.9270834 0.9270834 0.8958334 0.8958334]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.9166666 0.7395833 0.7395833 0.9375    0.9375    0.9375   ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.75      0.7395834 0.7083334 0.7083334 0.7291666 0.6875   ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8854166 0.75      0.8541667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8125    0.7083334 0.75      0.84375   0.8333333 0.8333333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.7708333 0.6458333 0.7708333 0.7916666 0.7604166 0.78125  ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "Test acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/single_graph/cycle_random1000/META_SETUP_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
