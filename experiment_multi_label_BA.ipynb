{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1621.93it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 457.08it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.93it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.5    0.501  0.5034 0.4976 0.495  0.4924 0.4988\n",
      " 0.4917]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.5        0.5        0.5        0.48958333 0.4375     0.45833333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.5        0.5        0.45833333 0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.5        0.5        0.5        0.5        0.55208333 0.57291667]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5        0.375      0.55208333 0.5        0.5        0.54166667]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.35416667 0.32291667 0.5625     0.48958333 0.52083333 0.5       ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5        0.5        0.41666667 0.41666667 0.35416667 0.40625   ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.5        0.625      0.5625     0.54166667 0.5625     0.59375   ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.5        0.83333333 0.77083333 0.78125    0.79166667 0.8125    ]\n",
      "epoch: 1 Val acc: [0.5    0.5    0.5    0.5    0.503  0.5    0.4983 0.501  0.501  0.4983\n",
      " 0.4976]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.5        0.70833333 0.78125    0.75       0.79166667 0.80208333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.52083333 0.5625     0.5625     0.66666667 0.6875    ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.47916667 0.46875    0.59375    0.71875    0.78125    0.85416667]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5        0.60416667 0.84375    0.82291667 0.8125     0.8125    ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5625     0.84375    0.8125     0.875      0.83333333 0.85416667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5        0.67708333 0.72916667 0.6875     0.67708333 0.70833333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.5625     0.66666667 0.60416667 0.625      0.65625   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.51041667 0.5        0.63541667 0.625      0.625      0.625     ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.40625    0.5        0.625      0.72916667 0.75       0.67708333]\n",
      "epoch: 2 Val acc: [0.497  0.4954 0.497  0.5015 0.4963 0.4924 0.4988 0.4958 0.5015 0.4963\n",
      " 0.502 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.51041667 0.67708333 0.86458333 0.90625    0.90625    0.90625   ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.63541667 0.72916667 0.6875     0.6875     0.69791667]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.625      0.69791667 0.76041667 0.76041667 0.79166667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.51041667 0.70833333 0.71875    0.70833333 0.72916667 0.71875   ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.4375     0.4375     0.5625     0.4375     0.42708333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5        0.625      0.54166667 0.71875    0.76041667 0.71875   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.5625     0.65625    0.73958333 0.70833333 0.76041667]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.51041667 0.66666667 0.67708333 0.79166667 0.8125    ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5     0.5     0.5     0.5     0.5625  0.59375]\n",
      "epoch: 3 Val acc: [0.5    0.4976 0.502  0.502  0.5063 0.509  0.51   0.511  0.5107 0.51\n",
      " 0.508 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.57291667 0.65625    0.80208333 0.73958333 0.83333333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.61458333 0.61458333 0.73958333 0.46875    0.51041667]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.5        0.58333333 0.71875    0.77083333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.4375     0.59375    0.60416667 0.71875    0.78125   ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.51041667 0.58333333 0.80208333 0.71875    0.75       0.71875   ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.59375    0.85416667 0.84375    0.94791667 0.96875   ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.45833333 0.64583333 0.67708333 0.72916667 0.76041667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.63541667 0.875      0.73958333 0.90625    0.79166667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.71875    0.83333333 0.80208333 0.82291667 0.77083333]\n",
      "epoch: 4 Val acc: [0.5    0.501  0.5015 0.5107 0.5127 0.52   0.515  0.525  0.516  0.5293\n",
      " 0.5186]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.46875    0.78125    0.79166667 0.84375    0.84375   ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.5        0.70833333 0.60416667 0.83333333 0.77083333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.65625    0.63541667 0.79166667 0.6875     0.79166667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.70833333 0.83333333 0.75       0.79166667 0.76041667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.71875    0.85416667 0.97916667 0.97916667 0.97916667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.53125    0.875      0.85416667 0.86458333 0.86458333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.57291667 0.58333333 0.72916667 0.76041667 0.79166667]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.875      0.80208333 0.95833333 0.875      0.94791667]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.44791667 0.84375    0.84375    0.875      0.875     ]\n",
      "epoch: 5 Val acc: [0.5    0.495  0.503  0.4993 0.512  0.5073 0.51   0.505  0.517  0.503\n",
      " 0.523 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.625      0.70833333 0.77083333 0.85416667 0.86458333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.60416667 0.8125     0.8125     0.90625    0.94791667]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.55208333 0.78125    0.76041667 0.83333333 0.79166667]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.66666667 0.875      0.875      0.91666667 0.95833333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.63541667 0.61458333 0.78125    0.86458333 0.86458333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.5        0.69791667 0.77083333 0.6875     0.78125   ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.66666667 0.875      0.92708333 0.875      0.98958333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.72916667 0.875      0.85416667 0.875      0.85416667]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.8125     0.79166667 0.86458333 0.79166667 0.86458333]\n",
      "epoch: 6 Val acc: [0.5    0.4966 0.5034 0.5083 0.508  0.508  0.514  0.518  0.5127 0.517\n",
      " 0.514 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.39583333 0.71875    0.75       0.75       0.83333333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.80208333 0.90625    0.83333333 0.92708333 0.83333333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.71875    0.71875    0.72916667 0.75       0.77083333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.72916667 0.89583333 0.95833333 0.97916667 0.98958333]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.75       0.75       0.9375     0.95833333 0.96875   ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.52083333 0.71875    0.8125     0.82291667 0.94791667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.625      0.66666667 0.84375    0.875      0.86458333]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.77083333 0.79166667 0.875      0.875      0.875     ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.55208333 0.70833333 0.57291667 0.84375    0.78125   ]\n",
      "epoch: 7 Val acc: [0.5    0.501  0.4993 0.5083 0.5054 0.5127 0.514  0.5195 0.519  0.5215\n",
      " 0.521 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.85416667 0.875      0.875      0.86458333 0.875     ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.5        0.66666667 0.60416667 0.79166667 0.8125    ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.88541667 0.88541667 0.91666667 0.91666667 0.91666667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.39583333 0.79166667 0.875      0.86458333 0.875     ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5        0.25       0.72916667 0.9375     0.98958333 0.92708333]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5        0.79166667 0.88541667 0.86458333 0.90625    0.85416667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5 1.  1.  1.  1.  1. ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.83333333 0.91666667 0.75       0.71875    0.70833333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.625      0.86458333 0.96875    0.98958333 0.9375    ]\n",
      "epoch: 8 Val acc: [0.5    0.495  0.504  0.5024 0.5103 0.5156 0.51   0.5166 0.516  0.5166\n",
      " 0.5146]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.61458333 0.63541667 0.85416667 0.9375     0.86458333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.95833333 0.97916667 0.97916667 0.97916667 0.97916667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.5        0.57291667 0.6875     0.82291667 0.77083333 0.85416667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.625      0.96875    0.94791667 0.98958333 0.96875   ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.5        0.66666667 0.58333333 0.70833333 0.625     ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5        0.59375    0.875      0.875      0.92708333 0.89583333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5        0.70833333 0.75       0.86458333 0.85416667 0.86458333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.42708333 0.53125    0.67708333 0.6875     0.59375   ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.92708333 0.98958333 0.98958333 0.98958333 0.98958333]\n",
      "epoch: 9 Val acc: [0.5    0.501  0.5    0.5137 0.509  0.5146 0.511  0.5044 0.5156 0.519\n",
      " 0.5186]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.77083333 0.75       0.85416667 0.79166667 0.77083333]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.47916667 0.71875    0.75       0.84375    0.6875    ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.91666667 0.98958333 1.         1.         1.        ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.71875    0.88541667 0.97916667 0.9375     0.97916667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.5        0.625      0.78125    0.75       0.8125     0.79166667]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5        0.48958333 0.75       0.77083333 0.84375    0.77083333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.5        0.79166667 0.875      0.92708333 1.         1.        ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5        0.84375    0.82291667 0.86458333 0.86458333 0.9375    ]\n",
      "Test acc: [0.5    0.7856 0.821  0.9175 0.933  0.939  0.942  0.9443 0.9443 0.942\n",
      " 0.9424]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 860.55it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1392.99it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 438.61it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.04it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5        0.5        0.38541667 0.5        0.5        0.5       ]\n",
      "epoch: 0 Val acc: [0.5    0.465  0.5    0.5005 0.5005 0.5005 0.5015 0.5034 0.504  0.5044\n",
      " 0.506 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.5        0.47916667 0.52083333 0.5        0.48958333 0.48958333]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.5        0.54166667 0.53125    0.53125    0.53125    0.53125   ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.55208333 0.51041667 0.57291667 0.5        0.58333333 0.52083333]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.45833333 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.375      0.60416667 0.58333333 0.58333333 0.59375    0.59375   ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5        0.625      0.60416667 0.60416667 0.58333333 0.58333333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.5        0.73958333 0.41666667 0.45833333 0.57291667 0.57291667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.46875    0.6875     0.58333333 0.58333333 0.58333333 0.61458333]\n",
      "epoch: 1 Val acc: [0.4966 0.872  0.742  0.8223 0.839  0.8433 0.847  0.8643 0.863  0.8833\n",
      " 0.8936]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.51041667 0.55208333 0.60416667 0.71875    0.85416667 0.80208333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.52083333 0.69791667 0.6875     0.75       0.78125   ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5        0.40625    0.59375    0.625      0.60416667 0.625     ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5        0.625      0.51041667 0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5        0.5        0.52083333 0.52083333 0.5        0.48958333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.5        0.47916667 0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.5        0.55208333 0.53125    0.51041667 0.51041667 0.51041667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 Val acc: [0.5    0.4934 0.517  0.5205 0.5273 0.535  0.5396 0.547  0.5557 0.5684\n",
      " 0.5864]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.5        0.47916667 0.5        0.5        0.5       ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.5        0.60416667 0.52083333 0.5        0.5       ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.61458333 0.61458333 0.55208333 0.60416667 0.57291667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5        0.53125    0.54166667 0.55208333 0.5625     0.52083333]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.5        0.57291667 0.54166667 0.54166667 0.54166667]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.67708333 0.52083333 0.53125    0.53125    0.57291667 0.5625    ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.5        0.46875    0.52083333 0.53125    0.54166667]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.51041667 0.57291667 0.57291667 0.59375    0.61458333 0.625     ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5        0.5        0.5        0.57291667 0.625      0.61458333]\n",
      "epoch: 3 Val acc: [0.5    0.6    0.745  0.8457 0.871  0.8857 0.902  0.9146 0.922  0.9224\n",
      " 0.9316]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.69791667 0.59375    0.65625    0.69791667 0.69791667]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.51041667 0.67708333 0.70833333 0.72916667 0.73958333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.625      0.70833333 0.72916667 0.72916667]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.58333333 0.67708333 0.71875    0.85416667 0.88541667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.5        0.40625    0.55208333 0.47916667 0.5       ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5     0.5     0.5     0.71875 0.90625 0.9375 ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.5        0.67708333 0.95833333 0.98958333 0.98958333]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.61458333 0.61458333 0.69791667 0.625      0.70833333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.5        0.78125    1.         0.97916667 1.        ]\n",
      "epoch: 4 Val acc: [0.4988 0.717  0.9683 0.9785 0.9805 0.982  0.982  0.9844 0.9854 0.9863\n",
      " 0.9873]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.84375    0.86458333 0.875      0.86458333 0.76041667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.60416667 0.52083333 0.8125     0.85416667 0.86458333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.5        0.5        0.6875     0.69791667 0.72916667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.5        0.5        0.65625    0.75       0.91666667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5   0.5   0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.5        0.65625    0.67708333 0.6875     0.6875    ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.5        0.625      0.63541667 0.72916667 0.69791667]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.82291667 0.84375    0.86458333 0.86458333 0.86458333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.51041667 0.91666667 0.91666667 0.91666667 0.92708333]\n",
      "epoch: 5 Val acc: [0.5    0.7573 1.     1.     1.     1.     1.     1.     1.     1.\n",
      " 1.    ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.375      0.75       0.64583333 0.875      0.77083333 0.83333333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.58333333 0.84375    0.85416667 0.86458333 0.85416667]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.5        0.625      0.57291667 0.64583333 0.64583333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.5        0.875      0.90625    0.875      0.86458333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.48958333 0.86458333 0.92708333 0.95833333 0.95833333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.5625     0.61458333 0.63541667 0.65625    0.75      ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.47916667 0.82291667 0.86458333 0.72916667 0.66666667]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.5        0.52083333 0.52083333 0.65625    0.71875   ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.40625    0.84375    0.85416667 0.875      0.875     ]\n",
      "epoch: 6 Val acc: [0.5    0.887  0.994  0.9937 0.997  0.996  0.997  0.997  0.9985 0.9985\n",
      " 0.998 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.70833333 0.91666667 0.89583333 0.91666667 0.91666667]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.5        0.48958333 0.55208333 0.72916667 0.71875   ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.5        0.65625    0.66666667 0.70833333 0.70833333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.5     0.5     0.5     0.5     0.625   0.78125]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.5        0.61458333 0.80208333 0.90625    0.92708333]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.71875    0.63541667 0.72916667 0.72916667 0.73958333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.48958333 0.65625    0.5625     0.67708333 0.63541667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.55208333 0.6875     0.6875     0.69791667 0.73958333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.71875    0.875      0.91666667 0.89583333 0.94791667]\n",
      "epoch: 7 Val acc: [0.5    0.916  0.945  0.9463 0.947  0.945  0.9443 0.9443 0.9434 0.943\n",
      " 0.942 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.70833333 0.83333333 0.85416667 0.86458333 0.89583333]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.5        0.34375    0.40625    0.63541667 0.73958333]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.625      0.70833333 0.75       0.78125    0.76041667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.5        0.61458333 0.58333333 0.69791667 0.71875   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.40625    0.64583333 0.63541667 0.76041667 0.76041667 0.78125   ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5        0.5        0.85416667 0.875      0.875      0.875     ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.42708333 0.79166667 0.66666667 0.625      0.66666667 0.64583333]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.125      0.41666667 0.53125    0.66666667 0.875      0.90625   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.63541667 0.5625     0.63541667 0.67708333 0.80208333 0.80208333]\n",
      "epoch: 8 Val acc: [0.55   0.799  0.9287 0.945  0.9575 0.9585 0.9736 0.977  0.98   0.982\n",
      " 0.984 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5625     0.59375    0.75       0.76041667 0.80208333 0.80208333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.91666667 0.91666667 0.95833333 0.9375     0.95833333 0.95833333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.75       0.71875    0.70833333 0.75       0.73958333 0.72916667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.75       0.82291667 0.82291667 0.8125     0.83333333 0.82291667]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.58333333 0.63541667 0.71875    0.75       0.70833333 0.71875   ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.375      0.625      0.76041667 0.89583333 0.89583333 0.88541667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.48958333 0.67708333 0.625      0.69791667 0.625      0.79166667]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.38541667 0.63541667 0.58333333 0.70833333 0.70833333 0.70833333]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.40625    0.65625    0.625      0.78125    0.86458333 0.90625   ]\n",
      "epoch: 9 Val acc: [0.47   0.969  0.9673 0.976  0.9775 0.9785 0.9785 0.981  0.9814 0.982\n",
      " 0.9824]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.52083333 0.5625     0.65625    0.82291667 0.82291667 0.82291667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.51041667 0.64583333 0.70833333 0.73958333 0.78125    0.71875   ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.76041667 0.79166667 0.86458333 0.83333333 0.83333333 0.86458333]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.48958333 0.44791667 0.53125    0.69791667 0.65625    0.75      ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.51041667 0.5625     0.53125    0.53125    0.55208333 0.61458333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5        0.58333333 0.625      0.52083333 0.71875    0.67708333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.4375     0.39583333 0.54166667 0.5        0.625      0.54166667]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.46875    0.58333333 0.70833333 0.61458333 0.77083333 0.76041667]\n",
      "Test acc: [0.5    0.581  0.7124 0.7827 0.898  0.945  0.945  0.9585 0.9517 0.9385\n",
      " 0.9253]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 762.74it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1165.57it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 418.54it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 35.77it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.5    0.4978 0.493  0.4963 0.4983 0.4924 0.4883\n",
      " 0.487 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.5        0.40625    0.60416667 0.51041667 0.5        0.5       ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.52083333 0.65625    0.70833333 0.69791667 0.6875     0.6875    ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.52083333 0.45833333 0.5625     0.625      0.67708333 0.5625    ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.58333333 0.63541667 0.69791667 0.72916667 0.70833333 0.70833333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.52083333 0.63541667 0.79166667 0.86458333 0.77083333 0.86458333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.51041667 0.55208333 0.35416667 0.53125    0.55208333 0.46875   ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.51041667 0.52083333 0.51041667 0.51041667 0.57291667 0.65625   ]\n",
      "epoch: 1 Val acc: [0.5034 0.5054 0.5117 0.5493 0.5547 0.5854 0.5757 0.598  0.5903 0.607\n",
      " 0.602 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.59375    0.78125    0.6875     0.70833333 0.69791667 0.72916667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.59375    0.73958333 0.71875    0.71875    0.69791667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5        0.48958333 0.54166667 0.52083333 0.5625     0.54166667]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.48958333 0.70833333 0.72916667 0.72916667 0.76041667 0.72916667]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5625     0.8125     0.6875     0.86458333 0.77083333 0.89583333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.52083333 0.59375    0.80208333 0.86458333 0.85416667 0.85416667]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.51041667 0.58333333 0.60416667 0.57291667 0.67708333]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.51041667 0.75       0.82291667 0.8125     0.98958333 0.875     ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5        0.6875     0.70833333 0.70833333 0.66666667 0.72916667]\n",
      "epoch: 2 Val acc: [0.5024 0.4912 0.524  0.5117 0.5366 0.5117 0.5366 0.5127 0.536  0.521\n",
      " 0.5366]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.73958333 0.875      0.6875     0.78125    0.83333333]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.4375     0.52083333 0.73958333 0.76041667 0.77083333 0.75      ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.375      0.51041667 0.39583333 0.63541667 0.66666667 0.8125    ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5        0.61458333 0.69791667 0.6875     0.75       0.71875   ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.55208333 0.58333333 0.59375    0.5        0.59375    0.48958333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.4375     0.61458333 0.625      0.73958333 0.8125     0.84375   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.58333333 0.63541667 0.77083333 0.78125    0.83333333 0.8125    ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.38541667 0.38541667 0.5        0.5625     0.60416667 0.70833333]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.53125    0.40625    0.85416667 0.88541667 0.84375    0.77083333]\n",
      "epoch: 3 Val acc: [0.5    0.465  0.5156 0.512  0.541  0.53   0.5425 0.5464 0.548  0.544\n",
      " 0.5527]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.36458333 0.76041667 0.89583333 0.89583333 0.94791667]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.36458333 0.54166667 0.53125    0.60416667 0.625     ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.47916667 0.27083333 0.54166667 0.75       0.73958333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.5        0.625      0.53125    0.57291667 0.73958333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.5        0.53125    0.57291667 0.54166667 0.54166667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.55208333 0.58333333 0.71875    0.61458333 0.65625   ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.58333333 0.63541667 0.89583333 0.86458333 0.875     ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.5        0.63541667 0.65625    0.66666667 0.65625   ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.5        0.61458333 0.4375     0.6875     0.72916667]\n",
      "epoch: 4 Val acc: [0.5    0.5    0.5    0.518  0.5117 0.539  0.55   0.564  0.5703 0.5815\n",
      " 0.5815]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.40625    0.60416667 0.8125     0.82291667 0.85416667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.5        0.375      0.75       0.6875     0.70833333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.57291667 0.71875    0.77083333 0.82291667 0.8125    ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.5        0.72916667 0.75       0.72916667 0.75      ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.5625     0.58333333 0.88541667 0.89583333 0.88541667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.57291667 0.40625    0.66666667 0.73958333 0.72916667]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.60416667 0.83333333 0.85416667 0.80208333 0.77083333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.41666667 0.83333333 0.98958333 0.98958333 0.98958333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.58333333 0.71875    0.75       0.5625     0.69791667]\n",
      "epoch: 5 Val acc: [0.5    0.5176 0.487  0.4966 0.5024 0.5327 0.539  0.5605 0.5693 0.5747\n",
      " 0.582 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.47916667 0.70833333 0.70833333 0.76041667 0.90625   ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.66666667 0.63541667 0.80208333 0.82291667 0.8125    ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.5625     0.86458333 0.85416667 0.85416667 0.85416667]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.39583333 0.5        0.72916667 0.77083333 0.66666667]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.42708333 0.67708333 0.52083333 0.65625    0.6875     0.65625   ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.5        0.52083333 0.6875     0.57291667 0.67708333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.65625    0.73958333 0.75       0.73958333 0.76041667]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.51041667 0.65625    0.85416667 0.8125     0.85416667 0.8125    ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.52083333 0.61458333 0.98958333 0.96875    0.97916667 0.97916667]\n",
      "epoch: 6 Val acc: [0.4983 0.5093 0.4993 0.4966 0.5127 0.504  0.5234 0.5156 0.5386 0.5312\n",
      " 0.558 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.48958333 0.67708333 0.625      0.625      0.6875     0.65625   ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.53125    0.82291667 0.75       0.79166667 0.72916667 0.85416667]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.52083333 0.51041667 0.69791667 0.71875    0.70833333 0.71875   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.59375    0.76041667 0.80208333 0.85416667 0.84375    0.84375   ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.69791667 0.875      0.875      0.875      0.96875   ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.51041667 0.60416667 0.84375    0.84375    0.84375    0.88541667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.48958333 0.48958333 0.8125     0.78125    0.85416667 0.82291667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.45833333 0.45833333 0.625      0.6875     0.77083333 0.79166667]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.52083333 0.54166667 0.46875    0.40625    0.42708333 0.61458333]\n",
      "epoch: 7 Val acc: [0.5127 0.488  0.507  0.4958 0.5156 0.505  0.5273 0.523  0.548  0.5386\n",
      " 0.5674]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.52083333 0.6875     0.72916667 0.78125    0.85416667 0.82291667]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.52083333 0.79166667 0.84375    0.83333333 0.9375     0.9375    ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.57291667 0.5625     0.66666667 0.61458333 0.67708333 0.5625    ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.48958333 0.5        0.83333333 0.8125     0.95833333 0.86458333]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.47916667 0.64583333 0.57291667 0.625      0.77083333 0.76041667]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.46875    0.8125     0.69791667 0.77083333 0.72916667 0.73958333]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.48958333 0.88541667 0.83333333 0.85416667 0.82291667 0.86458333]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.69791667 0.69791667 0.71875    0.71875    0.91666667]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.625      0.89583333 0.94791667 0.91666667 0.90625   ]\n",
      "epoch: 8 Val acc: [0.5073 0.4907 0.5024 0.522  0.5376 0.5273 0.544  0.5444 0.555  0.5522\n",
      " 0.5654]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.72916667 0.80208333 0.89583333 0.82291667 0.91666667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.51041667 0.52083333 0.86458333 0.79166667 0.86458333 0.79166667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.51041667 0.66666667 0.78125    0.86458333 0.83333333 0.83333333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.47916667 0.5625     0.76041667 0.875      0.85416667 0.86458333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.51041667 0.51041667 0.5625     0.60416667 0.66666667 0.65625   ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.51041667 0.64583333 0.78125    0.77083333 0.76041667 0.73958333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.48958333 0.5        0.33333333 0.54166667 0.48958333 0.55208333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.73958333 0.875      0.77083333 0.77083333 0.76041667]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.5        0.67708333 0.61458333 0.70833333 0.71875   ]\n",
      "epoch: 9 Val acc: [0.5005 0.5137 0.4993 0.4858 0.5127 0.5376 0.5366 0.5576 0.5605 0.5884\n",
      " 0.5874]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.45833333 0.45833333 0.61458333 0.60416667 0.69791667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.48958333 0.54166667 0.58333333 0.53125    0.61458333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.625      0.875      0.92708333 0.91666667 0.92708333]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.63541667 0.73958333 0.9375     0.875      0.97916667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.5        0.67708333 0.70833333 0.69791667 0.77083333 0.75      ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.51041667 0.54166667 0.85416667 0.875      0.95833333 0.86458333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.48958333 0.75       0.88541667 0.91666667 0.95833333 0.96875   ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5        0.625      0.71875    0.83333333 0.90625    0.90625   ]\n",
      "Test acc: [0.5    0.4539 0.556  0.5913 0.702  0.7114 0.7476 0.771  0.781  0.7944\n",
      " 0.815 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 792.28it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1214.33it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 427.17it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 39.91it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5        0.5        0.42708333 0.5        0.5        0.5       ]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.4922 0.4978 0.4817 0.4954 0.5    0.5    0.5\n",
      " 0.5   ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.5   0.375 0.5   0.5   0.5   0.5  ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.45833333 0.51041667 0.5        0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.46875    0.51041667 0.51041667 0.51041667 0.51041667 0.51041667]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.5        0.58333333 0.55208333 0.51041667 0.5        0.5       ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.5        0.51041667 0.51041667 0.5        0.5        0.5       ]\n",
      "epoch: 1 Val acc: [0.5    0.6826 0.595  0.536  0.5137 0.507  0.5044 0.5034 0.5034 0.5034\n",
      " 0.5034]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.35416667 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.5        0.5        0.57291667 0.52083333 0.51041667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5        0.5        0.39583333 0.40625    0.41666667 0.39583333]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5        0.58333333 0.64583333 0.69791667 0.65625    0.65625   ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.34375    0.53125    0.61458333 0.625      0.625      0.60416667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.5        0.57291667 0.70833333 0.63541667 0.64583333 0.61458333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.5        0.5        0.5625     0.63541667 0.63541667 0.60416667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.52083333 0.58333333 0.70833333 0.6875     0.71875    0.59375   ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.58333333 0.69791667 0.67708333 0.73958333 0.78125    0.69791667]\n",
      "epoch: 2 Val acc: [0.522  0.5083 0.5923 0.602  0.655  0.7144 0.7754 0.794  0.8135 0.8247\n",
      " 0.836 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.5        0.625      0.58333333 0.53125    0.51041667]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.44791667 0.51041667 0.59375    0.78125    0.73958333 0.76041667]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.51041667 0.54166667 0.57291667 0.40625    0.47916667 0.48958333]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5        0.64583333 0.57291667 0.70833333 0.77083333 0.8125    ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.5625     0.625      0.59375    0.83333333 0.64583333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5        0.625      0.57291667 0.52083333 0.65625    0.59375   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.5        0.625      0.57291667 0.5625     0.5625    ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5        0.5        0.71875    0.52083333 0.52083333 0.52083333]\n",
      "epoch: 3 Val acc: [0.5    0.5    0.5    0.5093 0.6323 0.6523 0.6455 0.6216 0.6    0.5825\n",
      " 0.573 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.53125    0.53125    0.54166667 0.54166667 0.54166667]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.40625    0.5        0.5        0.55208333 0.61458333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.59375    0.48958333 0.51041667 0.52083333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.5        0.5        0.51041667 0.5        0.5       ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.52083333 0.51041667 0.625      0.67708333 0.70833333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.5        0.59375    0.58333333 0.61458333 0.61458333]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.53125    0.53125    0.64583333 0.76041667 0.76041667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.63541667 0.66666667 0.51041667 0.69791667 0.48958333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.46875    0.40625    0.59375    0.53125    0.54166667]\n",
      "epoch: 4 Val acc: [0.5    0.5024 0.708  0.677  0.6777 0.716  0.7686 0.8027 0.8335 0.8433\n",
      " 0.86  ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.54166667 0.59375    0.65625    0.625      0.64583333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.70833333 0.64583333 0.6875     0.83333333 0.875     ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.3125     0.59375    0.72916667 0.59375    0.80208333 0.77083333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.70833333 0.65625    0.67708333 0.80208333 0.80208333 0.92708333]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.54166667 0.5        0.60416667 0.60416667 0.79166667 0.63541667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.45833333 0.52083333 0.60416667 0.66666667 0.64583333 0.6875    ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.52083333 0.57291667 0.625      0.63541667 0.66666667 0.59375   ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.625      0.86458333 0.82291667 0.77083333 0.86458333 0.77083333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.46875    0.47916667 0.53125    0.65625    0.72916667 0.85416667]\n",
      "epoch: 5 Val acc: [0.5156 0.5503 0.6543 0.7065 0.783  0.835  0.883  0.893  0.911  0.916\n",
      " 0.937 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.48958333 0.47916667 0.78125    0.75       0.76041667]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.52083333 0.5        0.5        0.42708333 0.64583333 0.6875    ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.375      0.625      0.625      0.83333333 0.8125     0.89583333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.51041667 0.5        0.60416667 0.86458333 0.89583333 0.89583333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.52083333 0.54166667 0.69791667 0.53125    0.60416667]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.67708333 0.625      0.54166667 0.5625     0.75       0.64583333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.58333333 0.65625    0.67708333 0.64583333 0.66666667 0.73958333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.48958333 0.54166667 0.625      0.80208333 0.84375   ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.5        0.54166667 0.6875     0.59375    0.625     ]\n",
      "epoch: 6 Val acc: [0.4995 0.578  0.696  0.6694 0.707  0.768  0.868  0.8877 0.9253 0.917\n",
      " 0.944 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.42708333 0.5        0.375      0.70833333 0.75       0.73958333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.59375    0.54166667 0.58333333 0.69791667 0.64583333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.55208333 0.71875    0.64583333 0.70833333 0.77083333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.5        0.8125     0.73958333 0.78125    0.77083333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 150 \ttraining acc: [0.51041667 0.5        0.53125    0.66666667 0.55208333 0.625     ]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.47916667 0.64583333 0.65625    0.82291667 0.79166667 0.82291667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.66666667 0.65625    0.80208333 0.78125    0.76041667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.80208333 0.86458333 0.875      0.875      0.875     ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.48958333 0.94791667 0.85416667 0.96875    0.84375    0.97916667]\n",
      "epoch: 7 Val acc: [0.506  0.5977 0.7354 0.9136 0.9233 0.955  0.948  0.9414 0.9263 0.935\n",
      " 0.9233]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.58333333 0.54166667 0.73958333 0.71875    0.72916667]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.59375    0.75       0.70833333 0.72916667 0.63541667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.47916667 0.375      0.25       0.375      0.38541667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.69791667 0.64583333 0.86458333 0.83333333 0.90625   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5   0.75  0.75  0.875 1.    1.   ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5        0.51041667 0.625      0.57291667 0.625      0.5625    ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5        0.72916667 0.6875     0.86458333 0.8125     0.85416667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.48958333 0.57291667 0.625      0.73958333 0.73958333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.5        0.65625    0.70833333 0.78125    0.76041667]\n",
      "epoch: 8 Val acc: [0.5    0.5    0.523  0.6997 0.836  0.8936 0.9478 0.9414 0.964  0.9614\n",
      " 0.968 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.5        0.5        0.71875    0.73958333 0.75      ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.63541667 0.44791667 0.61458333 0.64583333 0.69791667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.48958333 0.55208333 0.625      0.61458333 0.84375    0.875     ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.6875     0.5625     0.55208333 0.375      0.38541667]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.69791667 0.70833333 0.67708333 0.72916667 0.80208333]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5        0.63541667 0.71875    0.63541667 0.8125     0.69791667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5625     0.70833333 0.73958333 0.76041667 0.71875    0.75      ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.52083333 0.5        0.60416667 0.58333333 0.71875   ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.5625     0.64583333 0.70833333 0.73958333 0.72916667]\n",
      "epoch: 9 Val acc: [0.4866 0.52   0.5767 0.5503 0.804  0.9067 0.922  0.949  0.9536 0.9624\n",
      " 0.9624]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.27083333 0.89583333 0.83333333 0.85416667 0.80208333 0.85416667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.26041667 0.71875    0.67708333 0.64583333 0.70833333 0.82291667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.54166667 0.625      0.71875    0.63541667 0.6875    ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.5        0.61458333 0.71875    0.73958333 0.88541667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.61458333 0.58333333 0.63541667 0.625      0.70833333 0.75      ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5        0.625      0.55208333 0.55208333 0.5625     0.53125   ]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.5        0.5        0.70833333 0.8125     0.80208333 0.86458333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5        0.5        0.47916667 0.52083333 0.45833333 0.58333333]\n",
      "Test acc: [0.5    0.5    0.4988 0.5005 0.4995 0.5015 0.5015 0.5    0.5034 0.5015\n",
      " 0.505 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 615.72it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 941.17it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 392.39it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.96it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.5    0.4924 0.4941 0.4958 0.5005 0.487  0.4854\n",
      " 0.4917]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.5        0.45833333 0.5        0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.5        0.5        0.52083333 0.55208333 0.57291667 0.58333333]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.5        0.51041667 0.51041667 0.51041667 0.51041667 0.51041667]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5        0.59375    0.55208333 0.55208333 0.5625     0.55208333]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.51041667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5        0.66666667 0.75       0.78125    0.77083333 0.77083333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.48958333 0.48958333 0.57291667 0.63541667 0.59375    0.63541667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.5        0.63541667 0.64583333 0.69791667 0.6875     0.66666667]\n",
      "epoch: 1 Val acc: [0.505  0.509  0.523  0.535  0.544  0.558  0.572  0.593  0.5947 0.601\n",
      " 0.6133]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.42708333 0.64583333 0.76041667 0.79166667 0.71875    0.77083333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.48958333 0.73958333 0.73958333 0.77083333 0.78125    0.82291667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.4375     0.32291667 0.66666667 0.51041667 0.70833333 0.75      ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.16666667 0.375      0.66666667 0.72916667 0.72916667 0.72916667]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.51041667 0.95833333 0.95833333 0.95833333 0.95833333 0.94791667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.57291667 0.60416667 0.52083333 0.52083333 0.5625     0.5625    ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.64583333 0.64583333 0.76041667 0.76041667 0.76041667 0.76041667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.39583333 0.53125    0.61458333 0.59375    0.58333333 0.58333333]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.39583333 0.75       0.73958333 0.67708333 0.63541667 0.61458333]\n",
      "epoch: 2 Val acc: [0.5    0.5    0.5    0.501  0.507  0.5234 0.542  0.5684 0.5835 0.5933\n",
      " 0.598 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.51041667 0.75       0.70833333 0.64583333 0.61458333 0.625     ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.47916667 0.63541667 0.67708333 0.60416667 0.61458333 0.61458333]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.625      0.70833333 0.70833333 0.71875    0.70833333]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.61458333 0.5        0.5625     0.5        0.5       ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5     0.5     0.5     0.5     0.5     0.53125]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.57291667 0.54166667 0.48958333 0.57291667 0.54166667 0.54166667]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.39583333 0.51041667 0.51041667 0.51041667 0.53125    0.58333333]\n",
      "epoch: 3 Val acc: [0.4924 0.5337 0.5596 0.572  0.573  0.5713 0.5703 0.5723 0.5693 0.568\n",
      " 0.568 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.625      0.55208333 0.66666667 0.58333333 0.70833333]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.5        0.44791667 0.40625    0.44791667 0.46875   ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.5        0.57291667 0.6875     0.84375   ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.51041667 0.65625    0.69791667 0.8125     0.70833333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.60416667 0.57291667 0.625      0.64583333 0.66666667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.52083333 0.42708333 0.52083333 0.40625    0.5       ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.75       0.98958333 0.82291667 0.9375     0.86458333]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.64583333 0.85416667 0.72916667 0.79166667 0.80208333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.41666667 0.61458333 0.41666667 0.625      0.60416667]\n",
      "epoch: 4 Val acc: [0.5    0.518  0.5195 0.5024 0.5195 0.5254 0.5366 0.5444 0.551  0.5557\n",
      " 0.5635]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.5        0.52083333 0.52083333 0.53125    0.53125   ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.5625     0.75       0.70833333 0.75       0.75      ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.5        0.625      0.80208333 0.65625    0.64583333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.5        0.61458333 0.67708333 0.69791667 0.6875    ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.36458333 0.75       0.82291667 0.83333333 0.8125    ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.75       0.80208333 0.88541667 0.76041667 0.80208333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.75       0.72916667 0.83333333 0.85416667 0.86458333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.5        0.51041667 0.55208333 0.70833333 0.75      ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.48958333 0.5        0.48958333 0.46875    0.61458333 0.58333333]\n",
      "epoch: 5 Val acc: [0.4958 0.521  0.537  0.523  0.524  0.5527 0.5425 0.55   0.5537 0.588\n",
      " 0.5825]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5     0.5     0.46875 0.53125 0.65625 0.65625]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.5        0.5        0.63541667 0.60416667 0.625     ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.57291667 0.6875     0.69791667 0.79166667 0.6875    ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.63541667 0.77083333 0.70833333 0.625      0.61458333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.78125    0.8125     0.875      0.80208333 0.79166667]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.5        0.65625    0.625      0.63541667 0.625     ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.5        0.30208333 0.5        0.54166667 0.61458333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.55208333 0.44791667 0.60416667 0.84375    0.78125   ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.61458333 0.73958333 0.63541667 0.70833333 0.77083333]\n",
      "epoch: 6 Val acc: [0.5    0.558  0.558  0.5884 0.55   0.5576 0.5537 0.57   0.5728 0.598\n",
      " 0.6123]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.41666667 0.625      0.77083333 0.85416667 0.77083333 0.75      ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.48958333 0.85416667 0.98958333 0.98958333 0.98958333 0.98958333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.5        0.75       0.85416667 0.75       0.98958333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.60416667 0.5        0.63541667 0.46875    0.59375   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 150 \ttraining acc: [0.5        0.53125    0.66666667 0.79166667 0.9375     0.94791667]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.5        0.66666667 0.70833333 0.73958333 0.73958333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.72916667 0.625      0.72916667 0.8125     0.77083333]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.54166667 0.67708333 0.6875     0.8125     0.83333333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.57291667 0.78125    0.75       0.75       0.70833333]\n",
      "epoch: 7 Val acc: [0.5    0.5    0.5303 0.556  0.5864 0.59   0.6294 0.6094 0.649  0.6157\n",
      " 0.646 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.28125    0.48958333 0.70833333 0.97916667 0.86458333 0.95833333]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.4375     0.5        0.5        0.80208333 0.80208333 0.79166667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.52083333 0.625      0.625      0.625      0.58333333]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.82291667 0.71875    0.82291667 0.75       0.84375   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.5        0.66666667 0.625      0.67708333 0.72916667 0.77083333]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.63541667 0.71875    0.67708333 0.78125    0.80208333 0.85416667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.375      0.52083333 0.8125     0.85416667 0.875      0.85416667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.75       0.66666667 0.625      0.77083333 0.75      ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.625      0.71875    0.71875    0.86458333 0.86458333]\n",
      "epoch: 8 Val acc: [0.5    0.511  0.507  0.5    0.504  0.5044 0.5063 0.5083 0.5186 0.524\n",
      " 0.53  ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.48958333 0.60416667 0.59375    0.61458333 0.73958333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.59375    0.73958333 0.8125     0.8125     0.83333333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.48958333 0.5        0.5625     0.59375    0.70833333 0.79166667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.70833333 0.67708333 0.63541667 0.6875     0.63541667]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.75       0.82291667 0.79166667 0.8125     0.84375   ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.32291667 0.84375    0.8125     0.83333333 0.84375    0.88541667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.58333333 0.72916667 0.60416667 0.67708333 0.60416667 0.6875    ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.44791667 0.78125    0.85416667 0.85416667 0.875     ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.54166667 0.71875    0.6875     0.91666667 0.92708333 0.9375    ]\n",
      "epoch: 9 Val acc: [0.5    0.5    0.579  0.513  0.554  0.541  0.5493 0.596  0.5947 0.6113\n",
      " 0.605 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.4375     0.59375    0.67708333 0.83333333 0.86458333]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.60416667 0.54166667 0.51041667 0.4375     0.51041667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.5        0.51041667 0.58333333 0.64583333 0.78125   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.48958333 0.51041667 0.71875    0.60416667 0.69791667 0.76041667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.52083333 0.5        0.75       0.75       0.75       0.80208333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.52083333 0.72916667 0.86458333 0.8125     0.86458333 0.82291667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.52083333 0.5625     0.55208333 0.875      0.875      0.875     ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.55208333 0.70833333 0.66666667 0.79166667 0.82291667 0.84375   ]\n",
      "Test acc: [0.5    0.921  0.9995 1.     1.     1.     1.     1.     1.     1.\n",
      " 1.    ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 706.11it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 928.87it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 394.60it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.72it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 Val acc: [0.523  0.5225 0.5234 0.523  0.522  0.5225 0.5215 0.5215 0.5215 0.521\n",
      " 0.5215]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 0 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 390 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 Val acc: [0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215\n",
      " 0.5215]\n",
      "epoch: 0 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 570 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 630 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 0 step: 660 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 990 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215 0.5215\n",
      " 0.5215]\n",
      "epoch: 1 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 1 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 480 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 Val acc: [0.5215 0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522\n",
      " 0.522 ]\n",
      "epoch: 1 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 930 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.5215 0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522\n",
      " 0.522 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 330 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 480 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 Val acc: [0.5215 0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522\n",
      " 0.522 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 540 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 660 \ttraining acc: [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "epoch: 2 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 780 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 990 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 Val acc: [0.5215 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225\n",
      " 0.5225]\n",
      "epoch: 3 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 300 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 390 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 Val acc: [0.522  0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225\n",
      " 0.5225]\n",
      "epoch: 3 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 570 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 step: 630 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 660 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 690 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 780 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.5225 0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.5234\n",
      " 0.523 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 300 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 330 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 390 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 480 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 Val acc: [0.5225 0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.523\n",
      " 0.523 ]\n",
      "epoch: 4 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.523  0.5234 0.5234\n",
      " 0.5234]\n",
      "epoch: 5 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 420 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 480 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 Val acc: [0.522  0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225\n",
      " 0.5225]\n",
      "epoch: 5 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 660 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 780 \ttraining acc: [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "epoch: 5 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 900 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 Val acc: [0.522  0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225 0.5225\n",
      " 0.5225]\n",
      "epoch: 6 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 300 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 Val acc: [0.522  0.5225 0.522  0.522  0.522  0.522  0.522  0.522  0.522  0.522\n",
      " 0.522 ]\n",
      "epoch: 6 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 660 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 690 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 810 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 840 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 900 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 Val acc: [0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523]\n",
      "epoch: 7 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 330 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 360 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 390 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 420 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523 0.523]\n",
      "epoch: 7 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 570 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 960 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 step: 990 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 Val acc: [0.5273 0.5273 0.5273 0.5273 0.5273 0.5273 0.5273 0.5273 0.5273 0.5273\n",
      " 0.5273]\n",
      "epoch: 8 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 Val acc: [0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283\n",
      " 0.5283]\n",
      "epoch: 8 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 540 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 690 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 720 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283 0.5283\n",
      " 0.5283]\n",
      "epoch: 9 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.528 0.528 0.528 0.528 0.528 0.528 0.528 0.528 0.528 0.528 0.528]\n",
      "epoch: 9 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 570 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 660 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 690 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 840 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 900 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 990 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "Test acc: [0.925 0.925 0.925 0.925 0.925 0.925 0.925 0.925 0.925 0.925 0.925]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 839.70it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1528.82it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 467.45it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 38.41it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 0 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 0 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 0 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 0 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 330 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 0 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 0 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 0 step: 510 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 600 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 step: 630 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 0 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 step: 780 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 810 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 990 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.08333334 0.08333334 0.08333334 0.08333334 0.08333334 0.08333334]\n",
      "epoch: 1 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 1 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 1 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 300 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 330 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 1 step: 360 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 1 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 540 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 570 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 1 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 630 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 1 step: 660 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 690 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 1 step: 720 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 750 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 810 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 870 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 930 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 990 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 360 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 390 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 2 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 540 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 2 step: 570 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 720 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 780 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 2 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 870 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 2 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 3 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 270 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 3 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 390 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 420 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 480 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 3 step: 510 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 3 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 840 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 3 step: 930 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 990 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 4 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 300 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 360 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 4 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 600 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 4 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 690 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 4 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 750 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 4 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 960 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 4 step: 990 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 5 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 300 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 390 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 5 step: 420 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 5 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 510 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 540 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 570 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 630 \ttraining acc: [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "epoch: 5 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 810 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 5 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 900 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 5 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 6 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 360 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 390 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 6 step: 510 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 540 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 690 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 6 step: 720 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 6 step: 780 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 6 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 840 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 6 step: 870 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 6 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 7 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 360 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 390 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 7 step: 510 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 570 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 7 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 840 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 7 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 930 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 8 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 8 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 300 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 330 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 8 step: 360 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 390 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 8 step: 420 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 510 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 540 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 630 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 660 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 690 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 720 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 840 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 900 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 8 step: 930 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 9 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 390 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 9 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 540 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 600 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 750 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 870 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "Test acc: [0.9927 0.9927 0.9927 0.9927 0.9927 0.9927 0.9927 0.9927 0.9927 0.9927\n",
      " 0.9927]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 566.26it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1001.98it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 371.00it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 36.52it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 Val acc: [0.653  0.657  0.6562 0.6553 0.655  0.6553 0.656  0.6562 0.6553 0.6543\n",
      " 0.655 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 360 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 0 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 450 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 Val acc: [0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66]\n",
      "epoch: 0 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 600 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 0 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 900 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 930 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 990 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 Val acc: [0.6987 0.6987 0.6987 0.6987 0.6987 0.6987 0.6987 0.6987 0.6987 0.6987\n",
      " 0.6987]\n",
      "epoch: 1 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 300 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 1 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807\n",
      " 0.6807]\n",
      "epoch: 1 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 540 \ttraining acc: [0.08333334 0.08333334 0.08333334 0.08333334 0.08333334 0.08333334]\n",
      "epoch: 1 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 690 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 750 \ttraining acc: [0.08333334 0.08333334 0.08333334 0.08333334 0.08333334 0.08333334]\n",
      "epoch: 1 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 810 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 870 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 step: 900 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807 0.6807\n",
      " 0.6807]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 2 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 270 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 420 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 450 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 2 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 540 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 2 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 2 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 690 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 900 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 3 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 3 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 420 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 3 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 480 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 3 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 870 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 990 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 4 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 360 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 390 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 480 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 4 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 600 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 690 \ttraining acc: [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "epoch: 4 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 750 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 810 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 4 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 930 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 4 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 990 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 330 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 5 step: 510 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 540 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 5 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 630 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 750 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 5 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 930 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 6 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 300 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 6 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 420 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 6 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 570 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 6 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 660 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 720 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 900 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 7 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 390 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 7 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 810 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 7 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 990 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 480 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 8 step: 510 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 630 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 780 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 840 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 870 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 300 \ttraining acc: [0.08333334 0.08333334 0.08333334 0.08333334 0.08333334 0.08333334]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 390 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 Val acc: [0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675 0.675]\n",
      "epoch: 9 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 540 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 9 step: 570 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 660 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 720 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 750 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 930 \ttraining acc: [0.08333334 0.08333334 0.08333334 0.08333334 0.08333334 0.08333334]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "Test acc: [0.9204 0.9204 0.9204 0.9204 0.9204 0.9204 0.9204 0.9204 0.9204 0.9204\n",
      " 0.9204]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 870.37it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1644.83it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 509.62it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 34.23it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5       0.5       0.5       0.6666667 0.7916667 0.875    ]\n",
      "epoch: 0 Val acc: [0.972  0.9727 0.9727 0.973  0.973  0.973  0.973  0.973  0.973  0.9727\n",
      " 0.973 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 0 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 330 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 0 step: 510 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 540 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 step: 570 \ttraining acc: [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "epoch: 0 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 630 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 660 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 0 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 0 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 840 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 870 \ttraining acc: [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "epoch: 0 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 1 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 1 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 630 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 1 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 720 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 780 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 1 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 960 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 Val acc: [0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 2 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 2 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 480 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 Val acc: [0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976]\n",
      "epoch: 2 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 660 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 810 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 840 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 870 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 990 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 3 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 450 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 Val acc: [0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746\n",
      " 0.9746]\n",
      "epoch: 3 step: 510 \ttraining acc: [0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667]\n",
      "epoch: 3 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 570 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 720 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 750 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 3 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 960 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 4 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 300 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 420 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 450 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 4 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746\n",
      " 0.9746]\n",
      "epoch: 4 step: 510 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 4 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 660 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 690 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 720 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 750 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 900 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746\n",
      " 0.9746]\n",
      "epoch: 5 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 5 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976]\n",
      "epoch: 5 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 570 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 600 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 690 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 5 step: 720 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 780 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 930 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 5 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 Val acc: [0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975]\n",
      "epoch: 6 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 270 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.7083333 0.875     0.9166667]\n",
      "epoch: 6 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "epoch: 6 step: 360 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 6 Val acc: [0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 6 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 600 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 630 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 660 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 690 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 780 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 900 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 960 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 990 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.942 0.942 0.942 0.942 0.942 0.942 0.942 0.942 0.942 0.942 0.942]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 420 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975]\n",
      "epoch: 7 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 570 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 600 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 810 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 900 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 270 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 300 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 330 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 8 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 480 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 Val acc: [0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746 0.9746\n",
      " 0.9746]\n",
      "epoch: 8 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 720 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 Val acc: [0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 420 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 9 Val acc: [0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976 0.976]\n",
      "epoch: 9 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 660 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 810 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 9 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 870 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "Test acc: [0.493 0.493 0.493 0.493 0.493 0.493 0.493 0.493 0.493 0.493 0.493]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 862.67it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1508.20it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 310.10it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 35.33it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.45833334 0.45833334 0.375      0.33333334 0.33333334 0.25      ]\n",
      "epoch: 0 Val acc: [0.6787 0.6807 0.681  0.681  0.6816 0.6816 0.6816 0.682  0.682  0.6816\n",
      " 0.6816]\n",
      "epoch: 0 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 300 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 0 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 390 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 0 step: 420 \ttraining acc: [0.9166667 0.9166667 0.875     0.875     0.7916667 0.875    ]\n",
      "epoch: 0 step: 450 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 0 Val acc: [0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665]\n",
      "epoch: 0 step: 510 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 0 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 660 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 0 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 960 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 0 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 Val acc: [0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665]\n",
      "epoch: 1 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 300 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 390 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 420 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 450 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665]\n",
      "epoch: 1 step: 510 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 570 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 600 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 660 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 780 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 990 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665]\n",
      "epoch: 2 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 270 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 390 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 2 step: 420 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 450 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 2 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 Val acc: [0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666]\n",
      "epoch: 2 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 690 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 750 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 step: 780 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 Val acc: [0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666]\n",
      "epoch: 3 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 270 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 3 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 420 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 480 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 Val acc: [0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666 0.666]\n",
      "epoch: 3 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 540 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 570 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 630 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 3 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 750 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 3 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 810 \ttraining acc: [0.04166667 0.04166667 0.04166667 0.04166667 0.04166667 0.04166667]\n",
      "epoch: 3 step: 840 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 3 step: 870 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 330 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 4 step: 360 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 390 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 4 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 4 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "epoch: 4 step: 660 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 4 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 720 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 810 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 870 \ttraining acc: [0.29166666 0.29166666 0.29166666 0.29166666 0.29166666 0.29166666]\n",
      "epoch: 4 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 930 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 300 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 330 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 5 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 660 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 5 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 780 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 5 step: 810 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 900 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 360 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 390 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 6 step: 510 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 570 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 6 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 690 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 780 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 7 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 360 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 420 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 7 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 7 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 690 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 840 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 8 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 330 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 8 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 450 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 8 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 540 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 570 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 630 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 660 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 690 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 750 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 780 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 930 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 8 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 990 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 9 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655 0.6655\n",
      " 0.6655]\n",
      "epoch: 9 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 390 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 420 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 Val acc: [0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665 0.665]\n",
      "epoch: 9 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 570 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 600 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 660 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 690 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 750 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 780 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 9 step: 810 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "Test acc: [0.9976 0.9976 0.9976 0.9976 0.9976 0.9976 0.9976 0.9976 0.9976 0.9976\n",
      " 0.9976]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=1, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 109.40it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 849.31it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 303.47it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 35.79it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.9895833 0.9166667 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 0 Val acc: [0.523  0.5273 0.5273 0.5264 0.5254 0.527  0.5234 0.522  0.521  0.5215\n",
      " 0.5215]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.9375    0.8333333 0.875     0.8854167 0.90625   0.90625  ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9479167 0.9375    0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.78125    0.6458334  0.7083334  0.75       0.7291666  0.74999994]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.7083334 0.7083334 0.7083334 0.7083334 0.7083334 0.7083334]\n",
      "epoch: 0 step: 150 \ttraining acc: [1.        0.8958333 0.9583333 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.9270833 0.8854166 0.8854166 0.8854166 0.8645834 0.8645834]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.8645833 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.9895833 0.9166667 0.9583333 0.96875   0.9791667 0.9791667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.9791667 0.9895833 0.9895833 0.9895833 0.9895833 0.9791667]\n",
      "epoch: 1 Val acc: [0.5146 0.5215 0.5225 0.522  0.5215 0.5225 0.521  0.5225 0.523  0.5225\n",
      " 0.5215]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.8645834 0.8854167 0.8854167 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.75      0.6979167 0.7083333 0.7083333 0.6979166 0.7083333]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9895833 0.9791667 0.9791667 0.9791667 0.9895833 0.9895833]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9479166 0.875     0.8541666 0.875     0.8958333 0.90625  ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9270833 0.8645833 0.8958333 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8020834 0.7916667 0.7916667 0.7916667 0.7916667 0.78125  ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9583333 0.8229166 0.8854166 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.7604167 0.7604167 0.7708333 0.7708333 0.75      0.7395833]\n",
      "epoch: 2 step: 0 \ttraining acc: [1.        1.        1.        0.9895833 1.        1.       ]\n",
      "epoch: 2 Val acc: [0.513  0.5146 0.518  0.5205 0.5205 0.5195 0.5156 0.522  0.5215 0.515\n",
      " 0.521 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.9479166 0.8958334 0.8958334 0.8854167 0.875     0.875    ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9270833 0.8958333 0.9270833 0.9270834 0.9270834 0.9479167]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.96875   0.9166667 0.9583333 1.        0.96875   0.96875  ]\n",
      "epoch: 2 step: 120 \ttraining acc: [1.        0.8645833 0.9270833 0.9583333 0.96875   0.9791667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.8020833 0.6041667 0.6354167 0.6666667 0.71875   0.7395833]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.8645834 0.9270833 0.9270833 0.9270833 0.9270833 0.9166667]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8229166 0.7916667 0.8229166 0.8229166 0.8229166 0.8229166]\n",
      "epoch: 2 step: 240 \ttraining acc: [1.        0.9791666 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8958333 0.875     0.875     0.875     0.8854167 0.8854167]\n",
      "epoch: 3 Val acc: [0.515  0.5205 0.5234 0.5234 0.5225 0.524  0.524  0.522  0.5215 0.52\n",
      " 0.5205]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.9375    0.8645833 0.8541667 0.8541667 0.875     0.8854167]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.9270833 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.875     0.8333334 0.8229167 0.8229167 0.84375   0.875    ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.8958334 0.8958333 0.8854167 0.8854167 0.875     0.875    ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8854167 0.8229167 0.84375   0.8645834 0.875     0.8854167]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.8958334 0.71875   0.75      0.78125   0.7916667 0.8125   ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.8541667 0.7395833 0.7708333 0.7916667 0.8020833 0.8125   ]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 4 Val acc: [0.5137 0.5215 0.5215 0.5234 0.521  0.5205 0.521  0.5215 0.5195 0.5205\n",
      " 0.521 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.8854166 0.8958333 0.9270833 0.9166666 0.90625   0.90625  ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.84375   0.7395833 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.7916667 0.7291667 0.7604167 0.7708334 0.7708334 0.7916667]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.75    0.78125 0.75    0.75    0.75    0.75   ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.9791667 0.6770833 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.9791667 0.8958333 0.9166667 0.9375    0.9583333 0.9791667]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8958333 0.8958333 0.9270833 0.9270833 0.9270833 0.9166667]\n",
      "epoch: 4 step: 240 \ttraining acc: [1.        0.8958333 0.9270834 0.9479166 0.9583333 0.9583333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.9791667 0.90625   0.9375    0.9479166 0.9895833 0.9791667]\n",
      "epoch: 5 Val acc: [0.5127 0.521  0.521  0.5215 0.5195 0.5186 0.5205 0.5215 0.5215 0.522\n",
      " 0.5225]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9791667 0.9166667 0.9166667 0.9270834 0.9583333 0.9583333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.90625    0.87499994 0.8333333  0.8333333  0.8541667  0.8333333 ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.78125 0.75    0.8125  0.8125  0.8125  0.8125 ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.96875 0.9375  0.9375  0.9375  0.9375  0.9375 ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.8125    0.8020833 0.8020833 0.78125   0.78125   0.8020833]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.9479167 0.96875   0.96875   0.9583333 0.9479167 0.9479167]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.9583333 0.9791667 0.9791667 0.9791667 0.9479167 1.       ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.9791667 0.9583334 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.7916667 0.78125   0.78125   0.78125   0.7916667 0.7916667]\n",
      "epoch: 6 Val acc: [0.514  0.523  0.5225 0.52   0.516  0.5176 0.518  0.5176 0.5205 0.5195\n",
      " 0.521 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.7708333 0.65625   0.75      0.7604166 0.7604166 0.7604166]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8020834 0.7604166 0.7916667 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.8645833 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.9895833 1.        0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.96875   0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.8958333 0.8229167 0.875     0.9166667 0.8958333 0.8958333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.96875   0.9270834 0.9375    0.9479167 0.96875   0.9791667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.96875   0.9583333 0.9583333 0.9583333 0.9479167 0.9479167]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9270834 0.875     0.875     0.875     0.8854167 0.90625  ]\n",
      "epoch: 7 Val acc: [0.512  0.5215 0.5205 0.5205 0.5205 0.5215 0.522  0.52   0.5215 0.521\n",
      " 0.52  ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9270834 0.9270834 0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.9166667 0.8541667 0.8854167 0.8958334 0.9166667 0.9166667]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.90625   0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 7 step: 120 \ttraining acc: [1.        0.9479167 0.9583333 0.9583333 0.9583333 0.9791667]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.96875 1.      1.      0.96875 0.96875 0.96875]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.96875 0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.87499994 0.87499994 0.87499994 0.87499994 0.87499994 0.87499994]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.9895833 0.9479167 0.9479167 0.9375    0.9375    0.9375   ]\n",
      "epoch: 8 Val acc: [0.515  0.516  0.5166 0.5186 0.519  0.5195 0.519  0.521  0.5195 0.5205\n",
      " 0.5205]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.9479167 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.9270833 0.96875   0.9583333 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9791666 1.        1.        1.        1.        0.9895833]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.71875 0.71875 0.71875 0.71875 0.71875 0.71875]\n",
      "epoch: 8 step: 180 \ttraining acc: [1.        0.9895833 1.        1.        1.        1.       ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.8333334  0.84375006 0.84375006 0.84375006 0.84375006 0.84375006]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.875      0.8541667  0.8645834  0.875      0.8645834  0.84375006]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.96875 0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 9 Val acc: [0.5146 0.5215 0.5205 0.521  0.5215 0.522  0.521  0.5234 0.524  0.5234\n",
      " 0.524 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.90624994 0.8645834  0.8645834  0.8958334  0.9166667  0.90625006]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.9270834 0.8958333 0.8958333 0.9166667 0.9270833 0.9270833]\n",
      "epoch: 9 step: 90 \ttraining acc: [1.        0.9791667 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 9 step: 120 \ttraining acc: [1.        0.9375    0.9479166 0.9479166 0.9479166 0.9583333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9166667 0.8854167 0.8958334 0.90625   0.90625   0.90625  ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.8541666 0.8333333 0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 9 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.93749994 0.90625    0.90625    0.9270833  0.9270833  0.9270833 ]\n",
      "Test acc: [0.933  0.8843 0.9087 0.914  0.9185 0.92   0.922  0.922  0.9233 0.923\n",
      " 0.922 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 1 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=2, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 494.26it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1243.68it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 400.69it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 37.59it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.8020833  0.71875    0.7395834  0.75000006 0.7604167  0.7708333 ]\n",
      "epoch: 0 Val acc: [0.9897 0.797  0.9917 0.991  0.9907 0.9907 0.99   0.99   0.99   0.99\n",
      " 0.99  ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.8854167 0.84375   0.84375   0.8541667 0.8541667 0.8541667]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.8541667 0.8020833 0.8020833 0.8229166 0.8229166 0.8229166]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.84375   0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.7916667 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.78125   0.75      0.78125   0.7708333 0.7708333 0.7604166]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.90625 0.90625 0.90625 0.90625 0.90625 0.90625]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.8333333 0.84375   0.84375   0.84375   0.84375   0.8541667]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.9791667 0.9166667 0.9479167 0.9583333 0.9791667 0.9791667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.7291666 0.7291666 0.7291666 0.7291666 0.7291666 0.7291666]\n",
      "epoch: 1 Val acc: [0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.90625   0.9166666 0.875     0.8854166 0.8541667 0.8645834]\n",
      "epoch: 1 step: 90 \ttraining acc: [1.        0.9270833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.90625 0.90625 0.90625 0.90625 0.90625 0.90625]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.9375    0.9270834 0.9375    0.9375    0.9583334 0.9479167]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.8229166 0.8333333 0.8229167 0.8125    0.8125    0.8125   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.8854167 0.9375    0.9375    0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.7708334 0.71875   0.7291667 0.7604167 0.7395833 0.7291667]\n",
      "epoch: 2 Val acc: [0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863\n",
      " 0.9863]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.6875    0.6979166 0.6979166 0.6770833 0.65625   0.6666667]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.8854166  0.87499994 0.87499994 0.87499994 0.87499994 0.87499994]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.8020833 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.84375 0.8125  0.8125  0.8125  0.8125  0.8125 ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.875     0.8958333 0.8854166 0.90625   0.8958333 0.90625  ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.7708333  0.8333333  0.84375    0.8541667  0.8645833  0.87499994]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.71875   0.71875   0.6979166 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 3 Val acc: [0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.7395833 0.7395834 0.7395834 0.7395834 0.7395834 0.7291667]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.78125006 0.78125006 0.78125006 0.78125006 0.78125006 0.78125006]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.84375   0.8333333 0.8333333 0.8333333 0.84375   0.8333333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8333333 0.84375   0.84375   0.84375   0.8229167 0.8125   ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.96875   0.9583334 0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.6979167 0.71875   0.71875   0.7291666 0.7291666 0.7291666]\n",
      "epoch: 4 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 Val acc: [0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863\n",
      " 0.9863]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.6979166 0.6875    0.6979166 0.6979166 0.6875    0.6875   ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.9375 0.9375 0.9375 0.9375 0.9375 0.9375]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.875     0.875     0.875     0.8645834 0.8645834 0.8854167]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.6979167 0.7083334 0.6979166 0.6979166 0.6979166 0.6979167]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5625    0.5833333 0.5833333 0.59375   0.6354167 0.65625  ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.8645834 0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.96875   0.96875   0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 Val acc: [0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863\n",
      " 0.9863]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.9375    0.9375    0.9270833 0.9375    0.9166667 0.9270833]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.8229167 0.8229166 0.84375   0.8229166 0.8229166 0.8333333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.96875 0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.96875   0.96875   0.96875   0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.75       0.7083333  0.7291667  0.7395834  0.75000006 0.75000006]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8645833 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.875     0.90625   0.90625   0.90625   0.8958333 0.8958333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.8958333 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 6 Val acc: [0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863\n",
      " 0.9863]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.8958334 0.9270833 0.9375    0.9166666 0.9166666 0.9166666]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8020833 0.7708333 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.8125 0.8125 0.8125 0.8125 0.8125 0.8125]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.6979166 0.7291666 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.7291666 0.7395833 0.7395833 0.7395833 0.7395833 0.7395833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 240 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9583333 0.9895833 0.96875   0.9375    0.9375    0.9375   ]\n",
      "epoch: 7 Val acc: [0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863 0.9863\n",
      " 0.9863]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.90625   0.90625   0.90625   0.90625   0.90625   0.8958333]\n",
      "epoch: 7 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.7291666 0.7291666 0.7291666 0.7291666 0.7291666 0.7291666]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.7395834 0.7604166 0.7604166 0.7604166 0.7604166 0.7708334]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.8541667 0.8333333 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9166667 0.8958333 0.8958334 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8541667 0.8541666 0.8645833 0.8645833 0.8541666 0.8541666]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.7708334 0.7708334 0.7708334 0.7708334 0.7708334 0.7708334]\n",
      "epoch: 8 Val acc: [0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987 0.987]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.8229167 0.7916667 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9479166 0.9270833 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.7708334 0.78125   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.84375   0.84375   0.84375  ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.6979167 0.71875   0.7083333 0.6979167 0.7083333 0.7083333]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.875     0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.8020833 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.71875   0.7291666 0.7395833 0.71875   0.7291666 0.7291667]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 9 Val acc: [0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897 0.9897\n",
      " 0.9897]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9270834 0.9270834 0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.71875   0.7604167 0.7291667 0.71875   0.71875   0.71875  ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.8645834 0.8854167 0.8854167 0.8854167 0.8854167 0.8958334]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.90624994 0.9583333  0.9375     0.9270833  0.9270833  0.9270833 ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.6354167 0.6354167 0.65625   0.6458334 0.6666667 0.6354167]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.7083333 0.7291667 0.7395833 0.7083333 0.6979166 0.6979166]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.7708334 0.7708333 0.7708333 0.7708334 0.7708334 0.7604167]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "Test acc: [0.9795 0.9814 0.9834 0.9844 0.9844 0.9854 0.9854 0.9844 0.985  0.985\n",
      " 0.985 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 2 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=3, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 404.19it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 801.28it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 309.67it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 40.30it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [1.        0.8854167 0.9791667 1.        1.        1.       ]\n",
      "epoch: 0 Val acc: [0.654  0.649  0.654  0.656  0.6567 0.655  0.66   0.6577 0.6577 0.6553\n",
      " 0.6567]\n",
      "epoch: 0 step: 30 \ttraining acc: [1.        0.90625   0.9270833 0.9375    0.9479167 0.9791666]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9791667 0.9375    0.9479167 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.8020834 0.8125    0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.9166667 0.9583333 0.9583333 0.9583333 0.9583333 0.9479167]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.7708333 0.7604166 0.75      0.75      0.75      0.75     ]\n",
      "epoch: 0 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 210 \ttraining acc: [1.        0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.8854167 0.8854166 0.875     0.875     0.8541666 0.84375  ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.8020834 0.7395833 0.7916667 0.7916667 0.7604167 0.7708334]\n",
      "epoch: 1 Val acc: [0.6616 0.6665 0.6675 0.666  0.666  0.6665 0.6646 0.664  0.6646 0.6636\n",
      " 0.6636]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.90625   0.875     0.8958333 0.8958333 0.90625   0.8958334]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.8541667 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.8229167 0.8333333 0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9479167 0.9375    0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9895833 0.9791666 0.9791666 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9583333 0.9375    0.9375    0.9375    0.9375    0.9479167]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.9479167 0.96875   0.96875   0.9583333 0.9583333 0.9479167]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.875     0.90625   0.90625   0.90625   0.9166667 0.9270834]\n",
      "epoch: 2 Val acc: [0.6562 0.6636 0.661  0.662  0.6577 0.6587 0.655  0.66   0.655  0.658\n",
      " 0.657 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.9791667 0.9583333 0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9375    0.875     0.875     0.875     0.8854167 0.9166667]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.9375    0.90625   0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.9270834  0.9270833  0.9270833  0.9270833  0.9375     0.93749994]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.9166667 0.8958334 0.9270834 0.9270834 0.9166667 0.9166667]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.9895833 0.9583333 0.9583333 0.9583333 0.9583333 0.9375   ]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8541667 0.53125   0.7708334 0.7604167 0.7916667 0.8020834]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.8333333  0.65625    0.65625    0.65624994 0.68749994 0.7291667 ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8854167 0.875     0.90625   0.90625   0.9166667 0.9270833]\n",
      "epoch: 3 Val acc: [0.64   0.646  0.647  0.649  0.6455 0.6455 0.644  0.647  0.647  0.648\n",
      " 0.6465]\n",
      "epoch: 3 step: 30 \ttraining acc: [1.        0.90625   0.9479167 1.        1.        1.       ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.9479166 0.8854167 0.9166667 0.9166667 0.9270833 0.9270833]\n",
      "epoch: 3 step: 90 \ttraining acc: [1.        0.8958333 0.8958333 0.8958333 0.9166666 0.9479166]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.875     0.7083333 0.75      0.7708333 0.7916666 0.8229167]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8854167 0.8020834 0.8541667 0.84375   0.84375   0.8541667]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.875     0.8020834 0.8645833 0.875     0.8854167 0.8854167]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.96875   0.9375    0.9583334 0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.9166667 0.90625   0.90625   0.8958334 0.8958334 0.8958334]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.9166667 0.8645834 0.8958334 0.8854167 0.8854166 0.90625  ]\n",
      "epoch: 4 Val acc: [0.59   0.6245 0.6064 0.6235 0.6074 0.6265 0.6045 0.627  0.6123 0.633\n",
      " 0.621 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.9791667 0.9479166 0.9791667 0.9791667 0.96875   0.9791667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.8333333 0.71875   0.84375   0.84375   0.84375   0.8333333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.8333333  0.7916667  0.8020833  0.81249994 0.8229166  0.8333333 ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8645833 0.7395833 0.8229166 0.8541667 0.8229167 0.8645833]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.8958333 0.8541667 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.9375     0.8229166  0.90625    0.93749994 0.9583333  0.9583333 ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8854167 0.8645833 0.8854166 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.9895833 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.8541667 0.8854166 0.8958333 0.8958333 0.9270833 0.8958333]\n",
      "epoch: 5 Val acc: [0.5483 0.5527 0.557  0.5684 0.577  0.574  0.584  0.574  0.5884 0.5884\n",
      " 0.5884]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9479167 0.9375    0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.78125   0.84375   0.8541666 0.8541666 0.8125    0.8125   ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9895833 0.9791666 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.875     0.84375   0.84375   0.8645833 0.8645833 0.8645833]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.8125    0.8125    0.8020833 0.8125    0.8125    0.8020833]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.8854167 0.8333333 0.8229166 0.8229166 0.8229166 0.8229166]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.7708333 0.7291666 0.75      0.7708333 0.78125   0.7916666]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.8958333 0.8645834 0.8645834 0.875     0.8958334 0.8958334]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 6 Val acc: [0.625  0.6323 0.6343 0.6313 0.6313 0.635  0.6353 0.635  0.634  0.6323\n",
      " 0.635 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9479166 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8020833 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.8541667 0.875     0.875     0.8645833 0.8645833 0.8645833]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.96875   0.9270833 0.96875   0.9791666 0.9791666 0.9791666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.9375    0.96875   0.96875   0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 210 \ttraining acc: [1.        0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.7708333 0.78125   0.7708334 0.7708334 0.7708334 0.78125  ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.8333334 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 Val acc: [0.5493 0.5566 0.564  0.5728 0.5806 0.5845 0.5874 0.5957 0.598  0.6025\n",
      " 0.6045]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9583333 0.96875   0.96875   0.9583334 0.96875   0.96875  ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.9895833 0.9375    0.9791666 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.90625   0.8333333 0.8020833 0.7916666 0.7916667 0.8020833]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.9375    0.8020833 0.9166667 0.9375    0.9375    0.9375   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.8229167 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.8020834 0.8020834 0.7604167 0.8229167 0.8229167 0.8020834]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8854166 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9479167 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.9270833 0.9270833 0.9270833 0.9270833 0.9166667 0.9270833]\n",
      "epoch: 8 Val acc: [0.633  0.64   0.6406 0.639  0.6396 0.6396 0.64   0.6406 0.6416 0.639\n",
      " 0.6387]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.96875   0.9166667 0.9270834 0.9375    0.9375    0.9270833]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.8645833 0.8333333 0.8125    0.8125    0.8125    0.8229167]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.875     0.9270833 0.9270833 0.9270833 0.90625   0.8958333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.96875   0.9791667 0.9791667 0.96875   0.96875   0.96875  ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.71875   0.7083334 0.71875   0.71875   0.71875   0.7083334]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5833334 0.5208333 0.5208334 0.53125   0.53125   0.5416667]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.7708333 0.75      0.7604166 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8854166 0.84375   0.8333334 0.8333334 0.8333334 0.84375  ]\n",
      "epoch: 9 Val acc: [0.6343 0.6367 0.6377 0.638  0.638  0.637  0.6367 0.636  0.6353 0.636\n",
      " 0.6377]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.8229166 0.75      0.75      0.7604166 0.7604166 0.7604166]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.8541667 0.8229167 0.84375   0.84375   0.84375   0.8541667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9895833 0.9375    0.9583333 0.9583333 0.96875   0.9791666]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9583334 0.9895833 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.96875   0.9791666 0.9791666 0.9791666 0.9791666 0.9791666]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9270833 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.9270834 0.8541667 0.8541667 0.875     0.8854167 0.875    ]\n",
      "Test acc: [0.93   0.908  0.9116 0.916  0.919  0.9243 0.927  0.9253 0.9272 0.9277\n",
      " 0.9287]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 3 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 726.66it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1321.04it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 477.15it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.29it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.9791666 0.7083334 0.8541667 0.9479166 0.9583333 0.9583333]\n",
      "epoch: 0 Val acc: [0.9717 0.9443 0.9614 0.9688 0.9736 0.9736 0.974  0.974  0.974  0.973\n",
      " 0.973 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.875     0.7916667 0.8020834 0.8229167 0.8333334 0.8541667]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9270834 0.7604167 0.8020833 0.8333334 0.8333334 0.8333334]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.96875   0.8958334 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.93750006 0.8333333  0.9166667  0.9375     0.9583334  0.9583334 ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.9791667 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.7916666 0.8229166 0.8229166 0.8229166 0.8020833 0.8020833]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.9895833 0.84375   0.8958333 0.9270833 0.9583333 0.96875  ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.9791666 0.9791666 0.9791666 0.9791666 0.9791666 0.9791666]\n",
      "epoch: 1 Val acc: [0.9775 0.9644 0.973  0.975  0.9756 0.976  0.976  0.976  0.976  0.9766\n",
      " 0.9766]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.9479167 0.8854167 0.8958333 0.8958333 0.9166667 0.9270834]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.7291667 0.6979167 0.6979167 0.6979167 0.6979167 0.6979167]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9270834 0.9270834 0.9270834 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9270833 0.8854167 0.8958334 0.8958334 0.90625   0.8958334]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.875      0.7916667  0.81250006 0.8229167  0.8541666  0.8645833 ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.8333334  0.78125    0.8020834  0.8020834  0.81250006 0.8020834 ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9270833 0.9270833 0.9270833 0.9270833 0.9375    0.9270833]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.9583334 0.875     0.9166667 0.9375    0.9375    0.9375   ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.8854167 0.8125    0.8229167 0.8541667 0.8854167 0.8854167]\n",
      "epoch: 2 Val acc: [0.97   0.954  0.971  0.979  0.979  0.9785 0.9775 0.977  0.9775 0.9775\n",
      " 0.9775]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.8645833 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9375    0.8541666 0.8854166 0.8958333 0.9166667 0.9270833]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.9479166 0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.9895833 0.9791666 0.9791666 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.7916666 0.8125    0.8125    0.8020834 0.8020834 0.8020834]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.90625   0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.9895833 0.9895833 1.        1.        0.9895833 0.9895833]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.96875   0.875     0.9895833 0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.9583333 0.9375    0.9479167 0.9583333 0.96875   0.9583333]\n",
      "epoch: 3 Val acc: [0.9766 0.9688 0.9785 0.976  0.976  0.976  0.976  0.9756 0.9756 0.976\n",
      " 0.9766]\n",
      "epoch: 3 step: 30 \ttraining acc: [1.        0.9895833 1.        1.        1.        1.       ]\n",
      "epoch: 3 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.93750006 0.9375     0.96875    0.9479167  0.9479167  0.96875   ]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9479167 0.96875   0.9479167 0.9583333 0.9479167 0.9479167]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.96875   0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9166666 0.8645834 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.8958334  0.90625006 0.8854167  0.8854167  0.9166667  0.9166667 ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.9895833 0.9791667 1.        1.        0.9895833 0.9791667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.9375    0.84375   0.875     0.90625   0.90625   0.9270833]\n",
      "epoch: 4 Val acc: [0.9814 0.933  0.977  0.977  0.977  0.976  0.976  0.977  0.9766 0.9766\n",
      " 0.9766]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.625     0.6354167 0.6354167 0.6354167 0.6354167 0.6354167]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.78125   0.7708333 0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.9375    0.8333334 0.96875   0.9270834 0.9270834 0.9375   ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.9270833 0.71875   0.8541667 0.8541667 0.90625   0.84375  ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.8958333 0.8229167 0.8333334 0.8645833 0.875     0.8645833]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.8229166 0.7395833 0.7916667 0.8229167 0.8333333 0.8125   ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.71875   0.5416666 0.6041667 0.7083334 0.7291667 0.71875  ]\n",
      "epoch: 4 step: 240 \ttraining acc: [1.        0.7916667 0.8333333 0.9270834 0.9479167 0.96875  ]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.8541666 0.8645833 0.8229166 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 5 Val acc: [0.883  0.979  0.9673 0.9604 0.9697 0.9746 0.975  0.9756 0.976  0.977\n",
      " 0.9756]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.7395834 0.7083334 0.75      0.7708333 0.7604167 0.7604167]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.7604167 0.6875    0.7083333 0.7291667 0.75      0.7604166]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9270834 0.8958334 0.8958334 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.96875   0.9270833 0.9583333 0.9583333 0.96875   0.96875  ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.7916666 0.6979167 0.7395834 0.7604166 0.7708334 0.7708334]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.9166667 0.9583333 0.9479166 0.9375    0.9479166 0.9375   ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8333333 0.8333333 0.8541667 0.84375   0.84375   0.84375  ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.8645833 0.8854166 0.8645833 0.8645833 0.875     0.8958333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.8854167 0.7604167 0.8541666 0.875     0.8958333 0.8958333]\n",
      "epoch: 6 Val acc: [0.9263 0.9844 0.984  0.9736 0.971  0.976  0.976  0.976  0.977  0.977\n",
      " 0.976 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9583334 0.9479167 0.9479167 0.9270834 0.9375    0.9479167]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8125    0.75      0.8541667 0.8333333 0.8125    0.7708334]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.9375    0.8541667 0.9270833 0.9583333 0.9270833 0.9375   ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.9583333 0.8958334 0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.9479167 0.9375    0.9479167 0.9479167 0.9583334 0.9583334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.875 0.75  0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.8958333 0.7708333 0.8958333 0.8854167 0.90625   0.90625  ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.90625   0.875     0.9166667 0.9166667 0.9166667 0.90625  ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9895833 0.8541667 0.8958334 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 7 Val acc: [0.9673 0.9517 0.9824 0.977  0.9736 0.974  0.9727 0.973  0.9717 0.9717\n",
      " 0.9727]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9270833 0.8541666 0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.6979166 0.7395834 0.7708334 0.7291667 0.71875   0.71875  ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.9270833 0.90625   0.96875   0.9583333 0.9583334 0.8958333]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.9479166 0.9583333 0.9479166 0.9375    0.9583333 0.9583333]\n",
      "epoch: 7 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9166667 0.84375   0.8958333 0.8958334 0.8958334 0.8958334]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9479167 0.7604167 0.8020834 0.9375    0.9270834 0.9270834]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.84375   0.75      0.7708333 0.84375   0.84375   0.84375  ]\n",
      "epoch: 8 Val acc: [0.9595 0.965  0.9497 0.977  0.971  0.9683 0.9683 0.9653 0.9644 0.9653\n",
      " 0.9697]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.9583333 0.84375   0.9375    0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.75       0.78124994 0.7395833  0.75       0.75       0.7916666 ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.9791666 0.7395834 0.8854166 0.9791666 0.9895833 0.9791666]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9270833 0.6666666 0.8125    0.8854166 0.8854166 0.90625  ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.9479166  0.7916667  0.84375    0.8645833  0.87499994 0.93749994]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8020834 0.6979167 0.7604167 0.7708334 0.7708334 0.78125  ]\n",
      "epoch: 8 step: 210 \ttraining acc: [1.      0.96875 0.96875 1.      1.      1.     ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.7916667 0.6770833 0.7604167 0.7708334 0.7916667 0.8020834]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.96875   0.625     0.8541666 0.9375    0.9375    0.9375   ]\n",
      "epoch: 9 Val acc: [0.8936 0.9624 0.9595 0.9614 0.972  0.9736 0.971  0.9717 0.97   0.97\n",
      " 0.969 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.96875   0.8229167 0.8541666 0.9375    0.9270833 0.9270833]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.9479166 0.8854167 0.9375    0.9270833 0.9270833 0.9270833]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.90625   0.75      0.8020834 0.8541667 0.8854167 0.9375   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.8333333 0.75      0.75      0.71875   0.7291667 0.75     ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.8125    0.7291667 0.8125    0.8125    0.8333333 0.8333333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9583333 0.9375    0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.7291667 0.71875   0.7604167 0.7083333 0.7395833 0.7395833]\n",
      "Test acc: [0.4924 0.497  0.4966 0.4941 0.4912 0.4875 0.4907 0.4924 0.4976 0.4941\n",
      " 0.4976]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/BA/META_LABEL/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 575.75it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 965.87it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 397.38it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.13it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.7604166 0.7083333 0.71875   0.7395834 0.7395833 0.7395833]\n",
      "epoch: 0 Val acc: [0.682  0.6636 0.6733 0.677  0.6772 0.682  0.6836 0.683  0.683  0.683\n",
      " 0.6816]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.8645834 0.8020833 0.8229166 0.8333333 0.84375   0.84375  ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.9166667 0.875     0.8854167 0.90625   0.9270834 0.9166667]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.9270834 0.9166667 0.9166667 0.9270834 0.9270834 0.9270834]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.875      0.84375    0.8541667  0.87499994 0.87499994 0.87499994]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.8541667 0.84375   0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 0 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.7083333 0.71875   0.71875   0.71875   0.71875   0.71875  ]\n",
      "epoch: 1 step: 0 \ttraining acc: [1.        0.9791667 0.9583333 0.9791667 1.        1.       ]\n",
      "epoch: 1 Val acc: [0.676  0.6787 0.681  0.6836 0.6816 0.6846 0.684  0.6836 0.6807 0.6807\n",
      " 0.6826]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.9270833 0.9583333 0.9583333 0.9583333 0.96875   0.96875  ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.8333333  0.81249994 0.84374994 0.84374994 0.84374994 0.8541666 ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9479167  0.9166667  0.9166667  0.93749994 0.93749994 0.9583333 ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9479166  0.93749994 0.9479167  0.9270833  0.9479167  0.9583333 ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9791667 0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.6666666 0.6666666 0.6666666 0.6666666 0.6666666 0.6666666]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9583333 0.9375    0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.8854167 0.8541667 0.8541667 0.8333333 0.8229167 0.8541667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.875     0.8645833 0.875     0.875     0.875     0.875    ]\n",
      "epoch: 2 Val acc: [0.6763 0.679  0.6807 0.681  0.6807 0.681  0.6777 0.677  0.6777 0.677\n",
      " 0.6763]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.9270833 0.9270833 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.7916667 0.8020833 0.8229167 0.8333334 0.8333334 0.8333334]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.8854166 0.8229167 0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.9375 0.9375 0.9375 0.9375 0.9375 0.9375]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8958334 0.8541666 0.8854166 0.8854166 0.8958333 0.90625  ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.9166667 0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 3 Val acc: [0.573  0.571  0.5806 0.587  0.594  0.603  0.6147 0.6206 0.6265 0.6294\n",
      " 0.6377]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.8854166 0.875     0.875     0.875     0.8854166 0.8854166]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.7291667 0.6979167 0.6979167 0.7083334 0.7083334 0.7083334]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.9479167 0.9479167 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.8645833 0.8645833 0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.9583333 0.9166667 0.9166667 0.9166667 0.9166667 0.9270834]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5520834 0.5520834 0.5520834]\n",
      "epoch: 3 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.9270833 0.8541667 0.8958333 0.8958333 0.875     0.8645833]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.90625   0.8958333 0.8958333 0.8958333 0.90625   0.90625  ]\n",
      "epoch: 4 Val acc: [0.669  0.664  0.67   0.6665 0.671  0.665  0.6704 0.6685 0.6724 0.666\n",
      " 0.668 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5833334 0.5520833 0.6041667 0.6041667 0.6041667 0.5833334]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.9583333 0.9375    0.9479167 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.8958333 0.8333333 0.8541666 0.8854166 0.8854166 0.8854166]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8645833 0.8854167 0.8541667 0.8645833 0.8541667 0.8645833]\n",
      "epoch: 4 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9479167 0.9375    0.9375   ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8333334 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.8125    0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.90625   0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 5 Val acc: [0.6577 0.6436 0.6475 0.6465 0.653  0.6567 0.655  0.6577 0.6606 0.6553\n",
      " 0.661 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.65625006 0.68750006 0.6666667  0.65625006 0.65625006 0.65625006]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8541666 0.7083333 0.7604167 0.7395834 0.7916667 0.8020834]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9270833 0.9479166 0.9479166 0.9479166 0.9479166 0.9270833]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.78125   0.71875   0.7708333 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.90625   0.9479167 0.9270833 0.9375    0.9270833 0.9270833]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.7604167 0.78125   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8229167 0.8020833 0.6979167 0.6666667 0.8333334 0.71875  ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.8229167 0.84375   0.8333333 0.8333334 0.8333334 0.8229167]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9270833 0.9270833 0.9270833 0.9270833 0.9166667 0.9166667]\n",
      "epoch: 6 Val acc: [0.655  0.6455 0.6465 0.6484 0.652  0.6553 0.6553 0.658  0.6587 0.66\n",
      " 0.6597]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9166667 0.9166666 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 6 step: 60 \ttraining acc: [1.        0.9895833 1.        1.        1.        1.       ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.90625   0.96875   0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.8020834 0.7604167 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.96875   0.9479166 0.9479166 0.9479166 0.9479166 0.9479166]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.84375   0.8645833 0.8645833 0.84375   0.84375   0.84375  ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.8958334 0.90625   0.8958334 0.8958334 0.8958334 0.8958334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 240 \ttraining acc: [0.9479167 0.9583333 0.96875   0.9583333 0.96875   0.9583333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9479166 0.8854167 0.90625   0.90625   0.9479166 0.9375   ]\n",
      "epoch: 7 Val acc: [0.6426 0.6294 0.6294 0.6353 0.639  0.646  0.6484 0.6494 0.6514 0.6514\n",
      " 0.6533]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9270834 0.96875   0.9791666 0.9479166 0.9583333 0.9583334]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.8125    0.8229167 0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.8333334 0.8645833 0.8541666 0.8541666 0.84375   0.8333333]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.9583333 0.9270833 0.9270833 0.9270833 0.9375    0.96875  ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.78125 0.78125 0.78125 0.78125 0.78125 0.78125]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.90625   0.8854167 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.84375   0.8229166 0.8229166 0.8229166 0.8229166 0.8229166]\n",
      "epoch: 8 Val acc: [0.648  0.6323 0.631  0.629  0.628  0.6353 0.6387 0.635  0.6426 0.641\n",
      " 0.641 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.8020834 0.71875   0.8229167 0.8125    0.8125    0.8125   ]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9270834 0.9166667 0.9270834 0.9270834 0.9166667 0.9270834]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.78125    0.8020834  0.8333334  0.8333334  0.8229167  0.84375006]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.8958333 0.90625   0.8958333 0.90625   0.90625   0.90625  ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8333333 0.90625   0.8958333 0.9270833 0.9270833 0.9479166]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.71875   0.7291666 0.75      0.75      0.75      0.7291667]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.9791666 0.9479166 0.9791666 0.9791666 0.96875   0.96875  ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.9583333 0.96875   0.96875   0.9583333 0.96875   0.96875  ]\n",
      "epoch: 9 Val acc: [0.655  0.652  0.6543 0.655  0.6562 0.6577 0.6577 0.6562 0.657  0.6577\n",
      " 0.658 ]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.9375    0.9270834 0.9375    0.9479167 0.9375    0.9270834]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.7604166  0.78124994 0.8229166  0.8229166  0.78124994 0.78124994]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.7291667 0.7083333 0.7083333 0.71875   0.7291667 0.7291667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.7604167  0.75000006 0.75000006 0.75000006 0.7395834  0.7291667 ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9270833 0.8854166 0.90625   0.9270833 0.9479166 0.9479166]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.8645833 0.90625   0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 9 step: 210 \ttraining acc: [1.      0.96875 0.96875 0.96875 0.96875 0.96875]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.9479167 0.9270834 0.9166667 0.9375    0.9479167 0.9479167]\n",
      "Test acc: [0.999  1.     1.     0.9995 0.9995 0.9995 0.9995 0.9995 0.9995 0.9995\n",
      " 0.999 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/BA/META_LABEL/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 749.25it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1290.16it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 435.92it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.12it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.7916667 0.78125   0.78125   0.75      0.7604167 0.7708334]\n",
      "epoch: 0 Val acc: [0.9565 0.904  0.905  0.905  0.905  0.9043 0.904  0.905  0.906  0.9067\n",
      " 0.9097]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.96875   0.9895833 0.9895833 0.9895833 0.9895833 1.       ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.90625   0.90625   0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.6666667 0.65625   0.6458334 0.6145834 0.6145834 0.625    ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.5208333 0.5520834 0.5520834 0.5416667 0.53125   0.53125  ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.65625006 0.6354167  0.6354167  0.6354167  0.6354167  0.6354167 ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.875   0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.9583333 0.9375    0.9375    0.9479167 0.9479167 0.9583333]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.6458333 0.6354166 0.6354166 0.6354166 0.6354166 0.6354166]\n",
      "epoch: 1 Val acc: [0.944  0.927  0.9316 0.935  0.9395 0.941  0.9424 0.9453 0.9473 0.9478\n",
      " 0.948 ]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.75      0.78125   0.7604167 0.7604167 0.7604167 0.7708334]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.78125   0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.84374994 0.8333333  0.8333333  0.84375    0.84375    0.8541667 ]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.84375   0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.8020833  0.78124994 0.78124994 0.7916666  0.7916666  0.8020833 ]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.7395833 0.7395833 0.7395833 0.7395833 0.7395833 0.7395833]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.7916667 0.8125    0.8125    0.8125    0.8125    0.8125   ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.68749994 0.7083333  0.7083333  0.7083333  0.6979166  0.6979166 ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.9375     0.93749994 0.93749994 0.93749994 0.93749994 0.93749994]\n",
      "epoch: 2 Val acc: [0.9395 0.9194 0.924  0.925  0.9316 0.937  0.939  0.9414 0.942  0.942\n",
      " 0.9424]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.7708333 0.8333333 0.7916666 0.7916666 0.7916666 0.7916666]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.8229166  0.84374994 0.8541666  0.84375    0.8541667  0.8541667 ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.7708333 0.7708333 0.7916666 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.71875 0.71875 0.71875 0.71875 0.71875 0.71875]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.78125   0.7708333 0.7604166 0.7604166 0.7708333 0.7708333]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.8854167 0.8854167 0.8854167 0.8854167 0.8854167 0.8854167]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.84375   0.84375   0.84375   0.84375   0.8541666 0.8541666]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.7708333  0.78124994 0.78124994 0.78124994 0.78124994 0.78124994]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.90625   0.9166667 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 3 Val acc: [0.939  0.919  0.9243 0.93   0.935  0.936  0.937  0.939  0.94   0.9395\n",
      " 0.941 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.8125    0.7916667 0.78125   0.78125   0.7708334 0.7708334]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.8541667 0.875     0.8854167 0.875     0.8958333 0.90625  ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.8020833 0.7916666 0.7916667 0.7916667 0.8020834 0.8020834]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.9583333 0.8958333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.8229167 0.7291667 0.8541667 0.7291667 0.8333333 0.7604166]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.8645833  0.87499994 0.87499994 0.8333333  0.8645833  0.7708334 ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.84375   0.84375   0.84375   0.84375   0.8541667 0.8541667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.8333333 0.8333333 0.8229166 0.8229166 0.8333333 0.8333333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.90625    0.9479166  0.9479166  0.93749994 0.9479166  0.9479166 ]\n",
      "epoch: 4 Val acc: [0.938  0.913  0.9165 0.9214 0.9375 0.922  0.9307 0.938  0.933  0.932\n",
      " 0.9434]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.875     0.90625   0.9166667 0.8958334 0.9270833 0.9270834]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.68749994 0.6458333  0.6666666  0.6666666  0.6979166  0.6979166 ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.9166667 0.90625   0.9375    0.90625   0.9375    0.9270833]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.96875   0.9895833 1.        1.        1.        0.9895833]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.75       0.7291666  0.78125    0.71875006 0.7083334  0.7083333 ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.7395833  0.74999994 0.71874994 0.6979166  0.71874994 0.7083333 ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8958333 0.8854167 0.9270833 0.9375    0.875     0.9270833]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.9270833 0.8958333 0.9479166 0.9479166 0.9375    0.9479166]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.8020834 0.78125   0.7916667 0.7916667 0.8020834 0.7916667]\n",
      "epoch: 5 Val acc: [0.913  0.909  0.9067 0.9126 0.9146 0.917  0.9185 0.92   0.922  0.924\n",
      " 0.924 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.9583333 0.9479166 0.9479166 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8854167  0.8958334  0.90625006 0.8854167  0.8854167  0.8854167 ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.84375   0.75      0.8229167 0.7604167 0.8333333 0.7604167]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.90625   0.875     0.8958333 0.90625   0.90625   0.90625  ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.875     0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.6666667 0.6770834 0.65625   0.7291666 0.6979166 0.71875  ]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.7916666 0.8020833 0.8020833 0.78125   0.78125   0.78125  ]\n",
      "epoch: 5 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9479167 0.9375    0.9375    0.9375    0.9375    0.9270833]\n",
      "epoch: 6 Val acc: [0.9297 0.8687 0.9077 0.908  0.909  0.9165 0.921  0.92   0.923  0.9253\n",
      " 0.923 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.7916666 0.78125   0.7604166 0.8020833 0.7916667 0.78125  ]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.9895833 0.9166666 0.9791666 0.9791666 0.9791666 0.9791666]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.71875006 0.7708333  0.78125    0.7604167  0.78125    0.78125   ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.7916666 0.75      0.7916667 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9375    0.8645833 0.875     0.8854167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.87500006 0.8229167  0.8229167  0.8333333  0.8333334  0.8541667 ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.59375   0.625     0.6458334 0.6666667 0.65625   0.6458334]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.87499994 0.8333333  0.84375    0.84375    0.84375    0.8645833 ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.78125   0.7291667 0.7083333 0.7708333 0.71875   0.7604166]\n",
      "epoch: 7 Val acc: [0.9316 0.9204 0.9155 0.9175 0.921  0.924  0.9272 0.9272 0.9253 0.9272\n",
      " 0.93  ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9479166 0.9270833 0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.7916666  0.78125    0.74999994 0.7604166  0.7604166  0.8020833 ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.8958333  0.8958333  0.8958333  0.8958333  0.87499994 0.8958333 ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.8854167 0.8645833 0.875     0.8854166 0.8854166 0.8854167]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.9270833 0.8958334 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9270833 0.8958333 0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.8645833 0.8541667 0.8541667 0.8541666 0.8541667 0.8541667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.7708333 0.78125   0.78125   0.8229167 0.75      0.8125   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.9375    0.875     0.8645833 0.8645833 0.8645833 0.8645833]\n",
      "epoch: 8 Val acc: [0.894  0.884  0.8794 0.9043 0.9053 0.9023 0.9175 0.916  0.913  0.919\n",
      " 0.918 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.6979167 0.6979166 0.7291666 0.7708334 0.75      0.7395833]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.7916667 0.8125    0.8125    0.8125    0.8020833 0.7916667]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.8854167  0.8854166  0.90624994 0.8958333  0.9270833  0.9270833 ]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9166667  0.8958333  0.8958333  0.8958333  0.90624994 0.90624994]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.8958333 0.9166666 0.9166666 0.9166666 0.9166666 0.9375   ]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.7083333 0.71875   0.7291666 0.7291666 0.7083333 0.7395833]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.8958334 0.9375    0.9375    0.9479167 0.9583334 0.9583334]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.9375    0.8645833 0.9270833 0.9166666 0.9583333 0.9375   ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.9166667 0.8854166 0.875     0.8854167 0.8854167 0.8958333]\n",
      "epoch: 9 Val acc: [0.918  0.8887 0.9033 0.9087 0.9136 0.9175 0.9185 0.922  0.925  0.9263\n",
      " 0.9287]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.8541667 0.78125   0.7916667 0.7708333 0.7916667 0.7604167]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.93749994 0.8541667  0.8958333  0.84375    0.90625    0.8541667 ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.90625   0.9270833 0.8958333 0.90625   0.9270833 0.90625  ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.9791667 0.9791667 0.96875   0.96875   0.96875   0.90625  ]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.96875   0.9270834 0.9375    0.9375    0.9375    0.9375   ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.7708333 0.8125    0.8229167 0.8333333 0.8020833 0.8229166]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9270833 0.8854166 0.9166666 0.9166666 0.9270833 0.9270833]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.9791667 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "Test acc: [0.7026 0.655  0.695  0.6865 0.6953 0.6914 0.6924 0.6953 0.693  0.694\n",
      " 0.693 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.03, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 805.67it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1393.69it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 544.50it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 40.39it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.8958333 0.8229167 0.84375   0.8541667 0.8541667 0.8541667]\n",
      "epoch: 0 Val acc: [0.6035 0.5986 0.599  0.6    0.6    0.601  0.601  0.601  0.6006 0.6\n",
      " 0.6   ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.7291667 0.71875   0.71875   0.71875   0.71875   0.71875  ]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.8645833 0.8854167 0.8854167 0.875     0.875     0.875    ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.8229167 0.84375   0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.90625   0.90625   0.8958333 0.8958333 0.8958333 0.90625  ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.8020833 0.8229166 0.8229166 0.8229166 0.8229166 0.8125   ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.8125    0.78125   0.78125   0.78125   0.7916667 0.7916667]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.7083333  0.68749994 0.68749994 0.68749994 0.68749994 0.68749994]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.93749994 0.9375     0.9375     0.9375     0.9375     0.9375    ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.9375    0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 Val acc: [0.6265 0.62   0.6206 0.6226 0.623  0.6235 0.622  0.6216 0.6216 0.6226\n",
      " 0.6216]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.8645834 0.8333334 0.8333334 0.84375   0.84375   0.84375  ]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.7916667 0.8020834 0.8020834 0.8020834 0.8020834 0.8020834]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.8229166 0.8229167 0.8229167 0.8229167 0.8229167 0.8229167]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9583333 0.96875   0.96875   0.96875   0.96875   0.96875  ]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.6041667 0.6145833 0.6145833 0.6145833 0.6145833 0.6145833]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.71875   0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.6979166 0.6354167 0.6354167 0.6354167 0.6354167 0.6354167]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.7916667 0.78125   0.78125   0.7916667 0.7916667 0.7916667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.90625    0.8854167  0.8854167  0.8854167  0.8958333  0.90624994]\n",
      "epoch: 2 Val acc: [0.6377 0.628  0.6323 0.633  0.633  0.6323 0.6333 0.6323 0.6323 0.6333\n",
      " 0.632 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.8645834 0.90625   0.90625   0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.6458333 0.6354167 0.6354167 0.6354167 0.6458333 0.6458333]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.6875  0.65625 0.65625 0.65625 0.65625 0.65625]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.96874994 0.9583333  0.9583333  0.9583333  0.9583333  0.96874994]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.59375 0.65625 0.65625 0.65625 0.65625 0.65625]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.8958333 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.90625   0.8854166 0.8958333 0.8958333 0.90625   0.90625  ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.875     0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 3 Val acc: [0.639  0.6294 0.6313 0.631  0.6323 0.6333 0.6333 0.6343 0.6353 0.6353\n",
      " 0.6353]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.7604167 0.7395834 0.7395834 0.7395834 0.7395834 0.7395834]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.8854166 0.90625   0.90625   0.90625   0.90625   0.90625  ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.8020833 0.8020833 0.8020833 0.8020833 0.8020833 0.8020833]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.8645833 0.875     0.875     0.875     0.875     0.875    ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.7708333 0.7708333 0.7708333 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.9479166 0.9166666 0.9166666 0.9166666 0.9166666 0.9166666]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.7083334 0.7083334 0.7083334 0.7083334 0.7083334 0.71875  ]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.7291666  0.7395833  0.7395833  0.74999994 0.74999994 0.74999994]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.875     0.7916666 0.7916666 0.7916666 0.7916666 0.8020833]\n",
      "epoch: 4 Val acc: [0.6387 0.6294 0.635  0.6357 0.6353 0.6367 0.636  0.6367 0.637  0.6377\n",
      " 0.637 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.8229166 0.8333333 0.8333333 0.84375   0.84375   0.8333333]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.75000006 0.7291667  0.71875    0.7291667  0.75000006 0.7395834 ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.84375 0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.7604167  0.78124994 0.7916666  0.8020833  0.7708333  0.78125   ]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.8541667 0.84375   0.84375   0.8541667 0.84375   0.8541667]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.7916666 0.84375   0.84375   0.84375   0.84375   0.84375  ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.625     0.625     0.6458334 0.6458334 0.6458334 0.6458334]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.7395834 0.7291667 0.7291667 0.7291667 0.7395834 0.7395834]\n",
      "epoch: 5 Val acc: [0.636  0.6323 0.633  0.635  0.635  0.6357 0.636  0.6353 0.6353 0.6353\n",
      " 0.635 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.7604167 0.78125   0.78125   0.78125   0.78125   0.78125  ]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8645833 0.9166667 0.9166667 0.9166667 0.8958333 0.8958333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.46875 0.46875 0.46875 0.46875 0.46875 0.46875]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.9791666 0.9791667 0.9791667 0.9791667 0.9791667 0.9791667]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.7708334 0.7708334 0.7708334 0.7708334 0.7708334 0.7708334]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.9895833 0.9895833 0.9895833 0.9895833 0.9895833 0.9895833]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.8854167 0.9375    0.9270833 0.9270833 0.9270833 0.9270833]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.7395834  0.71875006 0.71875006 0.71875006 0.71875006 0.71875006]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.8958333 0.8958333 0.8958333 0.8958333 0.8958333 0.8958333]\n",
      "epoch: 6 Val acc: [0.637  0.6323 0.6343 0.6304 0.628  0.634  0.635  0.6343 0.6343 0.6353\n",
      " 0.635 ]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.875  0.9375 0.9375 0.9375 0.9375 0.9375]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8020833  0.8229166  0.81249994 0.81249994 0.81249994 0.8020833 ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5520834 0.5416666 0.53125   0.53125   0.53125   0.53125  ]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.8125  0.84375 0.84375 0.84375 0.84375 0.84375]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.8125    0.8125    0.8229167 0.8229167 0.8125    0.8125   ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 180 \ttraining acc: [0.8020834 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.8854167 0.8645834 0.8645834 0.875     0.875     0.875    ]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.8333333 0.8229167 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.9791666 0.9583333 0.9583333 0.96875   0.96875   0.96875  ]\n",
      "epoch: 7 Val acc: [0.6377 0.6323 0.6294 0.629  0.6353 0.6353 0.635  0.637  0.6367 0.635\n",
      " 0.6353]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.9166667 0.9166667 0.90625   0.9166667 0.9166667 0.90625  ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.8125 0.8125 0.8125 0.8125 0.8125 0.8125]\n",
      "epoch: 7 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.6979167 0.6979166 0.7083333 0.7083333 0.7083333 0.6979166]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.6875 0.6875 0.6875 0.6875 0.6875 0.6875]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.9479167 0.9791667 0.9791667 0.96875   0.96875   0.96875  ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.625     0.6354167 0.6354167 0.6354167 0.6354167 0.6354167]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.7708333  0.7395833  0.7395833  0.74999994 0.7604166  0.7604166 ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.8541667 0.8541667 0.8541667 0.8541667 0.8541667 0.8541667]\n",
      "epoch: 8 Val acc: [0.6406 0.631  0.629  0.6343 0.635  0.6367 0.6377 0.6387 0.639  0.6377\n",
      " 0.6377]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.6875 0.6875 0.6875 0.6875 0.6875 0.6875]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.9375    0.9270833 0.9166667 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.78125   0.8020833 0.8229167 0.8125    0.8125    0.8229167]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.7083333  0.74999994 0.71875    0.6979166  0.6979166  0.7083333 ]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.8645833 0.90625   0.9479167 0.9583334 0.9479167 0.9479167]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.8125    0.8541666 0.8541666 0.8541666 0.8541666 0.84375  ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.9791666 0.96875   0.96875   0.96875   0.96875   0.9583334]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.8541666 0.8333333 0.8333333 0.84375   0.84375   0.84375  ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.875     0.8645834 0.8645834 0.8645834 0.8645834 0.8645834]\n",
      "epoch: 9 Val acc: [0.632  0.645  0.6484 0.635  0.627  0.6343 0.6333 0.6333 0.635  0.634\n",
      " 0.6304]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.6875    0.6770833 0.6770833 0.6770833 0.6770833 0.6770833]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.7291667 0.75      0.75      0.7708333 0.7708333 0.75     ]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.93749994 0.9479166  0.9479166  0.9479166  0.9479166  0.9479166 ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.7604167 0.7708333 0.7708333 0.7708333 0.7708333 0.7708333]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.7604167 0.75      0.75      0.75      0.75      0.75     ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.8854167 0.9166666 0.9270833 0.9375    0.90625   0.8958334]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.8854167 0.9166667 0.9479167 0.9479167 0.9479167 0.9479167]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.84375   0.8854166 0.875     0.8645833 0.8645833 0.8645833]\n",
      "Test acc: [0.501  0.507  0.507  0.5073 0.506  0.5073 0.508  0.5063 0.5054 0.506\n",
      " 0.5073]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_ProtoMAML_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.03 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=3, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 573.31it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 978.49it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 396.36it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 39.02it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 3-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 3-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 3-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5416667 0.5      ]\n",
      "epoch: 0 Val acc: [0.9795 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785\n",
      " 0.979 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.9583333 0.9583333 0.7083333 0.7083333 0.7083333 0.9166667]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.625     0.625    ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9583333 0.875    ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.75      0.75      0.75      0.75      0.75      0.7916667]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [0.7083333 0.7083333 0.75      0.7916667 0.7916667 0.8333333]\n",
      "epoch: 0 step: 300 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 360 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 390 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 0 step: 420 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.7083333 0.7083333 0.6666667 0.625     0.625     0.8333333]\n",
      "epoch: 0 Val acc: [0.953  0.957  0.957  0.9565 0.9565 0.9565 0.9565 0.9565 0.9565 0.9565\n",
      " 0.957 ]\n",
      "epoch: 0 step: 510 \ttraining acc: [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "epoch: 0 step: 540 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 570 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 660 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.875     0.875    ]\n",
      "epoch: 0 step: 690 \ttraining acc: [0.875     0.875     0.875     0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 720 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 900 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 960 \ttraining acc: [1.        1.        0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 990 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 Val acc: [0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873\n",
      " 0.9873]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 330 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 390 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 420 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 450 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.45833334]\n",
      "epoch: 1 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 Val acc: [0.9873 0.9756 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873 0.9873\n",
      " 0.9873]\n",
      "epoch: 1 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 540 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 570 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 600 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 1 step: 630 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 660 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 step: 690 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 720 \ttraining acc: [0.5416667  0.5416667  0.5        0.5        0.45833334 0.45833334]\n",
      "epoch: 1 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 780 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9583333 0.9583333]\n",
      "epoch: 1 step: 900 \ttraining acc: [0.9166667 0.9166667 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 Val acc: [0.985  0.9844 0.9844 0.9844 0.9844 0.9844 0.9844 0.9844 0.9844 0.9844\n",
      " 0.9844]\n",
      "epoch: 2 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 150 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 270 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 330 \ttraining acc: [0.875     0.875     0.875     0.875     0.875     0.8333333]\n",
      "epoch: 2 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 390 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 420 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 480 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 2 Val acc: [0.9766 0.9775 0.9775 0.9775 0.9775 0.977  0.977  0.977  0.977  0.977\n",
      " 0.977 ]\n",
      "epoch: 2 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 570 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 600 \ttraining acc: [0.875     0.875     0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 720 \ttraining acc: [0.875     0.875     0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 780 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 2 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 840 \ttraining acc: [0.6666667 0.6666667 0.625     0.625     0.625     0.625    ]\n",
      "epoch: 2 step: 870 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 step: 900 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 2 step: 930 \ttraining acc: [0.75      0.75      0.75      0.75      0.7083333 0.7083333]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 Val acc: [0.977  0.978  0.978  0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775\n",
      " 0.9775]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5833333 0.5833333 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 300 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 3 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.625     0.625     0.625     0.625     0.5833333 0.5833333]\n",
      "epoch: 3 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 420 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 Val acc: [0.9766 0.977  0.977  0.977  0.977  0.977  0.977  0.977  0.977  0.977\n",
      " 0.977 ]\n",
      "epoch: 3 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 540 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 step: 570 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 660 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 690 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 720 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 780 \ttraining acc: [0.75      0.75      0.75      0.75      0.7916667 0.7916667]\n",
      "epoch: 3 step: 810 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 870 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 930 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 990 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 Val acc: [0.9785 0.9775 0.9775 0.978  0.978  0.978  0.978  0.978  0.978  0.9785\n",
      " 0.9785]\n",
      "epoch: 4 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 300 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 390 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 4 step: 420 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 4 step: 450 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 4 step: 480 \ttraining acc: [0.75      0.75      0.75      0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 Val acc: [0.9453 0.9473 0.9473 0.9497 0.95   0.9536 0.9546 0.956  0.9565 0.958\n",
      " 0.9585]\n",
      "epoch: 4 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 540 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 4 step: 600 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 720 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 4 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 780 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 4 step: 810 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 4 step: 870 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 4 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 930 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 4 step: 960 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 4 step: 990 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 0 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 5 Val acc: [0.976  0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756 0.9756\n",
      " 0.9756]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 5 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 300 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 360 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 390 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 5 step: 480 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 Val acc: [0.9736 0.9736 0.9736 0.9736 0.9736 0.9736 0.9736 0.9736 0.9736 0.9736\n",
      " 0.9736]\n",
      "epoch: 5 step: 510 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 540 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 600 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 630 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 690 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 5 step: 720 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.8333333 0.8333333]\n",
      "epoch: 5 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 5 step: 780 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 5 step: 810 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.625     0.625     0.625    ]\n",
      "epoch: 5 step: 840 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.8333333 0.8333333 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 900 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 5 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 Val acc: [0.9766 0.9766 0.9766 0.9766 0.9766 0.9766 0.9766 0.9766 0.9766 0.9766\n",
      " 0.9766]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.625     0.625     0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5416667 0.5416667 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 270 \ttraining acc: [0.7083333 0.7083333 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 6 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 420 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 6 step: 450 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 Val acc: [0.982  0.9814 0.9814 0.9814 0.9814 0.9814 0.9814 0.9814 0.9814 0.9814\n",
      " 0.9814]\n",
      "epoch: 6 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 570 \ttraining acc: [0.9166667 0.9166667 0.875     0.9166667 0.875     0.875    ]\n",
      "epoch: 6 step: 600 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.41666666 0.41666666]\n",
      "epoch: 6 step: 630 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 660 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 720 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 6 step: 780 \ttraining acc: [0.875     0.875     0.8333333 0.875     0.875     0.875    ]\n",
      "epoch: 6 step: 810 \ttraining acc: [0.875     0.875     0.875     0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 840 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 6 step: 870 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 6 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 960 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5       0.5      ]\n",
      "epoch: 6 step: 990 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 7 Val acc: [0.983  0.9834 0.9834 0.9834 0.9834 0.9834 0.9834 0.9834 0.9834 0.9834\n",
      " 0.9834]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.41666666 0.41666666 0.45833334 0.5        0.5        0.5       ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 7 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.875     0.875     0.875    ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 7 step: 330 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 7 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 390 \ttraining acc: [0.625     0.625     0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 7 step: 420 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 450 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 Val acc: [0.9766 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775\n",
      " 0.9775]\n",
      "epoch: 7 step: 510 \ttraining acc: [0.9166667 0.9166667 0.875     0.875     0.875     0.875    ]\n",
      "epoch: 7 step: 540 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 570 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 7 step: 600 \ttraining acc: [0.8333333 0.8333333 0.7916667 0.7916667 0.8333333 0.875    ]\n",
      "epoch: 7 step: 630 \ttraining acc: [0.625     0.625     0.625     0.5416667 0.5416667 0.5416667]\n",
      "epoch: 7 step: 660 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 690 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 750 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 7 step: 780 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 7 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9166667]\n",
      "epoch: 7 step: 840 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9166667]\n",
      "epoch: 7 step: 870 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 7 step: 900 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 930 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 7 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.978  0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785 0.9785\n",
      " 0.9785]\n",
      "epoch: 8 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 8 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.9166667 0.9166667 0.875     0.875     0.875     0.875    ]\n",
      "epoch: 8 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 270 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 8 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 420 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.9766 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775 0.9775\n",
      " 0.9775]\n",
      "epoch: 8 step: 510 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 570 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 8 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 660 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 720 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 8 step: 840 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.75      0.75      0.75     ]\n",
      "epoch: 8 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 8 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 Val acc: [0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975 0.975]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 270 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 300 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 330 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 360 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 9 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 420 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.7916667 0.7916667 0.75      0.75      0.75      0.75     ]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.75      0.75      0.7916667 0.7916667 0.75      0.75     ]\n",
      "epoch: 9 Val acc: [0.8257 0.7544 0.7354 0.774  0.7856 0.778  0.774  0.8125 0.7993 0.7905\n",
      " 0.8203]\n",
      "epoch: 9 step: 510 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 540 \ttraining acc: [0.875     0.875     0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 570 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 600 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 660 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 9 step: 690 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 720 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 750 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.875     0.875    ]\n",
      "epoch: 9 step: 810 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 9 step: 840 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 870 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5       0.5       0.5      ]\n",
      "epoch: 9 step: 900 \ttraining acc: [0.625     0.625     0.625     0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 930 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.7083333 0.7083333 0.75      0.7916667 0.7916667 0.8333333]\n",
      "epoch: 9 step: 990 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5416667]\n",
      "Test acc: [0.7793 0.6616 0.6123 0.601  0.6094 0.6113 0.6045 0.61   0.612  0.626\n",
      " 0.661 ]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 3 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=3, meta_lr=0.01, n_graphlets=5, n_way=2, no_finetune=True, task_num=1, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 93.77it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1166.87it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 411.15it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.63it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 3-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 3-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 3-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5       0.5       0.5416667 0.6666667 0.7916667 0.7916667]\n",
      "epoch: 0 Val acc: [0.726  0.734  0.734  0.734  0.734  0.7344 0.7344 0.7344 0.7344 0.7344\n",
      " 0.734 ]\n",
      "epoch: 0 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.75      0.75      0.75      0.75      0.6666667 0.75     ]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 0 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 300 \ttraining acc: [1.        1.        1.        1.        0.9583333 0.9583333]\n",
      "epoch: 0 step: 330 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.375      0.33333334]\n",
      "epoch: 0 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 450 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 480 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.875     0.875    ]\n",
      "epoch: 0 Val acc: [0.7573 0.7573 0.7617 0.765  0.7637 0.7646 0.766  0.766  0.768  0.7686\n",
      " 0.7686]\n",
      "epoch: 0 step: 510 \ttraining acc: [0.625     0.625     0.7083333 0.7083333 0.75      0.7083333]\n",
      "epoch: 0 step: 540 \ttraining acc: [0.20833333 0.20833333 0.20833333 0.20833333 0.20833333 0.20833333]\n",
      "epoch: 0 step: 570 \ttraining acc: [0.6666667 0.6666667 0.625     0.625     0.625     0.625    ]\n",
      "epoch: 0 step: 600 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 0 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 660 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 0 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 720 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.29166666 0.29166666]\n",
      "epoch: 0 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 0 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 900 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 0 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 0 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 0 step: 990 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 Val acc: [0.7554 0.758  0.758  0.758  0.758  0.7583 0.7573 0.7573 0.7573 0.7573\n",
      " 0.7573]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 240 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 300 \ttraining acc: [0.375      0.375      0.41666666 0.41666666 0.45833334 0.5       ]\n",
      "epoch: 1 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 480 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 Val acc: [0.7427 0.747  0.746  0.7466 0.7466 0.7466 0.7466 0.747  0.746  0.7466\n",
      " 0.747 ]\n",
      "epoch: 1 step: 510 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 1 step: 540 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 1 step: 570 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 1 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 630 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 1 step: 660 \ttraining acc: [0.8333333 0.8333333 0.75      0.75      0.7083333 0.7083333]\n",
      "epoch: 1 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 780 \ttraining acc: [0.375      0.375      0.375      0.375      0.45833334 0.5       ]\n",
      "epoch: 1 step: 810 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.8333333 0.7916667 0.7916667]\n",
      "epoch: 1 step: 840 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 1 step: 870 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 1 step: 900 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 1 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 1 step: 960 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 1 step: 990 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 2 Val acc: [0.7246 0.7314 0.7314 0.733  0.733  0.733  0.7324 0.732  0.7314 0.7314\n",
      " 0.7314]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.9166667 0.9166667 0.875     0.875     0.875     0.875    ]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 180 \ttraining acc: [0.9166667 0.9166667 0.875     0.875     0.875     0.9166667]\n",
      "epoch: 2 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 300 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 330 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 360 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 390 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.625     0.5833333 0.5833333]\n",
      "epoch: 2 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 480 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 Val acc: [0.724  0.7314 0.732  0.732  0.732  0.7324 0.7324 0.732  0.733  0.7324\n",
      " 0.732 ]\n",
      "epoch: 2 step: 510 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 570 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 2 step: 600 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 2 step: 630 \ttraining acc: [0.7916667 0.7916667 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 660 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 2 step: 690 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 2 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 2 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 2 step: 780 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 2 step: 810 \ttraining acc: [0.375      0.375      0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 2 step: 840 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 2 step: 900 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 930 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 2 step: 960 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 2 step: 990 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.625    ]\n",
      "epoch: 3 Val acc: [0.7627 0.774  0.774  0.7744 0.774  0.774  0.774  0.773  0.7725 0.772\n",
      " 0.772 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.875     0.875     0.875     0.875     0.875     0.8333333]\n",
      "epoch: 3 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 3 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 3 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 300 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 330 \ttraining acc: [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "epoch: 3 step: 360 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 3 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 420 \ttraining acc: [0.875     0.875     0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 3 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 480 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 3 Val acc: [0.7627 0.7695 0.7695 0.7695 0.769  0.7686 0.7686 0.768  0.768  0.7676\n",
      " 0.7676]\n",
      "epoch: 3 step: 510 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 3 step: 540 \ttraining acc: [0.625     0.625     0.625     0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 600 \ttraining acc: [0.875     0.875     0.875     0.875     0.875     0.8333333]\n",
      "epoch: 3 step: 630 \ttraining acc: [0.7083333 0.7083333 0.75      0.75      0.75      0.75     ]\n",
      "epoch: 3 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 720 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 3 step: 750 \ttraining acc: [0.75      0.75      0.75      0.75      0.7916667 0.7916667]\n",
      "epoch: 3 step: 780 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.75      0.75     ]\n",
      "epoch: 3 step: 810 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 840 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 3 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 3 step: 960 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 3 step: 990 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 Val acc: [0.7485 0.753  0.7524 0.7524 0.752  0.753  0.753  0.7524 0.7524 0.7524\n",
      " 0.753 ]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5       0.5       0.5416667 0.625     0.625     0.5833333]\n",
      "epoch: 4 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 4 step: 270 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 4 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 330 \ttraining acc: [0.7083333 0.7083333 0.75      0.75      0.75      0.75     ]\n",
      "epoch: 4 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 420 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.625     0.7083333]\n",
      "epoch: 4 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 480 \ttraining acc: [0.8333333 0.8333333 0.7916667 0.7916667 0.8333333 0.7916667]\n",
      "epoch: 4 Val acc: [0.7485 0.752  0.7515 0.7515 0.752  0.752  0.7515 0.7515 0.7515 0.7515\n",
      " 0.7515]\n",
      "epoch: 4 step: 510 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 4 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 570 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.875     0.875    ]\n",
      "epoch: 4 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 630 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 4 step: 660 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 720 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 780 \ttraining acc: [0.33333334 0.33333334 0.33333334 0.33333334 0.33333334 0.33333334]\n",
      "epoch: 4 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 4 step: 930 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 4 step: 960 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 4 step: 990 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 Val acc: [0.7456 0.752  0.752  0.752  0.752  0.7515 0.7515 0.751  0.7505 0.75\n",
      " 0.7505]\n",
      "epoch: 5 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.8333333 0.8333333 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.6666667 0.6666667 0.75      0.75      0.75      0.75     ]\n",
      "epoch: 5 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 5 step: 270 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 5 step: 300 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 330 \ttraining acc: [0.75      0.75      0.7083333 0.7083333 0.75      0.75     ]\n",
      "epoch: 5 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 390 \ttraining acc: [0.7916667 0.7916667 0.5416667 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 5 step: 420 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 5 step: 450 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5      ]\n",
      "epoch: 5 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 Val acc: [0.747  0.7515 0.7515 0.7515 0.7515 0.7515 0.7515 0.7515 0.7515 0.7515\n",
      " 0.7515]\n",
      "epoch: 5 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 570 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 630 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 5 step: 690 \ttraining acc: [0.625     0.625     0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 5 step: 720 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 810 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 5 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 5 step: 870 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 5 step: 900 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 5 step: 930 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 5 step: 960 \ttraining acc: [0.875     0.875     0.875     0.875     0.875     0.8333333]\n",
      "epoch: 5 step: 990 \ttraining acc: [0.875     0.875     0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 Val acc: [0.743  0.75   0.7505 0.7505 0.7505 0.7505 0.7505 0.75   0.75   0.7495\n",
      " 0.7495]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 150 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 300 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 330 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9583333 0.9583333]\n",
      "epoch: 6 step: 360 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 390 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 6 step: 420 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9166667 0.9166667]\n",
      "epoch: 6 step: 450 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 6 step: 480 \ttraining acc: [0.04166667 0.04166667 0.5        1.         0.9583333  0.875     ]\n",
      "epoch: 6 Val acc: [0.807  0.761  0.7603 0.7837 0.7886 0.7866 0.784  0.7837 0.784  0.787\n",
      " 0.7856]\n",
      "epoch: 6 step: 510 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 570 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 6 step: 600 \ttraining acc: [0.875     0.875     0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 630 \ttraining acc: [0.375 0.375 0.375 0.375 0.375 0.375]\n",
      "epoch: 6 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 720 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 6 step: 750 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 6 step: 780 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 810 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 6 step: 840 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 6 step: 870 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 900 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 6 step: 930 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 6 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 6 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 7 Val acc: [0.7485 0.758  0.757  0.7554 0.7544 0.755  0.7554 0.7563 0.756  0.757\n",
      " 0.7563]\n",
      "epoch: 7 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.7916667 0.7916667 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 210 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 270 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 300 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 360 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 390 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 450 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 Val acc: [0.748  0.7544 0.755  0.7544 0.754  0.752  0.752  0.7524 0.7524 0.754\n",
      " 0.753 ]\n",
      "epoch: 7 step: 510 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 7 step: 540 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 7 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 600 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 630 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.45833334 0.45833334]\n",
      "epoch: 7 step: 660 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 720 \ttraining acc: [0.7083333 0.7083333 0.7083333 0.7083333 0.7083333 0.7083333]\n",
      "epoch: 7 step: 750 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 7 step: 780 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 810 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 840 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 870 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 900 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 930 \ttraining acc: [1.        1.        1.        0.9583333 0.9583333 0.9583333]\n",
      "epoch: 7 step: 960 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 7 step: 990 \ttraining acc: [0.5833333 0.5833333 0.625     0.6666667 0.6666667 0.75     ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 Val acc: [0.7627 0.595  0.6177 0.6494 0.6675 0.687  0.6963 0.704  0.7144 0.72\n",
      " 0.729 ]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.75      0.75      0.75      0.75      0.7916667 0.7916667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.8333333 0.8333333 0.8333333 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 180 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 8 step: 270 \ttraining acc: [0.41666666 0.41666666 0.41666666 0.41666666 0.41666666 0.41666666]\n",
      "epoch: 8 step: 300 \ttraining acc: [1.        1.        0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 330 \ttraining acc: [0.625 0.625 0.625 0.625 0.625 0.625]\n",
      "epoch: 8 step: 360 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 8 step: 390 \ttraining acc: [0.75 0.75 0.75 0.75 0.75 0.75]\n",
      "epoch: 8 step: 420 \ttraining acc: [0.7916667 0.7916667 0.8333333 0.7083333 0.75      0.75     ]\n",
      "epoch: 8 step: 450 \ttraining acc: [0.75      0.75      0.7083333 0.7083333 0.7083333 0.7916667]\n",
      "epoch: 8 step: 480 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 Val acc: [0.7446 0.745  0.7456 0.7456 0.7476 0.7485 0.7485 0.7485 0.749  0.7505\n",
      " 0.751 ]\n",
      "epoch: 8 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 540 \ttraining acc: [1.        1.        1.        1.        0.9583333 0.9166667]\n",
      "epoch: 8 step: 570 \ttraining acc: [1.        1.        1.        0.9583333 0.8333333 0.75     ]\n",
      "epoch: 8 step: 600 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 630 \ttraining acc: [0.5833333 0.5833333 0.5833333 0.5833333 0.5833333 0.5833333]\n",
      "epoch: 8 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 690 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 720 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 8 step: 750 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 8 step: 780 \ttraining acc: [0.625     0.625     0.625     0.625     0.625     0.6666667]\n",
      "epoch: 8 step: 810 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 8 step: 840 \ttraining acc: [0.5       0.5       0.5       0.625     0.7083333 0.7083333]\n",
      "epoch: 8 step: 870 \ttraining acc: [0.375      0.375      0.375      0.375      0.375      0.41666666]\n",
      "epoch: 8 step: 900 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 8 step: 930 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 8 step: 960 \ttraining acc: [0.45833334 0.45833334 0.45833334 0.45833334 0.41666666 0.45833334]\n",
      "epoch: 8 step: 990 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 0 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 Val acc: [0.7397 0.7314 0.7324 0.7314 0.7324 0.7344 0.736  0.737  0.738  0.7397\n",
      " 0.74  ]\n",
      "epoch: 9 step: 30 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 60 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 90 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 120 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.9166667 0.9166667 0.7916667 0.7916667 0.75      0.75     ]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.7916667 0.7916667 0.7916667 0.7916667 0.7916667 0.7916667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 270 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 300 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.8333333 0.8333333 0.8333333]\n",
      "epoch: 9 step: 330 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 360 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 390 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 420 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 450 \ttraining acc: [0.6666667 0.6666667 0.6666667 0.6666667 0.6666667 0.6666667]\n",
      "epoch: 9 step: 480 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 Val acc: [0.7427 0.7456 0.7456 0.7456 0.745  0.7446 0.7456 0.7456 0.7456 0.746\n",
      " 0.7456]\n",
      "epoch: 9 step: 510 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 540 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 570 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 600 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 630 \ttraining acc: [0.875 0.875 0.875 0.875 0.875 0.875]\n",
      "epoch: 9 step: 660 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 690 \ttraining acc: [0.5416667 0.5416667 0.5416667 0.5416667 0.5416667 0.5416667]\n",
      "epoch: 9 step: 720 \ttraining acc: [0.9583333 0.9583333 0.9583333 0.9583333 0.9583333 0.9583333]\n",
      "epoch: 9 step: 750 \ttraining acc: [1. 1. 1. 1. 1. 1.]\n",
      "epoch: 9 step: 780 \ttraining acc: [0.9166667 0.9166667 0.9166667 0.9166667 0.9166667 0.9166667]\n",
      "epoch: 9 step: 810 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 840 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 870 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 900 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 930 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 960 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 9 step: 990 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "Test acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_Proto2_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 3 \\\n",
    "        --k_qry 12 \\\n",
    "        --meta_lr 1e-2 \\\n",
    "        --update_lr 0.01 \\\n",
    "        --epoch 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=4, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 708.14it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1039.61it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 441.88it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.72it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.5    0.4924\n",
      " 0.4922]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.38541667 0.54166667 0.625      0.625      0.61458333 0.61458333]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.19791667 0.16666667 0.26041667 0.35416667 0.36458333 0.4375    ]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.625      0.6875     0.69791667 0.6875     0.71875    0.69791667]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.5        0.52083333 0.67708333 0.69791667 0.66666667 0.66666667]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.5        0.55208333 0.625      0.60416667 0.60416667 0.60416667]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.40625    0.48958333 0.54166667 0.54166667 0.5        0.5       ]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.52083333 0.61458333 0.52083333 0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.5        0.5        0.46875    0.47916667 0.48958333 0.45833333]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.5        0.52083333 0.63541667 0.48958333 0.65625   ]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.5        0.72916667 0.5625     0.55208333 0.51041667 0.63541667]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.36458333 0.51041667 0.41666667 0.54166667 0.52083333 0.54166667]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.51041667 0.4375     0.54166667 0.58333333 0.55208333 0.5625    ]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.58333333 0.5        0.5        0.5        0.5        0.5       ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.375      0.5        0.5        0.5        0.54166667 0.55208333]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 2 Val acc: [0.5    0.4807 0.4954 0.5    0.5    0.501  0.502  0.503  0.507  0.5093\n",
      " 0.511 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.5        0.59375    0.59375    0.51041667 0.5        0.5       ]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.5        0.5625     0.55208333 0.54166667 0.5       ]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.5        0.5        0.5        0.58333333 0.5        0.5       ]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.5        0.5        0.53125    0.57291667 0.57291667 0.57291667]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.5        0.55208333 0.5625     0.59375    0.65625   ]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.5        0.5        0.5        0.5625     0.60416667 0.60416667]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.63541667]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.5        0.44791667 0.28125    0.3125     0.44791667 0.53125   ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.5        0.58333333 0.69791667 0.73958333 0.71875    0.70833333]\n",
      "epoch: 3 Val acc: [0.5    0.5    0.679  0.834  0.9023 0.8994 0.921  0.91   0.9214 0.916\n",
      " 0.917 ]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.5        0.5        0.47916667 0.57291667 0.53125    0.59375   ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.55208333 0.46875    0.46875    0.44791667 0.44791667]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.48958333 0.52083333 0.47916667 0.52083333]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.5        0.88541667 0.80208333 0.83333333 0.89583333 0.90625   ]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.5        0.63541667 0.84375    0.77083333 0.875     ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.58333333 0.77083333 0.875      0.86458333 0.875     ]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.61458333 0.71875    0.71875    0.71875    0.70833333]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.5        0.46875    0.41666667 0.70833333 0.73958333 0.73958333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.65625    0.63541667 0.72916667 0.73958333 0.66666667]\n",
      "epoch: 4 Val acc: [0.5    0.665  0.76   0.8765 0.9575 0.911  0.957  0.912  0.95   0.9126\n",
      " 0.9463]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.64583333 0.83333333 0.77083333 0.85416667 0.84375   ]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.5        0.61458333 0.66666667 0.63541667 0.67708333 0.625     ]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.61458333 0.73958333 0.71875    0.71875    0.70833333]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.5        0.51041667 0.625      0.84375    0.83333333 0.90625   ]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5        0.625      0.63541667 0.66666667 0.73958333 0.70833333]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.4375     0.45833333 0.5625     0.625      0.59375   ]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.76041667]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.70833333 0.67708333 0.76041667 0.69791667 0.77083333]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.5        0.61458333 0.5625     0.54166667 0.53125    0.61458333]\n",
      "epoch: 5 Val acc: [0.5    0.7314 0.9272 0.93   0.953  0.905  0.9385 0.913  0.9277 0.93\n",
      " 0.9365]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.5        0.71875    0.95833333 0.94791667 0.94791667 0.94791667]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.70833333 0.77083333 0.78125    0.77083333 0.77083333]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.66666667 0.72916667 0.70833333 0.82291667 0.78125   ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.54166667 0.61458333 0.71875    0.6875     0.71875   ]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.79166667 0.83333333 0.83333333 0.83333333 0.83333333]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.75       0.78125    0.76041667 0.77083333 0.77083333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.5        0.52083333 0.77083333 0.71875    0.78125    0.75      ]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.83333333 0.94791667 0.9375     0.9375     0.9375    ]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.6875     0.72916667 0.72916667 0.72916667 0.71875   ]\n",
      "epoch: 6 Val acc: [0.5    0.8687 0.9873 0.9673 0.97   0.954  0.955  0.9424 0.9517 0.9404\n",
      " 0.9478]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.66666667 0.76041667 0.79166667 0.80208333 0.80208333]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.5        0.59375    0.75       0.75       0.73958333 0.75      ]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.54166667 0.52083333 0.625      0.54166667 0.61458333]\n",
      "epoch: 6 step: 120 \ttraining acc: [0.5        0.59375    0.66666667 0.63541667 0.63541667 0.625     ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 150 \ttraining acc: [0.47916667 0.66666667 0.71875    0.69791667 0.70833333 0.70833333]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.66666667 0.72916667 0.79166667 0.78125    0.79166667]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.5        0.65625    0.72916667 0.71875    0.6875     0.66666667]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.63541667 0.83333333 0.82291667 0.85416667 0.85416667]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.5625     0.61458333 0.625      0.58333333 0.64583333]\n",
      "epoch: 7 Val acc: [0.5    0.7812 0.918  0.9297 0.951  0.9404 0.959  0.944  0.958  0.9395\n",
      " 0.9478]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.83333333 0.88541667 0.9375     0.91666667 0.92708333]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.5        0.73958333 0.70833333 0.73958333 0.72916667 0.71875   ]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.5        0.71875    0.77083333 0.8125     0.82291667 0.82291667]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.64583333 0.80208333 0.78125    0.78125    0.78125    0.78125   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.46875    0.75       0.875      0.88541667 0.9375     0.95833333]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5        0.75       0.82291667 0.76041667 0.84375    0.82291667]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.5        0.75       0.84375    0.84375    0.85416667 0.85416667]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.46875    0.75       0.69791667 0.78125    0.79166667 0.79166667]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.5        0.63541667 0.75       0.8125     0.83333333 0.83333333]\n",
      "epoch: 8 Val acc: [0.5    0.72   0.9727 0.9575 0.9663 0.95   0.9644 0.9443 0.967  0.951\n",
      " 0.9585]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.57291667 0.48958333 0.51041667 0.55208333 0.63541667]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.5        0.71875    0.67708333 0.66666667 0.67708333 0.70833333]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.48958333 0.65625    0.80208333 0.76041667 0.76041667 0.76041667]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.83333333 0.76041667 0.76041667 0.86458333 0.82291667]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.63541667 0.625      0.64583333 0.67708333 0.64583333]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.5        0.5625     0.61458333 0.73958333 0.61458333 0.71875   ]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.5        0.52083333 0.86458333 0.82291667 0.82291667 0.8125    ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.5        0.5        0.67708333 0.6875     0.70833333 0.75      ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.5        0.58333333 0.375      0.42708333 0.30208333 0.38541667]\n",
      "epoch: 9 Val acc: [0.5    0.539  0.964  0.968  0.9727 0.9565 0.9673 0.953  0.9644 0.956\n",
      " 0.9614]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.5        0.65625    0.66666667 0.69791667 0.69791667]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.65625    0.85416667 0.77083333 0.82291667 0.77083333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.58333333 0.67708333 0.64583333 0.76041667 0.71875   ]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.57291667 0.8125     0.86458333 0.875      0.88541667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.48958333 0.58333333 0.67708333 0.77083333 0.80208333 0.77083333]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.5        0.6875     0.73958333 0.72916667 0.71875    0.72916667]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.5        0.76041667 0.8125     0.86458333 0.86458333 0.86458333]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.52083333 0.79166667 0.86458333 0.875      0.94791667 0.94791667]\n",
      "Test acc: [0.5    0.601  0.6035 0.6797 0.6577 0.6733 0.6455 0.654  0.6426 0.652\n",
      " 0.6323]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 4 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(attention_size=32, data_dir='./data/multiple_graph/cycle/META_LABEL/random_edge100/', epoch=10, fold_n=5, hidden_dim=32, input_dim=1, k_qry=12, k_spt=1, meta_lr=0.001, n_graphlets=5, n_way=2, no_finetune=True, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 90.84it/s]\n",
      "There are 1 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 875.64it/s]\n",
      "There are 2 non-isomorphic graphs\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 359.49it/s]\n",
      "There are 6 non-isomorphic graphs\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 41.29it/s]\n",
      "There are 21 non-isomorphic graphs\n",
      "There are 30 number of graphlets\n",
      "Meta(\n",
      "  (net): Classifier(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 1x32]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 32x32]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 32x30]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 32]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 4354\n",
      "shuffle DB :train, b:1000, 2-way, 1-shot, 12-query\n",
      "shuffle DB :val, b:100, 2-way, 1-shot, 12-query\n",
      "shuffle DB :test, b:100, 2-way, 1-shot, 12-query\n",
      "epoch: 0 step: 0 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 Val acc: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 30 \ttraining acc: [0.46875    0.61458333 0.625      0.63541667 0.59375    0.58333333]\n",
      "epoch: 0 step: 60 \ttraining acc: [0.35416667 0.51041667 0.47916667 0.47916667 0.47916667 0.47916667]\n",
      "epoch: 0 step: 90 \ttraining acc: [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "epoch: 0 step: 120 \ttraining acc: [0.57291667 0.46875    0.5        0.5        0.5        0.5       ]\n",
      "epoch: 0 step: 150 \ttraining acc: [0.82291667 0.79166667 0.8125     0.79166667 0.79166667 0.79166667]\n",
      "epoch: 0 step: 180 \ttraining acc: [0.48958333 0.48958333 0.51041667 0.47916667 0.45833333 0.48958333]\n",
      "epoch: 0 step: 210 \ttraining acc: [0.61458333 0.55208333 0.5        0.48958333 0.44791667 0.44791667]\n",
      "epoch: 0 step: 240 \ttraining acc: [0.30208333 0.57291667 0.5625     0.5625     0.5625     0.5625    ]\n",
      "epoch: 1 step: 0 \ttraining acc: [0.41666667 0.625      0.67708333 0.66666667 0.65625    0.63541667]\n",
      "epoch: 1 Val acc: [0.522  0.5356 0.5215 0.517  0.515  0.5146 0.5186 0.5176 0.5186 0.5176\n",
      " 0.5215]\n",
      "epoch: 1 step: 30 \ttraining acc: [0.51041667 0.6875     0.53125    0.65625    0.625      0.60416667]\n",
      "epoch: 1 step: 60 \ttraining acc: [0.5        0.54166667 0.51041667 0.52083333 0.5        0.52083333]\n",
      "epoch: 1 step: 90 \ttraining acc: [0.73958333 0.625      0.54166667 0.51041667 0.5625     0.52083333]\n",
      "epoch: 1 step: 120 \ttraining acc: [0.42708333 0.38541667 0.47916667 0.5        0.51041667 0.54166667]\n",
      "epoch: 1 step: 150 \ttraining acc: [0.5        0.5        0.53125    0.57291667 0.58333333 0.58333333]\n",
      "epoch: 1 step: 180 \ttraining acc: [0.4375     0.5        0.47916667 0.47916667 0.48958333 0.52083333]\n",
      "epoch: 1 step: 210 \ttraining acc: [0.61458333 0.60416667 0.60416667 0.60416667 0.61458333 0.625     ]\n",
      "epoch: 1 step: 240 \ttraining acc: [0.44791667 0.46875    0.5        0.51041667 0.52083333 0.53125   ]\n",
      "epoch: 2 step: 0 \ttraining acc: [0.55208333 0.65625    0.80208333 0.73958333 0.71875    0.67708333]\n",
      "epoch: 2 Val acc: [0.5    0.4993 0.5146 0.5454 0.5527 0.5454 0.54   0.5415 0.5366 0.5405\n",
      " 0.544 ]\n",
      "epoch: 2 step: 30 \ttraining acc: [0.48958333 0.72916667 0.86458333 0.83333333 0.80208333 0.79166667]\n",
      "epoch: 2 step: 60 \ttraining acc: [0.5        0.5625     0.75       0.65625    0.67708333 0.67708333]\n",
      "epoch: 2 step: 90 \ttraining acc: [0.41666667 0.48958333 0.48958333 0.5        0.54166667 0.60416667]\n",
      "epoch: 2 step: 120 \ttraining acc: [0.27083333 0.60416667 0.60416667 0.60416667 0.60416667 0.61458333]\n",
      "epoch: 2 step: 150 \ttraining acc: [0.5        0.75       0.90625    0.95833333 0.94791667 0.94791667]\n",
      "epoch: 2 step: 180 \ttraining acc: [0.52083333 0.53125    0.61458333 0.64583333 0.67708333 0.66666667]\n",
      "epoch: 2 step: 210 \ttraining acc: [0.41666667 0.79166667 0.84375    0.84375    0.86458333 0.88541667]\n",
      "epoch: 2 step: 240 \ttraining acc: [0.32291667 0.61458333 0.80208333 0.79166667 0.80208333 0.8125    ]\n",
      "epoch: 3 step: 0 \ttraining acc: [0.57291667 0.61458333 0.625      0.61458333 0.61458333 0.63541667]\n",
      "epoch: 3 Val acc: [0.487  0.519  0.503  0.5015 0.501  0.4988 0.4988 0.506  0.511  0.5093\n",
      " 0.5117]\n",
      "epoch: 3 step: 30 \ttraining acc: [0.625      0.66666667 0.70833333 0.73958333 0.73958333 0.75      ]\n",
      "epoch: 3 step: 60 \ttraining acc: [0.5        0.47916667 0.5        0.5        0.5        0.5       ]\n",
      "epoch: 3 step: 90 \ttraining acc: [0.5        0.5        0.5625     0.55208333 0.53125    0.51041667]\n",
      "epoch: 3 step: 120 \ttraining acc: [0.52083333 0.5625     0.5625     0.60416667 0.625      0.64583333]\n",
      "epoch: 3 step: 150 \ttraining acc: [0.5        0.63541667 0.59375    0.63541667 0.61458333 0.625     ]\n",
      "epoch: 3 step: 180 \ttraining acc: [0.5        0.64583333 0.625      0.625      0.625      0.64583333]\n",
      "epoch: 3 step: 210 \ttraining acc: [0.5        0.48958333 0.5        0.5        0.5        0.54166667]\n",
      "epoch: 3 step: 240 \ttraining acc: [0.73958333 0.625      0.60416667 0.55208333 0.57291667 0.55208333]\n",
      "epoch: 4 step: 0 \ttraining acc: [0.5        0.73958333 0.71875    0.70833333 0.70833333 0.70833333]\n",
      "epoch: 4 Val acc: [0.5    0.5596 0.549  0.54   0.5327 0.531  0.527  0.527  0.53   0.5293\n",
      " 0.5303]\n",
      "epoch: 4 step: 30 \ttraining acc: [0.5        0.5        0.5        0.5        0.5        0.54166667]\n",
      "epoch: 4 step: 60 \ttraining acc: [0.51041667 0.48958333 0.48958333 0.48958333 0.48958333 0.48958333]\n",
      "epoch: 4 step: 90 \ttraining acc: [0.5        0.52083333 0.53125    0.53125    0.53125    0.53125   ]\n",
      "epoch: 4 step: 120 \ttraining acc: [0.85416667 0.64583333 0.5        0.51041667 0.59375    0.61458333]\n",
      "epoch: 4 step: 150 \ttraining acc: [0.5     0.53125 0.5     0.5     0.5     0.53125]\n",
      "epoch: 4 step: 180 \ttraining acc: [0.5        0.5        0.5        0.47916667 0.44791667 0.44791667]\n",
      "epoch: 4 step: 210 \ttraining acc: [0.5        0.5        0.5        0.5625     0.57291667 0.625     ]\n",
      "epoch: 4 step: 240 \ttraining acc: [0.5        0.40625    0.5        0.5        0.55208333 0.54166667]\n",
      "epoch: 5 step: 0 \ttraining acc: [0.375      0.21875    0.38541667 0.38541667 0.375      0.375     ]\n",
      "epoch: 5 Val acc: [0.5    0.4736 0.465  0.4841 0.497  0.5044 0.5103 0.5127 0.5137 0.5176\n",
      " 0.518 ]\n",
      "epoch: 5 step: 30 \ttraining acc: [0.55208333 0.58333333 0.58333333 0.61458333 0.61458333 0.61458333]\n",
      "epoch: 5 step: 60 \ttraining acc: [0.5        0.44791667 0.4375     0.63541667 0.70833333 0.75      ]\n",
      "epoch: 5 step: 90 \ttraining acc: [0.5        0.5        0.5        0.51041667 0.52083333 0.53125   ]\n",
      "epoch: 5 step: 120 \ttraining acc: [0.5        0.48958333 0.51041667 0.59375    0.65625    0.67708333]\n",
      "epoch: 5 step: 150 \ttraining acc: [0.5        0.5        0.5625     0.5625     0.54166667 0.5       ]\n",
      "epoch: 5 step: 180 \ttraining acc: [0.5        0.5        0.4375     0.58333333 0.72916667 0.73958333]\n",
      "epoch: 5 step: 210 \ttraining acc: [0.54166667 0.5        0.54166667 0.58333333 0.63541667 0.77083333]\n",
      "epoch: 5 step: 240 \ttraining acc: [0.5        0.39583333 0.45833333 0.5        0.54166667 0.47916667]\n",
      "epoch: 6 step: 0 \ttraining acc: [0.5        0.5        0.66666667 0.73958333 0.73958333 0.8125    ]\n",
      "epoch: 6 Val acc: [0.5    0.5034 0.4983 0.495  0.524  0.5303 0.538  0.547  0.555  0.557\n",
      " 0.5605]\n",
      "epoch: 6 step: 30 \ttraining acc: [0.5        0.5        0.5        0.54166667 0.58333333 0.63541667]\n",
      "epoch: 6 step: 60 \ttraining acc: [0.26041667 0.41666667 0.40625    0.44791667 0.44791667 0.52083333]\n",
      "epoch: 6 step: 90 \ttraining acc: [0.5        0.5        0.51041667 0.46875    0.4375     0.44791667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 120 \ttraining acc: [0.48958333 0.45833333 0.53125    0.47916667 0.53125    0.55208333]\n",
      "epoch: 6 step: 150 \ttraining acc: [0.26041667 0.51041667 0.54166667 0.54166667 0.51041667 0.52083333]\n",
      "epoch: 6 step: 180 \ttraining acc: [0.5        0.38541667 0.375      0.44791667 0.41666667 0.59375   ]\n",
      "epoch: 6 step: 210 \ttraining acc: [0.4375     0.59375    0.55208333 0.65625    0.60416667 0.61458333]\n",
      "epoch: 6 step: 240 \ttraining acc: [0.5        0.625      0.60416667 0.60416667 0.61458333 0.6875    ]\n",
      "epoch: 7 step: 0 \ttraining acc: [0.5        0.70833333 0.6875     0.72916667 0.75       0.79166667]\n",
      "epoch: 7 Val acc: [0.5    0.4978 0.514  0.5405 0.5615 0.563  0.5703 0.571  0.5806 0.5835\n",
      " 0.584 ]\n",
      "epoch: 7 step: 30 \ttraining acc: [0.5        0.5        0.54166667 0.60416667 0.67708333 0.75      ]\n",
      "epoch: 7 step: 60 \ttraining acc: [0.38541667 0.35416667 0.54166667 0.5        0.53125    0.55208333]\n",
      "epoch: 7 step: 90 \ttraining acc: [0.33333333 0.65625    0.71875    0.71875    0.71875    0.75      ]\n",
      "epoch: 7 step: 120 \ttraining acc: [0.5        0.625      0.63541667 0.64583333 0.64583333 0.65625   ]\n",
      "epoch: 7 step: 150 \ttraining acc: [0.45833333 0.59375    0.58333333 0.58333333 0.58333333 0.59375   ]\n",
      "epoch: 7 step: 180 \ttraining acc: [0.5625     0.58333333 0.70833333 0.70833333 0.71875    0.71875   ]\n",
      "epoch: 7 step: 210 \ttraining acc: [0.47916667 0.45833333 0.51041667 0.5625     0.5625     0.5625    ]\n",
      "epoch: 7 step: 240 \ttraining acc: [0.5        0.60416667 0.58333333 0.66666667 0.63541667 0.65625   ]\n",
      "epoch: 8 step: 0 \ttraining acc: [0.47916667 0.67708333 0.67708333 0.6875     0.70833333 0.70833333]\n",
      "epoch: 8 Val acc: [0.5    0.5093 0.5396 0.5317 0.549  0.544  0.553  0.5635 0.5586 0.5645\n",
      " 0.5625]\n",
      "epoch: 8 step: 30 \ttraining acc: [0.5        0.6875     0.69791667 0.71875    0.72916667 0.73958333]\n",
      "epoch: 8 step: 60 \ttraining acc: [0.63541667 0.79166667 0.6875     0.69791667 0.78125    0.78125   ]\n",
      "epoch: 8 step: 90 \ttraining acc: [0.54166667 0.69791667 0.70833333 0.75       0.76041667 0.77083333]\n",
      "epoch: 8 step: 120 \ttraining acc: [0.5        0.5        0.5        0.58333333 0.51041667 0.58333333]\n",
      "epoch: 8 step: 150 \ttraining acc: [0.5        0.60416667 0.69791667 0.625      0.67708333 0.66666667]\n",
      "epoch: 8 step: 180 \ttraining acc: [0.375      0.5        0.63541667 0.72916667 0.80208333 0.89583333]\n",
      "epoch: 8 step: 210 \ttraining acc: [0.04166667 0.5        0.625      0.66666667 0.75       0.75      ]\n",
      "epoch: 8 step: 240 \ttraining acc: [0.55208333 0.66666667 0.66666667 0.71875    0.70833333 0.75      ]\n",
      "epoch: 9 step: 0 \ttraining acc: [0.36458333 0.63541667 0.79166667 0.8125     0.82291667 0.84375   ]\n",
      "epoch: 9 Val acc: [0.4988 0.5156 0.521  0.5215 0.5273 0.534  0.5347 0.536  0.532  0.5425\n",
      " 0.5386]\n",
      "epoch: 9 step: 30 \ttraining acc: [0.5        0.5625     0.60416667 0.60416667 0.64583333 0.70833333]\n",
      "epoch: 9 step: 60 \ttraining acc: [0.5        0.6875     0.75       0.77083333 0.77083333 0.73958333]\n",
      "epoch: 9 step: 90 \ttraining acc: [0.5        0.58333333 0.78125    0.84375    0.92708333 0.94791667]\n",
      "epoch: 9 step: 120 \ttraining acc: [0.5        0.46875    0.44791667 0.59375    0.5        0.60416667]\n",
      "epoch: 9 step: 150 \ttraining acc: [0.44791667 0.39583333 0.45833333 0.59375    0.5625     0.57291667]\n",
      "epoch: 9 step: 180 \ttraining acc: [0.44791667 0.60416667 0.77083333 0.79166667 0.80208333 0.80208333]\n",
      "epoch: 9 step: 210 \ttraining acc: [0.65625    0.69791667 0.77083333 0.78125    0.79166667 0.76041667]\n",
      "epoch: 9 step: 240 \ttraining acc: [0.60416667 0.84375    0.89583333 0.86458333 0.88541667 0.86458333]\n",
      "Test acc: [0.501  0.4946 0.505  0.502  0.5034 0.4976 0.5034 0.4958 0.503  0.5\n",
      " 0.5005]\n"
     ]
    }
   ],
   "source": [
    "!python ./graphlet_meta_label/train.py \\\n",
    "        --data_dir ./data/multiple_graph/cycle/META_LABEL/random_edge100/ \\\n",
    "        --fold_n 5 \\\n",
    "        --k_spt 1 \\\n",
    "        --k_qry 12 \\\n",
    "        --epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
