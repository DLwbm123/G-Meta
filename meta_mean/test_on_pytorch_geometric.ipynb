{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9476, grad_fn=<NllLossBackward>)\n",
      "tensor(1.8307, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6957, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5587, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4129, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2781, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1640, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8570, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5797, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4433, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3166, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2276, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1591, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1253, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0893, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0935, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0847, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0763, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0523, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0681, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0408, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0267, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0573, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0314, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0336, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0313, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0298, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0326, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0274, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0195, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0290, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0183, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0288, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0259, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0236, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0307, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0224, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0306, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0217, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0317, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0205, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0245, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0216, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0251, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0310, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0330, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0262, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0311, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0241, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0272, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0192, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0219, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0231, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
